{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import zipfile\n",
    "import itertools\n",
    "from lxml import etree \n",
    "#from czml import czml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import repeat\n",
    "logging.info('numpy pandas and itertools')\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import DayLocator, HourLocator, DateFormatter, MinuteLocator, drange\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "logging.info('imported matplotlib')\n",
    "import math\n",
    "import sys\n",
    "import xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logging.info('imported math, sys, os and xlrd')\n",
    "from datetime import datetime, timedelta\n",
    "import csv\n",
    "logging.info('datetime and csv')\n",
    "from collections import OrderedDict, defaultdict\n",
    "import simplekml\n",
    "logging.info('collections and simplekml')\n",
    "import re\n",
    "import beacon_decode as bcn\n",
    "logging.info('re and beacon decode')\n",
    "import pypyodbc as odbc \n",
    "logging.info('pyodbc imported - all modules imported')\n",
    "from polycircles import polycircles\n",
    "from decimal import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "getcontext().prec = 3\n",
    "\n",
    "\n",
    "UID = 'jesse'\n",
    "PWD = 'nopw'\n",
    "\n",
    "pd.options.mode.chained_assignment = None # turn off SettingWithCopyWarning\n",
    "\n",
    "# Set some variable\n",
    "\n",
    "MEOLUTName ={3669:'Florida',3385:'Hawaii',3677:'Maryland'}\n",
    "MEOList = [3669, 3385, 3677]\n",
    "MEORefLoc = {3669:(25.6162, -80.3843),3385:(21.52071, -157.9963), #Reference Beacon Locations\n",
    "    3677:(38.999121, -76.853789)} # Goddard beacon antenna unknown\n",
    "MEOLUTref = {3669: 'Florida-1', 3385:'Hawaii-1', 3677:'NASA_Goddard'}\n",
    "ReferenceBeacons = {'Florida-1':{'beaconId': 'ADDC00202020201',\n",
    "                                'beaconLat': 25.61622,\n",
    "                                'beaconLon': -80.38422,\n",
    "                                'repRate': 50},\n",
    "                    'Hawaii-1': {'beaconId': 'AA5FC0000000001',\n",
    "                                'beaconLat': 21.52075,\n",
    "                                'beaconLon': -157.9963,\n",
    "                                'repRate': 50},\n",
    "                    'California': {'beaconId': 'ADFC000001D0033',\n",
    "                                'beaconLat': 34.6625,\n",
    "                                'beaconLon': -120.5515,\n",
    "                                'repRate': 50},\n",
    "                    'Edmonton': {'beaconId': 'A79EEE26E32E1D0',\n",
    "                                'beaconLat': 53.678667,\n",
    "                                'beaconLon': -113.315,\n",
    "                                'repRate': 50},\n",
    "                    'Ottawa': {'beaconId': 'A79EEE26E32E190',\n",
    "                                'beaconLat': 45.3291,\n",
    "                                'beaconLon': -75.6745,\n",
    "                                'repRate': 50},\n",
    "                    'McMurdo': {'beaconId': 'ADC268F8E0D3730',\n",
    "                                'beaconLat': -77.846033,\n",
    "                                'beaconLon': 166.71178,\n",
    "                                'repRate': 50},\n",
    "                    'NASA_Goddard': {'beaconId': 'ADFFFFFFFFFFFFC',\n",
    "                                'beaconLat': 38.99895,\n",
    "                                'beaconLon': -76.841599,\n",
    "                                'repRate': 50},\n",
    "                    'ToulouseTCAL': {'beaconId': '9C6000000000001',\n",
    "                                'beaconLat': 43.5605,\n",
    "                                'beaconLon': 1.4808,\n",
    "                                'repRate': 30},\n",
    "                    'ToulouseOrb': {'beaconId': '9C634E2AB509240',\n",
    "                                'beaconLat': 43.5605,\n",
    "                                'beaconLon': 1.4808,\n",
    "                                'repRate': 30},\n",
    "                    'ToulouseMeoQMS': {'beaconId': '9C62BE29630F1D0',\n",
    "                                'beaconLat': 43.56053521,\n",
    "                                'beaconLon': 1.480896128,\n",
    "                                'repRate': 50},\n",
    "                    'SpitsbergenMeoQMS': {'beaconId': 'A042BE29630F190',\n",
    "                                'beaconLat': 78.23075718,\n",
    "                                'beaconLon': 15.37056787,\n",
    "                                'repRate': 50},\n",
    "                    'MaspalomasMeoQMS': {'beaconId': '9C02BE29630F0A0',\n",
    "                                'beaconLat': 27.76150509,\n",
    "                                'beaconLon': -15.63427686,\n",
    "                                'repRate': 50},\n",
    "                }\n",
    "\n",
    "#Date Formats\n",
    "timepacket_format = '%Y-%m-%d %H:%M:%S.%f'\n",
    "sec_f = '%S.%f'\n",
    "plot_fmt = DateFormatter('%m-%d %H:%M')\n",
    "Hours = MinuteLocator(interval = 30)\n",
    "FiveMinutes = MinuteLocator(interval=5)\n",
    "\n",
    "\n",
    "data_cols = ['DataType','BcnId15','BcnId30','SourceId','TimeFirst','TimeLast','Latitude',\n",
    "    'Longitude','Altitude','NumBursts','NumPackets','DOP','ExpectedHorzError']\n",
    "data_cols = [0,1,2,4,8,9,10,11,12,13,14,17,18,19,20,21,22,36,37,47]\n",
    "ant_list = range(1,7)\n",
    "MEOLUTLoc = {3669:(25.617645, -80.383211), 3385:(21.5244, -158.0012), #MEOLUT Locations\n",
    "    3677:(38.999121, -76.853789), 2276:(43.56053521, 1.480896128)}\n",
    "\n",
    "Miami_height = 1\n",
    "NSOF_height = 10\n",
    "Wahiawa_height = 1\n",
    "\n",
    "MEOLUT_antenna_locations = {3669:{1:(25.617661, -80.383376, Miami_height),2: (25.617754, -80.383177, Miami_height), \n",
    "                                  3: (25.617641, -80.382956, Miami_height), 4:(25.617425, -80.382982, Miami_height),\n",
    "                                  5: (25.617309, -80.383185, Miami_height), 6:(25.617440, -80.383412, Miami_height),\n",
    "                                  7: (25.617234, -80.383470, Miami_height), 8:(25.617200, -80.382950, Miami_height),\n",
    "                                  9: (38.852473, -76.936823, NSOF_height)},\n",
    "                            3385:{1:(21.524682, -158.001442, Wahiawa_height), 2: (21.524711, -158.001071, Wahiawa_height),\n",
    "                                  3:(21.524414, -158.000923, Wahiawa_height), 4: (21.524086, -158.001048, Wahiawa_height),\n",
    "                                  5:(21.524123, -158.001459, Wahiawa_height), 6: (21.524392, -158.001614, Wahiawa_height),\n",
    "                                  7:(21.525110, -158.001270, Wahiawa_height), 8: (21.525090, -158.000895, Wahiawa_height)}}\n",
    "\n",
    "sat_list = [302, 315, 324, 430, 329, 408, 422, 319, 306, 317, 422, 430]\n",
    "''' see http://www.cospas-sarsat.int/en/system/space-segment-status-pro/current-space-segment-status-and-sar-payloads-pro  for full list '''\n",
    "all_sarsats = [401, 402, 403, 404, 405, 407, 408, 409, 414, 418, 419, 420, 422, \n",
    "               424, 426, 430, 501, 502, 301, 302, 303, 306, 308, 309, 310, 312, \n",
    "               315, 316, 317, 318, 319, 323, 324, 326, 327, 329, 330, 332]\n",
    "us_sarsats = allsats = [408, 409, 419, 422, 424, 426, 430, 301, 302, 303, 306, \n",
    "                        308, 309, 310, 312, 315, 316, 317, 318, 319, 323, 324, \n",
    "                        326, 327, 329, 330, 332]\n",
    "\n",
    "datetime_format = '%y %j %H%M %S.%f'\n",
    "\n",
    "USMCC = False\n",
    "\n",
    "if USMCC == True:\n",
    "    icon_list = {\n",
    "        'blue_dot': '/static/icons/blue_pog.png',\n",
    "        'red_dot': '/static/icons/placemark_circle_highlight.png',\n",
    "        'white_dot': '/static/icons/placemark_circle.png',\n",
    "        'blue_square': '/static/icons/track-none.png',\n",
    "        'black_square': '/static/icons/icon61.png',\n",
    "        'white_circle': '/static/icons/icon18.png',\n",
    "        'green_circle': '/static/icons/icon17.png',\n",
    "        'red_cross': '/static/icons/icon63.png',\n",
    "        'yellow_pin': '/static/icons/ylw-blank.png',\n",
    "        'red_pin': '/static/icons/red-circle.png',\n",
    "        'blue_pin': '/static/icons/blu-blank.png',\n",
    "        'white_arrow': '/static/icons/arrow.png',\n",
    "        'green_arrow': '/static/icons/green_arrow.png',\n",
    "        'circle_E': '/static/icons/iconE.png',\n",
    "        'circle_M': '/static/icons/iconM.png',\n",
    "        'circle_L': '/static/icons/iconL.png',\n",
    "        'little_E': '/static/icons/littleE.png',\n",
    "        'little_M': '/static/icons/littleM.png',\n",
    "        'little_L': '/static/icons/littleL.png',\n",
    "        'M': '/static/icons/M.png',\n",
    "        'L': '/static/icons/L.png',\n",
    "        'One': '/static/icons/1.png',\n",
    "        }\n",
    "\n",
    "else: \n",
    "    icon_list = {\n",
    "        'blue_dot': 'http://maps.google.com/mapfiles/kml/paddle/blu-blank-lv.png',\n",
    "        'red_dot': 'http://maps.google.com/mapfiles/kml/pal4/icon49.png',\n",
    "        'white_dot': 'http://maps.google.com/mapfiles/kml/pal4/icon57.png',\n",
    "        'blue_square': 'http://earth.google.com/images/kml-icons/track-directional/track-none.png',\n",
    "        'black_square': 'http://maps.google.com/mapfiles/kml/pal4/icon56.png',\n",
    "        'white_circle': 'http://maps.google.com/mapfiles/kml/pal2/icon18.png',\n",
    "        'green_circle': 'http://maps.google.com/mapfiles/kml/pal4/icon17.png',\n",
    "        'red_cross': 'http://maps.google.com/mapfiles/kml/pal4/icon63.png',\n",
    "        'yellow_pin': 'http://maps.google.com/mapfiles/kml/paddle/ylw-blank.png',\n",
    "        'red_pin': 'http://maps.google.com/mapfiles/kml/paddle/red-circle.png',\n",
    "        'blue_pin': 'http://maps.google.com/mapfiles/kml/paddle/blu-blank.png',\n",
    "        'white_arrow': 'http://maps.google.com/mapfiles/kml/shapes/arrow.png',\n",
    "        'green_arrow': 'https://www.google.com/mapfiles/arrow.png',\n",
    "        'circle_E': 'http://maps.google.com/mapfiles/kml/pal5/icon52.png',\n",
    "        'circle_M': 'http://maps.google.com/mapfiles/kml/pal5/icon36.png',\n",
    "        'circle_L': 'http://maps.google.com/mapfiles/kml/pal5/icon35.png',\n",
    "        'little_E': 'http://maps.google.com/mapfiles/kml/pal5/icon60l.png',\n",
    "        'little_M': 'http://maps.google.com/mapfiles/kml/pal5/icon36l.png',\n",
    "        'little_L': 'http://maps.google.com/mapfiles/kml/pal5/icon43l.png',\n",
    "        'M': 'http://maps.google.com/mapfiles/kml/paddle/M.png',\n",
    "        'L': 'http://maps.google.com/mapfiles/kml/paddle/L.png',\n",
    "        'One': 'http://maps.google.com/mapfiles/kml/paddle/1.png',}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#functions for dealing with times\n",
    "def xldate_to_datetime(xldate):\n",
    "\ttemp = datetime(1900, 1, 1)\n",
    "\tdelta = timedelta(days=(xldate-1))\n",
    "\treturn temp+delta\n",
    "\n",
    "def time_to_datetime(timein):\n",
    "    if isinstance(timein, datetime): \n",
    "        return timein\n",
    "    if isinstance(timein, basestring): \n",
    "        return datetime.strptime(timein, timepacket_format)\n",
    "    if isinstance(timein, float): return xldate_to_datetime(timein)\n",
    "    else: raise TypeError('timein is unrecognized type, must be a datetime, string, or excel serial float, not a %s' % type(timein))\n",
    "        \n",
    "def haversine(x):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points \n",
    "    on the earth (specified in decimal degrees)\n",
    "    \"\"\"\n",
    "    # convert decimal degrees to radians \n",
    "    for i in x:\n",
    "        if i == None:\n",
    "            return None\n",
    "\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [x[0], x[1], x[2], x[3]])\n",
    "    # haversine formula \n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a)) \n",
    "    r = 6373 # Radius of earth in kilometers. Use 3956 for miles     \n",
    "    return c * r\n",
    "\n",
    "#safe division (don't fail for divide by 0, return 0) \n",
    "def safe_div(a,b):\n",
    "    if b<=0:\n",
    "        return 0\n",
    "    else: return a/float(b)\n",
    "#function to iterate using fetchmany yield \n",
    "def ResultIter(cursor, arraysize=1000):\n",
    "    while True:\n",
    "        results = cursor.fetchmany(arraysize)\n",
    "        if not results:\n",
    "            break\n",
    "        for result in results:\n",
    "            yield result\n",
    "\n",
    "#Write function that filters data based on one field (filter field, filter criteria) \n",
    "def filter1(df, field, criteria):\n",
    "    return df[df[field]==float(criteria)]\n",
    "def JSON_to_csv(url, csvout):\n",
    "    response = urllib.urlopen(url)\n",
    "    data = json.loads(response.read())\n",
    "    file_out = r'D:\\Reich_disk1\\Documents\\Coding\\Python\\JSON_to_csv\\test.csv'\n",
    "    with open( file_out, 'wb' ) as out_file:\n",
    "        csv_w = csv.writer( out_file )\n",
    "        for i_r in data:\n",
    "            csv_w.writerow( i_r )\n",
    "    return None\n",
    "\n",
    "#Write function that filters data based on range of one field (filter field, filter criteria_low, filter criteria_high) \n",
    "def filter_range(df, field, criteria_low, criteria_high):\n",
    "    return df[((df[field] >= float(criteria_low)) & (df[field] <= float(criteria_high)))]\n",
    "\n",
    "def singleburst_loc(df, lat_GT, lon_GT, MEOLUT):\n",
    "    df2 = df\n",
    "    if MEOLUT:\n",
    "        df2 = df[(df.sourceid == MEOLUT)]\n",
    "    if df2.empty: return df2\n",
    "\n",
    "    df2['Lat_GT'],df2['Lon_GT'] = lat_GT, lon_GT\n",
    "    df2['Error_GT'] = df2[['latitude','longitude', 'Lat_GT','Lon_GT']].apply(haversine, axis = 1)\n",
    "    df2['Error_Enc'] = df2[['latitude','longitude','Enc_Lat','Enc_Lon']].apply(haversine, axis = 1)\n",
    "    dfSB = df2.sort_values('timelast')\n",
    "    dfSB = dfSB.drop(['Lat_GT','Lon_GT'],axis = 1)\n",
    "    dfSB['timestart_diff'] = dfSB['timefirst'].shift(-1) - dfSB['timefirst']\n",
    "    dfSB['TimeToMcc'] = dfSB.index - dfSB['timelast']\n",
    "    dfSB['TimeToGenerate'] = dfSB.index - dfSB['timelast']\n",
    "    dfSB = dfSB[(dfSB.timestart_diff > pd.Timedelta(seconds = 5)) | (dfSB.timestart_diff.isnull())] ###PROBLEM\n",
    "    return dfSB\n",
    "\n",
    "def multiburst_loc(df,lat_GT,lon_GT,MEOLUT, window_span):\n",
    "    timefirst = df.timefirst.min()\n",
    "    timelast = df.timelast.max()\n",
    "    df2 = df[(df.sourceid == MEOLUT)]\n",
    "    if df2.empty: return df2\n",
    "    df2['Lat_GT'],df2['Lon_GT'] = lat_GT, lon_GT\n",
    "    df2['Error_GT'] = df2[['latitude','longitude', 'Lat_GT','Lon_GT']].apply(haversine, axis = 1)\n",
    "    df2['Error_Enc'] = df2[['latitude','longitude','Enc_Lat','Enc_Lon']].apply(haversine, axis = 1)\n",
    "\n",
    "    ##df2 = df2.sort_values('TimeFirst')\n",
    "    df3 = df2.drop(['Lat_GT','Lon_GT'],axis = 1)\n",
    "    \n",
    "    # Sorting and finding windows\n",
    "    df3 = df3.sort_values('timelast') #Rethink how you do windows 12/9 -- I think it was solved previously 1/8/17\n",
    "    df3['timestart_diff'] = df3['timefirst'].shift(-1) - df3['timefirst']\n",
    "    df3['timestart_diff2'] = df3['timefirst'].shift(-2) - df3['timefirst']\n",
    "    df3['TimeToMcc'] = df3.index - df3['timelast']\n",
    "    df3['TimeToGenerate'] = df3.index - df3['timelast']\n",
    "    df3['last_in_window'] = (df3.timestart_diff > pd.Timedelta(minutes = 9)) & (df3.timestart_diff2 > pd.Timedelta(minutes = 3))    \n",
    "    df3 = df3[((df3.timestart_diff > pd.Timedelta(minutes = 9)) & (df3.timestart_diff2 > pd.Timedelta(minutes = 3))) | df3.timestart_diff.isnull()] \n",
    "    return df3 \n",
    "\n",
    "def write_headers(filetype,csvoutfile, approot, J1_header):\n",
    "    with open(os.path.join(approot,csvoutfile), 'wb') as csvfile:\n",
    "        wr = csv.writer(csvfile, quoting=csv.QUOTE_ALL)\n",
    "        if (filetype == \"packet\" or filetype == \"TOA_FOA_DATA\"): wr.writerow(J1_header)\n",
    "        elif filetype == 'status': wr.writerow(Statusfileheader)\n",
    "    return None\n",
    "def xml_process(filename, filetype, country= 'USA', beaconId = False):\n",
    "    packets = list()\n",
    "    if (filetype == 'packet' or filetype == 'TOA_FOA_DATA'):\n",
    "        for event, element in etree.iterparse(filename, tag='TOA_FOA_DATA'):\n",
    "            if country == 'Canada':\n",
    "                namespace = e.tag[1:].split(\"}\")[0]\n",
    "                packets = e.findall(\".//{%s}TOA_FOA_DATA\" % namespace)\n",
    "            elif beaconId:\n",
    "                for child in element:\n",
    "                    if child.tag == 'MF22' and child.text == beaconId: packets.append(element)\n",
    "            else:\n",
    "                packets = e.findall(\".//{}\".format(filetype))\n",
    "    else:\n",
    "        for i, item in ET1:\n",
    "            if (item.tag == 'solutionsMessage'):\n",
    "                packets = ET2\n",
    "    return packets\n",
    "#def find_str_in_tag(filename, searchtag, searchstr):\n",
    "#    packetlist = list()\n",
    "#    for event, element in etree.iterparse(filename, tag='TOA_FOA_DATA'):\n",
    "#        for child in element:\n",
    "#            if child.tag == searchtag and child.text == searchstr: packetlist.append(element)\n",
    "#    return packetlist\n",
    "\n",
    "def search_zip_output(MEOLUT, zip,zipmatches,filetypesearch,csvoutfile, approot, J1_header, country = 'USA', beaconId = False):\n",
    "    #open file and write headers which erases data in it\n",
    "    #write_headers_USSHARE(csvoutfile) - Need new Functions to write different headers other than USSHARE raw data\n",
    "    #if filetypesearch == 'packet': write_headers_USSHARE(csvoutfile)\n",
    "    write_headers(filetypesearch,csvoutfile, approot, J1_header)\n",
    "    with zipfile.ZipFile(zip, 'r') as myzip:\n",
    "        for files in zipmatches:\n",
    "            file = myzip.open(files)\n",
    "            filename = str(file)          \n",
    "            packets = xml_process(file,filetypesearch, country, beaconId)\n",
    "            if packets:\n",
    "                write_bursts_csv(packets,csvoutfile,filetypesearch, files, approot)\n",
    "def file_search_regex(filetypesearch, country):\n",
    "    if (filetypesearch == \"packet\" or filetypesearch == \"TOA_FOA_DATA\"):\n",
    "        if country == 'USA':\n",
    "            my_regex = r\"(.*)\"+ re.escape(\"USSHARE\") + r\"(.*)\"\n",
    "        if country == 'Canada':\n",
    "            my_regex = r\"(.*)\"+ re.escape(\"HGTMEO\") + r\"(.*)\"\n",
    "    else:\n",
    "        my_regex = r\"(.*)\"+ re.escape(\"USMCC\") + r\"(.*)\"\n",
    "    return my_regex\n",
    "def write_bursts_csv(packets,csvoutfile, filetypesearch, filename, approot, bcnId = False):\n",
    "    burst = list()\n",
    "    componentlist = list()\n",
    "    with open(os.path.join(approot,csvoutfile), 'ab') as csvfile:\n",
    "        csvoutwriter = csv.writer(csvfile, delimiter=',',\n",
    "                                quoting=csv.QUOTE_MINIMAL)\n",
    "        if (filetypesearch == \"packet\" or filetypesearch == \"TOA_FOA_DATA\"):   \n",
    "            for packet in packets:\n",
    "                for MF in packet:\n",
    "                    burst.append(MF.text)\n",
    "                TOA = datetime.strptime(burst[6],datetime_format)\n",
    "                newrow = [0, burst[4], burst[3], TOA, burst[7], burst[9],TOA,burst[8],burst[10],burst[11],burst[2],burst[0],burst[1],burst[5]]\n",
    "                csvoutwriter.writerow(newrow)\n",
    "                burst=list()\n",
    "# Return list of files of in zip file matching searchstring\n",
    "def find_file_inzip(zipfilename,searchstring):\n",
    "    with zipfile.ZipFile(zipfilename, 'r') as myzip:\n",
    "        ziplist = myzip.namelist()\n",
    "        matches = [string for string in ziplist if re.match(searchstring, string)]\n",
    "        print 'num of files in ' + zipfilename + ' = ' + str(len(ziplist))\n",
    "        print 'returning ' + str(len(matches)) + ' files in zip with search string ' + searchstring \n",
    "        return matches\n",
    "\n",
    "def find_packets(servername= 'localhost', databasename='MccTestLGM', beaconid = '%', start_date = 0, end_date = None, MEOLUT = '%',ant_i = '%', sat = '%', **kwargs):\n",
    "    if 'sql_login' in kwargs:\n",
    "        conn = odbc.connect(r'Driver={FreeTDS};Server='+servername+';Database='+databasename+'; UID='+UID+'; PWD=' + PWD, readonly=True, autocommit=True)\n",
    "    else:\n",
    "        conn = odbc.connect(r'Driver={SQL Server}; Server='+servername+'; Database='+databasename+'; Trusted_Connection=yes',readonly=True, autocommit=True)\n",
    "\tc = conn.cursor()\n",
    "    query_params = ['%'+beaconid+'%', MEOLUT, start_date, end_date, ant_i, sat]\n",
    "    sql_query = ('SELECT UplinkTOADate, UplinkFOA from MeolutPackets '\n",
    "\t\t'WHERE '\n",
    "\t\t'BcnId15 like ? '\n",
    "\t\t'AND '\n",
    "\t\t'MeolutId like ? '\n",
    "\t\t'AND ' \n",
    "\t\t'AddTime between ? AND ? '\n",
    "\t\t'AND '\n",
    "\t\t'AntennaId like ? '\n",
    "\t\t'AND '\n",
    "\t\t'SatId like ? ' )\n",
    "    c.execute(sql_query, query_params)\n",
    "    packets = c.fetchall()\n",
    "    return packets\n",
    "\n",
    "def plot_packets(packets, MEOLUT, ant_i,start_time,end_time, packets_found, percent_packets):\n",
    "    global ax1\n",
    "    frequencylist = list()\n",
    "    timelist = list()\n",
    "    velolist = list() \n",
    "    for packet in packets:\n",
    "        frequencylist.append(packet[1])\n",
    "        timelist.append(packet[0])\n",
    "        #timelist.append(datetime.strptime(packet[12],timepacket_format))\n",
    "    #if timelist:\n",
    "    #    mintime = min(timelist)\n",
    "    #    maxtime = max(timelist)\n",
    "    #else:\n",
    "    #alt = [np.linalg.norm(x) for x in posilist]    \n",
    "    #rangelist = [np.linalg.norm(MEOLUTLocDict[MEOLUT] - x) for x in posilist]\n",
    "    #plotting TLE positional difference below\n",
    "    #fig, ax = plt.subplots()\n",
    "    #ax.plot_date(timelist, frequencylist, '-')\n",
    "    #font = {'family' : 'normal',\n",
    "            #'weight' : 'bold',\n",
    "            #'size'   : 22}\n",
    "    #matplotlib.rc('font', **font)\n",
    "    plt.figure(MEOLUT, figsize=(40,20))\n",
    "    if ant_i == ant_list[0]:\n",
    "        ax1 = plt.subplot(len(ant_list),1,1)\n",
    "    else:\n",
    "        plt.subplot(len(ant_list),1,ant_list.index(ant_i)+1, sharex = ax1, sharey = ax1)\n",
    "    \n",
    "    plt.plot(timelist, frequencylist,'ro')\n",
    "    plt.title('{} - antenna {} -- {} packets = {:.1f}%'.format(MEOLUT,ant_i,packets_found,percent_packets))\n",
    "    #plt.title('{} - antenna {} ---- {} packets'.format(MEOLUT,ant_i,packets_found)) #,percent_packets))\n",
    "    plt.grid(True)\n",
    "    #plt.gca().xaxis.set_major_locator(Hours)\n",
    "    plt.gca().xaxis.set_major_formatter(plot_fmt)\n",
    "    #plt.gca().xaxis.set_minor_locator(FiveMinutes)\n",
    "    plt.gca().set_xlim(start_time,end_time)\n",
    "\n",
    "def xlx_analysis(UPLOADFILE, OUTPUTFOLDER, MEOLUT, TimeStart, TimeEnd, result, Lat_GT=0, Long_GT=0, Location='', **kwargs):\n",
    "    # need to add approot to any place a file is written if this will be functional on apache \n",
    "    # - done 7/12/17 in routes.py, UPLOADFILE is now full path - change may be needed in over functions \n",
    "    InputMEO_excelfile = UPLOADFILE\n",
    "    CSVoutfolder = OUTPUTFOLDER\n",
    "    BeaconID = result['beaconID']\n",
    "    if ('Lat' in kwargs): \n",
    "        Lat_GT = kwargs['Lat']\n",
    "    else: \n",
    "        Lat_GT = None\n",
    "    if ('Long' in kwargs): \n",
    "        Long_GT = kwargs['Long']\n",
    "        MEO_dist = haversine([Lat_GT,Long_GT,MEOLUTLoc[MEOLUT][0],MEOLUTLoc[MEOLUT][1]])\n",
    "    else: \n",
    "        Long_GT = None\n",
    "        MEO_dist = 'NA'\n",
    "    df = pd.read_excel(InputMEO_excelfile, index_col = 'TimeSolutionAdded') #, parse_dates = True) #, parse_cols =  data_cols) #parse_dates = True,\n",
    "    df['TimeFirst']=pd.to_datetime(df['TimeFirst'], errors = 'ignore') ### FIX THIS WHEN TimeFirst is already a datetime.time 12/9 \n",
    "    df['TimeLast']=pd.to_datetime(df['TimeLast'], errors = 'ignore')\n",
    "    df['TimeSolutionGenerated']=pd.to_datetime(df['TimeSolutionGenerated'], errors = 'ignore')\n",
    "    #df['TimeSolutionAdded']=pd.to_datetime(df['TimeSolutionAdded'])\n",
    "\n",
    "    #df['DataType'] = df['DataType']\n",
    "    #df.set_index(df['TimeSolutionAdded'],inplace = True)\n",
    "    #df = df.drop(['BcnId36','FbiasDev', 'FreqDrift','SitFunc','MsgNum','QualityIndicator','NumAntennas','Srr', \\\n",
    "        #'PositionConfFlag','SortId','SortType','Distance'], axis = 1) -- No longer needed if I just slice into sub table\n",
    "    #df.sort_values('TimeSolutionAdded').head()\n",
    "\n",
    "    df2 = df[['DataType','BcnId15','BcnId30','SourceId','TimeFirst','TimeLast','Latitude',\n",
    "        'Longitude','Altitude','NumBursts','NumPackets','DOP','ExpectedHorzError']]\n",
    "    df2.index = df2.index.map(str.lower)\n",
    "    df2 = df2.sort_index().ix[TimeStart:TimeEnd]\n",
    "    df3 = df2[(df2.bcnid15 == BeaconID)]\n",
    "    dfSB = df3[(df3.datatype == 3)] \n",
    "    dfMB = df3[(df3.datatype == 0)] \n",
    "    if df3.empty: \n",
    "        print \"Data Frame is empty after filtering out Beacon ID = \" + BeaconID\n",
    "\n",
    "    lat_fun = lambda hexin: bcn.beacon(hexin).lat\n",
    "    lon_fun = lambda hexin: bcn.beacon(hexin).lon\n",
    "    dfSB['Enc_Lat'] = dfSB['bcnid30'].apply(lat_fun)\n",
    "    dfSB['Enc_Lon'] = dfSB['bcnid30'].apply(lon_fun)\n",
    "    dfMB['Enc_Lat'] = dfMB['bcnid30'].apply(lat_fun)\n",
    "    dfMB['Enc_Lon'] = dfMB['bcnid30'].apply(lon_fun)\n",
    "\n",
    "    df_SBL = singleburst_loc(dfSB,Lat_GT,Long_GT,MEOLUT)\n",
    "    SBL = len(df_SBL)\n",
    "    df5 = df_SBL[df_SBL.Error_GT < 5] if not df_SBL.empty else df_SBL\n",
    "    df5_enc = df_SBL[df_SBL.Error_Enc < 5] if not df_SBL.empty else df_SBL\n",
    "    df10 = df_SBL[df_SBL.Error_GT < 10] if not df_SBL.empty else df_SBL\n",
    "    df10_enc = df_SBL[df_SBL.Error_Enc < 10] if not df_SBL.empty else df_SBL\n",
    "    df20_enc = df_SBL[df_SBL.Error_Enc < 20] if not df_SBL.empty else df_SBL\n",
    "\n",
    "    timefirst = df3.TimeFirst.min()\n",
    "    timelast = df3.TimeLast.max()\n",
    "    timediff = timelast - timefirst\n",
    "\n",
    "    SBL_5 = len(df5)\n",
    "    SBL_5_enc = len(df5_enc)\n",
    "    SBL_10 = len(df10)\n",
    "    SBL_10_enc = len(df10_enc)\n",
    "    SBL_20_enc = len(df20_enc)\n",
    "\n",
    "    error_SBL = df_SBL.Error_GT if not df_SBL.empty else df_SBL # not used currently\n",
    "\n",
    "    expected_bursts = int(timediff/pd.Timedelta(seconds = 50))\n",
    "    prob_SBL = float(SBL)/expected_bursts if expected_bursts != 0 else 0\n",
    "    prob_SBL_5 =float(SBL_5)/SBL if SBL !=0 else 0\n",
    "    prob_SBL_5_enc =float(SBL_5_enc)/SBL if SBL !=0 else 0\n",
    "    prob_SBL_10 = float(SBL_10)/SBL if SBL !=0 else 0\n",
    "    prob_SBL_10_enc = float(SBL_10_enc)/SBL if SBL !=0 else 0\n",
    "    prob_SBL_20_enc = float(SBL_20_enc)/SBL if SBL !=0 else 0\n",
    "\n",
    "    #print 'Analysis of MEOLUT -> {} - {}'.format(MEOLUTName[MEOLUT],MEOLUT)\n",
    "    #print '\\n Beacon Ground Truth Location used = {}, {}'.format(Lat_GT,Long_GT)\n",
    "    #print ' Distance from MEOLUT = {:.1f} km'.format(haversine([Lat_GT,Long_GT,MEOLUTLoc[MEOLUT][0],MEOLUTLoc[MEOLUT][1]]))\n",
    "    ##print ' Distance from MEOLUT = {:.1f} km'.format(haversine([Lat_GT,Long_GT,MEOlat,MEOlon]))\n",
    "    #print ' Time of first burst = {:%Y-%m-%d %H:%M:%S}'.format(timefirst)\n",
    "    #print ' Time of Last burst = {:%Y-%m-%d %H:%M:%S}'.format(timelast)\n",
    "    #print ' Time Span = {}'.format(timediff)\n",
    "\n",
    "    #print '\\nSINGLE BURST ANALYSIS'\n",
    "    #print 'Expected single burst locations = {}'.format(expected_bursts)\n",
    "    #print '\\n'\n",
    "    #print 'Number of single burst locations = {}'.format(SBL)\n",
    "    #print 'Probability of single burst location = {:.2%}'.format(prob_SBL)\n",
    "    #print '\\n'\n",
    "    #print 'Number of single burst locations within 5 km = {}'.format(SBL_5)\n",
    "    #print 'Percent of single burst locations within 5 km = {:.2%}'.format(prob_SBL_5)\n",
    "    #print 'Number of single burst locations within 5 km (vs Encoded Location) = {}'.format(SBL_5_enc)\n",
    "    #print 'Percent of single burst locations within 5 km (vs Encoded Location) = {:.2%}'.format(prob_SBL_5_enc)\n",
    "    #print '\\n'\n",
    "    #print 'Number of single burst locations within 10 km = {}'.format(SBL_10)\n",
    "    #print 'Percent of single burst locations within 10 km = {:.2%}'.format(prob_SBL_10)\n",
    "    #print 'Number of single burst locations within 10 km (vs Encoded Location) = {}'.format(SBL_10_enc)\n",
    "    #print 'Percent of single burst locations within 10 km (vs Encoded Location) = {:.2%}'.format(prob_SBL_10_enc)\n",
    "    #print '\\n'\n",
    "    #print 'Number of single burst locations within 20 km (vs Encoded Location) = {}'.format(SBL_20_enc)\n",
    "    #print 'Percent of single burst locations within 20 km (vs Encoded Location) = {:.2%}'.format(prob_SBL_20_enc)\n",
    "\n",
    "    ## Multi Burst (Windowed) Section\n",
    "    window_time = 20 #minutes - no longer used since now just look for change in TimeFirst\n",
    "    window_span = pd.Timedelta(minutes = window_time)\n",
    "    expected_windows = math.ceil(timediff/window_span)\n",
    "\n",
    "    df_MBL = multiburst_loc(dfMB, Lat_GT, Long_GT, MEOLUT, window_span)\n",
    "    df_MBL5 = df_MBL[df_MBL.Error_GT < 5] if not df_MBL.empty else df_MBL\n",
    "    df_MBL5_enc = df_MBL[df_MBL.Error_Enc < 5] if not df_MBL.empty else df_MBL\n",
    "    df_MBL10 = df_MBL[df_MBL.Error_GT < 10] if not df_MBL.empty else df_MBL\n",
    "    df_MBL10_enc = df_MBL[df_MBL.Error_Enc < 10] if not df_MBL.empty else df_MBL\n",
    "    df_MBL20_enc = df_MBL[df_MBL.Error_Enc < 20] if not df_MBL.empty else df_MBL\n",
    "\n",
    "    MBL = len(df_MBL)\n",
    "    MBL_5 = len(df_MBL5)\n",
    "    MBL_5_enc = len(df_MBL5_enc)\n",
    "    MBL_10 = len(df_MBL10)\n",
    "    MBL_10_enc = len(df_MBL10_enc)\n",
    "    MBL_20_enc = len(df_MBL20_enc)\n",
    "\n",
    "    error_MBL = df_MBL.Error_GT if not df_MBL.empty else df_MBL # not used currently\n",
    "\n",
    "    prob_MBL = float(MBL)/expected_windows if expected_windows != 0 else 0\n",
    "    prob_MBL_5 =float(MBL_5)/MBL if MBL !=0 else 0\n",
    "    prob_MBL_5_enc =float(MBL_5_enc)/MBL if MBL !=0 else 0\n",
    "    prob_MBL_10 = float(MBL_10)/MBL if MBL !=0 else 0\n",
    "    prob_MBL_10_enc = float(MBL_10_enc)/MBL if MBL !=0 else 0\n",
    "    prob_MBL_20_enc = float(MBL_20_enc)/MBL if MBL !=0 else 0\n",
    "\n",
    "    #print '\\n\\nMULTIPLE BURST ANALYSIS'\n",
    "    #print 'Multiple Burst (windowed) locations, Window = {}'.format(window_span)\n",
    "    #print 'Expected number of windows = {}'.format(int(expected_windows))\n",
    "    #print '\\n'\n",
    "    #print 'Number of windowed locations = {}'.format(MBL)\n",
    "    #print 'Probability of windowed location = {:.2%}'.format(prob_MBL)\n",
    "    #print '\\n'\n",
    "    #print 'Number of windowed locations within 5 km = {}'.format(MBL_5)\n",
    "    #print 'Percent of windowed locations within 5 km = {:.2%}'.format(prob_MBL_5)\n",
    "    #print 'Number of windowed locations within 5 km (vs Encoded Location) = {}'.format(MBL_5_enc)\n",
    "    #print 'Percent of windowed locations within 5 km (vs Encoded Location) = {:.2%}'.format(prob_MBL_5_enc)\n",
    "    #print '\\n'\n",
    "    #print 'Number of windowed locations within 10 km = {}'.format(MBL_10)\n",
    "    #print 'Percent of windowed locations within 10 km = {:.2%}'.format(prob_MBL_10)\n",
    "    #print 'Number of windowed locations within 10 km (vs Encoded Location) = {}'.format(MBL_10_enc)\n",
    "    #print 'Percent of windowed locations within 10 km (vs Encoded Location) = {:.2%}'.format(prob_MBL_10_enc)\n",
    "    #print '\\n'\n",
    "    #print 'Number of windowed locations within 20 km (vs Encoded Location) = {}'.format(MBL_20_enc)\n",
    "    #print 'Percent of windowed locations within 20 km (vs Encoded Location) = {:.2%}'.format(prob_MBL_20_enc)\n",
    "\n",
    "    outfilelist = list()\n",
    "    outfiletag = '{}_{}_{:%Y-%m-%d-%H%M}_{:%Y-%m-%d-%H%M}'.format(MEOLUT,BeaconID,TimeStart,TimeEnd)\n",
    "    SBLfile = OUTPUTFOLDER + '\\SBL'+outfiletag +'.csv'\n",
    "    MBLfile = OUTPUTFOLDER + '\\MBL'+outfiletag +'.csv'\n",
    "    OUTfile = OUTPUTFOLDER + '\\OUT' + outfiletag +'.csv'\n",
    "    df_SBL.to_csv(SBLfile)\n",
    "    df_MBL.to_csv(MBLfile)\n",
    "    outfilelist.append(SBLfile)\n",
    "    outfilelist.append(MBLfile)\n",
    "    outfilelist.append(OUTfile)\n",
    "    \n",
    "    with open(OUTfile, 'wb') as csvfile:\n",
    "        csvoutwriter = csv.writer(csvfile, delimiter=',',\n",
    "                                quoting=csv.QUOTE_MINIMAL)\n",
    "        csvoutwriter.writerow(['MEOLUT', MEOLUTName[MEOLUT]])\n",
    "        csvoutwriter.writerow(['MEOLUT_ID', MEOLUT])\n",
    "        csvoutwriter.writerow(['BeaconID',BeaconID])\n",
    "        csvoutwriter.writerow(['Location',Location])\n",
    "        csvoutwriter.writerow(['TimeStart',TimeStart])\n",
    "        csvoutwriter.writerow(['TimeEnd',TimeEnd])\n",
    "        csvoutwriter.writerow([])\n",
    "        csvoutwriter.writerow(['Ground Truth Lat',Lat_GT])\n",
    "        csvoutwriter.writerow(['Ground Truth Long',Long_GT])\n",
    "        csvoutwriter.writerow(['Distance From MEOLUT',MEO_dist]) #'{:.2f}'.format(MEO_dist)])\n",
    "        csvoutwriter.writerow([])\n",
    "        csvoutwriter.writerow(['Time First Burst','{:%Y-%m-%d %H:%M:%S}'.format(timefirst)])    \n",
    "        csvoutwriter.writerow(['Time Last Burst', '{:%Y-%m-%d %H:%M:%S}'.format(timelast)])\n",
    "        csvoutwriter.writerow(['Time Span', timediff])\n",
    "        csvoutwriter.writerow([])\n",
    "        csvoutwriter.writerow(['SINGLE BURST LOCATIONS'])\n",
    "        csvoutwriter.writerow(['ExpSBL',expected_bursts])\n",
    "        csvoutwriter.writerow(['NumSBL',SBL])\n",
    "        csvoutwriter.writerow(['ProbSBL','{:.2%}'.format(prob_SBL)])\n",
    "        csvoutwriter.writerow([])\n",
    "        csvoutwriter.writerow(['NumSBL <5km', SBL_5])\n",
    "        csvoutwriter.writerow(['% SBL <5km', '{:.2%}'.format(prob_SBL_5)])\n",
    "        csvoutwriter.writerow([])\n",
    "        csvoutwriter.writerow(['NumSBL <10km', SBL_10])\n",
    "        csvoutwriter.writerow(['% SBL <10km', '{:.2%}'.format(prob_SBL_10)])\n",
    "        csvoutwriter.writerow([])\n",
    "        csvoutwriter.writerow(['NumSBL <5km (vs Enc)', SBL_5_enc])\n",
    "        csvoutwriter.writerow(['% SBL <5km (vs Enc)', '{:.2%}'.format(prob_SBL_5_enc)])\n",
    "        csvoutwriter.writerow([])\n",
    "        csvoutwriter.writerow(['NumSBL <10km (vs Enc)', SBL_10_enc])\n",
    "        csvoutwriter.writerow(['% SBL <10km (vs Enc)', '{:.2%}'.format(prob_SBL_10_enc)])\n",
    "        csvoutwriter.writerow([])\n",
    "        csvoutwriter.writerow(['NumSBL <20km (vs Enc)', SBL_20_enc])\n",
    "        csvoutwriter.writerow(['% SBL <20km (vs Enc)', '{:.2%}'.format(prob_SBL_20_enc)])\n",
    "        csvoutwriter.writerow([])\n",
    "        csvoutwriter.writerow(['MULTIPLE BURST LOCATIONS'])\n",
    "        csvoutwriter.writerow(['Window Period', window_span])\n",
    "        csvoutwriter.writerow(['ExpMBL',expected_windows])\n",
    "        csvoutwriter.writerow(['NumMBL',MBL])\n",
    "        csvoutwriter.writerow(['ProbMBL','{:.2%}'.format(prob_MBL)])\n",
    "        csvoutwriter.writerow([])\n",
    "        csvoutwriter.writerow(['NumMBL <5km', MBL_5])\n",
    "        csvoutwriter.writerow(['% MBL <5km', '{:.2%}'.format(prob_MBL_5)])\n",
    "        csvoutwriter.writerow([])\n",
    "        csvoutwriter.writerow(['NumMBL <10km', MBL_10])\n",
    "        csvoutwriter.writerow(['% MBL <10km','{:.2%}'.format(prob_MBL_10)])\n",
    "        csvoutwriter.writerow([])\n",
    "        csvoutwriter.writerow(['NumMBL <5km (vs Enc)', MBL_5_enc])\n",
    "        csvoutwriter.writerow(['% MBL <5km (vs Enc)', '{:.2%}'.format(prob_MBL_5_enc)])\n",
    "        csvoutwriter.writerow([])\n",
    "        csvoutwriter.writerow(['NumMBL <10km (vs Enc)', MBL_10_enc])\n",
    "        csvoutwriter.writerow(['% MBL <10km (vs Enc)','{:.2%}'.format(prob_MBL_10_enc)])\n",
    "        csvoutwriter.writerow([])\n",
    "        csvoutwriter.writerow(['NumMBL <20km (vs Enc)', MBL_20_enc])\n",
    "        csvoutwriter.writerow(['% MBL <20km (vs Enc)','{:.2%}'.format(prob_MBL_20_enc)])\n",
    "\n",
    "    if 'KMLgen' in result:\n",
    "        kml = simplekml.Kml()\n",
    "        KMLfile = OUTPUTFOLDER + '\\KML' + outfiletag +'.kml'\n",
    "        #print '\\nCreating KML file - ' + KMLfile\n",
    "        if 'SingleBurstGen' in result:\n",
    "            #print 'Writing Single Burst Locations to KML' \n",
    "            with open(SBLfile, 'rb') as csvfile:\n",
    "                csvfile.next()\n",
    "                filereader = csv.reader(csvfile)\n",
    "                folSBL = kml.newfolder(name='Single Burst Locations - '+ str(MEOLUT))\n",
    "                folEnc = kml.newfolder(name = 'Encoded Locations - '+ str(MEOLUT))\n",
    "                for row in filereader:            \n",
    "                    pntSBL = folSBL.newpoint(coords=[(float(row[8]),float(row[7]),float(row[9]))], \n",
    "                        description = 'Single Burst Solution \\nBeacon = ' + row[2] + '\\n\\nTimeSolutionAdded = ' + row[0] + '\\nTimeFirst = ' +row[5] + '\\nTimeLast = ' +row[6] + \n",
    "                        '\\nMEOLUT = ' + row[4] + '\\nGT_Error = ' + row[16] + '\\nEnc_Error = ' + row[17] +\n",
    "                        '\\nNum of Bursts = ' + row[10] + '\\nNum of Packets = ' +row[11] +'\\nDOP = ' + row[12] + \n",
    "                        '\\nEHE = ' + row[13]\n",
    "                        )\n",
    "                    # name=str(row[0][11:19])\n",
    "                    pntSBL.timespan.begin = row[0][:10] + 'T' + row[0][11:19]\n",
    "                    pntSBL.style.iconstyle.icon.href = icon_list['white_dot']\n",
    "        if 'EncLocGen' in result:\n",
    "            #print 'Writing Encoded Locations to KML'\n",
    "            with open(SBLfile, 'rb') as csvfile:\n",
    "                csvfile.next()\n",
    "                filereader = csv.reader(csvfile)\n",
    "                folEnc = kml.newfolder(name = 'Encoded Locations - '+ str(MEOLUT))                \n",
    "                for row in filereader:\n",
    "                    if row[17] <> '':  \n",
    "                        pntEnc = folEnc.newpoint(coords=[(float(row[15]),float(row[14]))], \n",
    "                            description = 'Encoded Location - Beacon = ' + row[2] + '\\n\\nTimeSolutionAdded = ' + row[0] + '\\nLat,Long = (' + row[14] + ', ' +row[15] + ')'  \n",
    "                            )\n",
    "                        pntEnc.timespan.begin = row[0][:10] + 'T' + row[0][11:19]\n",
    "                        pntEnc.style.iconstyle.icon.href = icon_list['little_E']\n",
    "                        pntEnc.style.iconstyle.scale = 0.8\n",
    "                        pntEnc.style.labelstyle.color = '00ff0000'  # Red\n",
    "                    #pnt.snippet.content = 'this is content'\n",
    "                    #print row[0],row[7],row[8]\n",
    "        with open(MBLfile, 'rb') as csvfile:\n",
    "            csvfile.next()\n",
    "            filereader = csv.reader(csvfile)\n",
    "            folMBL = kml.newfolder(name='Multi Burst Locations - '+ str(MEOLUT))\n",
    "            for row in filereader:            \n",
    "                pntMBL = folMBL.newpoint(coords=[(float(row[8]),float(row[7]),float(row[9]))], \n",
    "                    description = 'Multi Burst Location - Beacon = ' + row[2] + '\\n\\nTimeSolutionAdded = ' + row[0] + '\\nTimeFirst = ' +row[5] + '\\nTimeLast = ' +row[6] + \n",
    "                    '\\nMEOLUT = ' + row[4] + '\\nGT_Error = ' + row[16] + '\\nEnc_Error = ' + row[17] + \n",
    "                    '\\nNum of Bursts = ' + row[10] + '\\nNum of Packets = ' +row[11] +'\\nDOP = ' + row[12] + \n",
    "                    '\\nEHE = ' + row[13]\n",
    "                    )\n",
    "                pntMBL.timespan.begin = row[0][:10] + 'T' + row[0][11:19]\n",
    "                pntMBL.style.iconstyle.icon.href = icon_list['little_M']\n",
    "                pntMBL.style.labelstyle.color = 'ff0000ff'  # Red\n",
    "                #pnt.snippet.content = 'this is content'\n",
    "                #print row[0],row[7],row[8]\n",
    "    \n",
    "\n",
    "    \n",
    "    if 'LEOgen' in result:\n",
    "        LEOinputfile = UPLOADFOLDER +'\\\\' + kwargs['LEOGEO_file']\n",
    "        #print 'Reading LEO file - ' + LEOinputfile\n",
    "        #print 'Writing LEO bursts to KML'\n",
    "        LEOoutfile = OUTPUTFOLDER + '\\LEO' + outfiletag + '.csv'\n",
    "        df = pd.read_excel(LEOinputfile, index_col = 'AddTime') #, parse_dates = True)\n",
    "        df = df[(df.BcnId15 == BeaconID)]\n",
    "        if df.empty: \n",
    "            print(LEOinputfile + ' - did not contain any data that matched')    \n",
    "        else:\n",
    "            dfLEO = df[df.Orbit.notnull()]\n",
    "            dfLEO_loc = dfLEO[dfLEO.A_Lat.notnull()]\n",
    "            dfLEO_loc.to_csv(LEOoutfile)\n",
    "            with open(LEOoutfile, 'rb') as csvfile:\n",
    "                filereader = csv.reader(csvfile)\n",
    "                csvfile.next()\n",
    "                fol_LEO = kml.newfolder(name='LEO Locations - '+ str(MEOLUT))\n",
    "                for row in filereader:            \n",
    "                    pnt_LEO = fol_LEO.newpoint(coords=[(float(row[22]),float(row[21]))], \n",
    "                        description = 'LEO Location \\nBeacon = ' + row[15] + '\\n\\nA_Tca = ' + row[23] + '\\nMCCTime = ' + row[0] + '\\n\\nLUT = ' + row[2] + '\\nSat = ' + row[3] +\n",
    "                        '\\nOrbit = ' + str(int(float(row[4]))) + '\\n\\nNominal = ' + row[73] +  \n",
    "                        '\\nNum of Points = ' +row[18] + '\\nA_Cta =' + row[24] + '\\nA_prob = ' +row[17] + '\\nSolId = ' + row[1]  \n",
    "                        )   \n",
    "                    pnt_LEO.timespan.begin = row[0][:10] + 'T' + row[0][11:19]\n",
    "                    pnt_LEO.style.iconstyle.icon.href = icon_list['little_L']\n",
    "                    #pnt_LEO.style.iconstyle.icon.href = 'file://C:/Users/Jesse/Documents/Programming/Python/MEO_Input_Processor/MEO_Input_Processor_v2_w_KML/icon35.png'\n",
    "                    pnt_LEO.style.iconstyle.scale = 0.7\n",
    "                    pnt_LEO.style.labelstyle.color = 'ffff0000'  # Red\n",
    "\n",
    "    kml.save(CSVoutfolder + '\\KML_' + csvoutfilename + '.kml')\n",
    "\n",
    "def parse_results(result, MEOList): \n",
    "    if result.get('Location', False): \n",
    "        Location = result['Location']\n",
    "    else: Location = 'NA'\n",
    "    if result.get('UseBeaconID') == \"UseRefBeacon\": \n",
    "        BeaconID = ReferenceBeacons[result.get(\"refbeacon\")]['beaconId']\n",
    "        BeaconQuery = BeaconID\n",
    "        Lat_GT = ReferenceBeacons[result.get(\"refbeacon\")]['beaconLat']\n",
    "        Long_GT = ReferenceBeacons[result.get(\"refbeacon\")]['beaconLon']\n",
    "        Location = result.get(\"refbeacon\")\n",
    "    else:\n",
    "        if result.get('beaconID', False):\n",
    "            BeaconID = result['beaconID']\n",
    "            BeaconQuery = '%' + BeaconID +'%' \n",
    "        else:\n",
    "            BeaconID = 'All'\n",
    "            BeaconQuery = '%'\n",
    "            \n",
    "        if 'beaconLat' in result and result['beaconLat'] <> '':\n",
    "            Lat_GT = float(result['beaconLat'])\n",
    "        if 'beaconLon' in result and result['beaconLon'] <> '':\n",
    "            Long_GT = float(result['beaconLon'])\n",
    "        else: \n",
    "            Lat_GT = None\n",
    "            Long_GT = None\n",
    "\n",
    "    \n",
    "    MEO_dist = []\n",
    "    for MEO in MEOList:\n",
    "        MEO_dist.append(haversine([Lat_GT,Long_GT,MEOLUTLoc[MEO][0],MEOLUTLoc[MEO][1]]))\n",
    "\n",
    "    return BeaconQuery, BeaconID, Lat_GT, Long_GT, Location, MEO_dist\n",
    "\n",
    "def MSSQL_analysis(result, MEOLUTList, TimeStart, TimeEnd, config_dict=False, Lat_GT=0, Long_GT=0, Location='', **kwargs):\n",
    "    OUTPUTFOLDER, approot, servername, databasename =  config_dict[\"OUTPUTFOLDER\"], config_dict[\"approot\"], config_dict[\"servername\"], config_dict[\"oppsdatabase\"]\n",
    "    if 'sql_login' in kwargs:\n",
    "        conn = odbc.connect(r'Driver={FreeTDS};Server='+servername+';Database='+databasename+'; UID='+UID+'; PWD=' + PWD, autocommit=True)\n",
    "    else:\n",
    "        conn = odbc.connect(r'Driver={SQL Server};Server='+servername+';Database='+databasename+';Trusted_Connection=yes;',readonly=True, autocommit=True)\n",
    "    if MEOLUTList==None: MEOLUTList = MEOList\n",
    "    BeaconQuery, BeaconID, Lat_GT, Long_GT, Location, MEO_dist = parse_results(result,MEOLUTList)\n",
    "    sql_query = ('SELECT * FROM '\n",
    "                    'InputMEOSolution ' \n",
    "                    'WHERE ' \n",
    "                    'TimeSolutionGenerated between ? AND ? '\n",
    "                    'AND '\n",
    "                    'BcnId15 LIKE ? '\n",
    "                    )\n",
    "    params=[TimeStart, TimeEnd, BeaconQuery]\n",
    "\n",
    "    df = pd.read_sql_query(sql_query,conn, index_col = 'timesolutionadded', params=params)\n",
    "    df_data = []\n",
    "    for MEO in MEOLUTList:\n",
    "        df_data.append(filter1(df,'sourceid',MEO))\n",
    "    dfMEO = pd.concat(df_data)\n",
    "    if len(MEOLUTList) > 1:\n",
    "        MEOLUT = None\n",
    "        MEOStr = \", \".join([str(MEO) for MEO in MEOList])\n",
    "    else: \n",
    "        MEOLUT = MEOList[0]\n",
    "        MEOStr = MEOLUTName[MEOLUT]\n",
    "\n",
    "    #    parse_dates=['timefirst','timelast', 'timesolutiongenerated','timesolutionadded'])\n",
    "    #df = pd.DataFrame(cursor.fetchall())\n",
    "    #df.columns = pd.DataFrame(np.matrix(cursor.description))[0]\n",
    "    df2 = dfMEO[['datatype','bcnid15','bcnid30','sourceid','timefirst','timelast','latitude',\n",
    "        'longitude','altitude','numbursts','numpackets','dop','expectedhorzerror']]\n",
    "    df3 = df2.sort_index().ix[TimeStart:TimeEnd]\n",
    "    #df3 = df2[(df2.BcnId15 == BeaconID)]\n",
    "    dfSB = df3[(df3.datatype == 3)] \n",
    "    dfMB = df3[(df3.datatype == 0)] \n",
    "    if df3.empty: \n",
    "        print \"Data Frame is empty after filtering out Beacon ID = \" + BeaconID\n",
    "        return None, { 'MEOLUT': MEOLUT,\n",
    "                        'TimeStart': TimeStart,\n",
    "                        'TimeEnd': TimeEnd,\n",
    "                        'Beacon': BeaconQuery,\n",
    "                      }\n",
    "    \n",
    "    lat_fun = lambda hexin: bcn.beacon(hexin).lat\n",
    "    lon_fun = lambda hexin: bcn.beacon(hexin).lon\n",
    "    dfSB['Enc_Lat'] = dfSB['bcnid30'].apply(lat_fun)\n",
    "    dfSB['Enc_Lon'] = dfSB['bcnid30'].apply(lon_fun)\n",
    "    dfMB['Enc_Lat'] = dfMB['bcnid30'].apply(lat_fun)\n",
    "    dfMB['Enc_Lon'] = dfMB['bcnid30'].apply(lon_fun)\n",
    "    \n",
    "    df_SBL = singleburst_loc(dfSB,Lat_GT,Long_GT,MEOLUT)\n",
    "    SBL = len(df_SBL)\n",
    "    df5 = df_SBL[df_SBL.Error_GT < 5] if not df_SBL.empty else df_SBL\n",
    "    df5_enc = df_SBL[df_SBL.Error_Enc < 5] if not df_SBL.empty else df_SBL\n",
    "    df10 = df_SBL[df_SBL.Error_GT < 10] if not df_SBL.empty else df_SBL\n",
    "    df10_enc = df_SBL[df_SBL.Error_Enc < 10] if not df_SBL.empty else df_SBL\n",
    "    df20_enc = df_SBL[df_SBL.Error_Enc < 20] if not df_SBL.empty else df_SBL\n",
    "\n",
    "    timefirst = df3.timefirst.min()\n",
    "    timelast = df3.timelast.max()\n",
    "    timediff = timelast - timefirst\n",
    "\n",
    "    SBL_5 = len(df5)\n",
    "    SBL_5_enc = len(df5_enc)\n",
    "    SBL_10 = len(df10)\n",
    "    SBL_10_enc = len(df10_enc)\n",
    "    SBL_20_enc = len(df20_enc)\n",
    "\n",
    "    error_SBL = df_SBL.Error_GT if not df_SBL.empty else df_SBL # not used currently\n",
    "\n",
    "    expected_bursts = int(timediff/pd.Timedelta(seconds = 50))\n",
    "    prob_SBL = float(SBL)/expected_bursts if expected_bursts != 0 else 0\n",
    "    prob_SBL_5 =float(SBL_5)/SBL if SBL !=0 else 0\n",
    "    prob_SBL_5_enc =float(SBL_5_enc)/SBL if SBL !=0 else 0\n",
    "    prob_SBL_10 = float(SBL_10)/SBL if SBL !=0 else 0\n",
    "    prob_SBL_10_enc = float(SBL_10_enc)/SBL if SBL !=0 else 0\n",
    "    prob_SBL_20_enc = float(SBL_20_enc)/SBL if SBL !=0 else 0\n",
    "\n",
    "    ## Multi Burst (Windowed) Section\n",
    "    window_time = 20 #minutes - no longer used since now just look for change in TimeFirst\n",
    "    window_span = pd.Timedelta(minutes = window_time)\n",
    "    expected_windows = math.ceil(timediff/window_span)\n",
    "\n",
    "    df_MBL = multiburst_loc(dfMB, Lat_GT, Long_GT, MEOLUT, window_span)\n",
    "    df_MBL5 = df_MBL[df_MBL.Error_GT < 5] if not df_MBL.empty else df_MBL\n",
    "    df_MBL5_enc = df_MBL[df_MBL.Error_Enc < 5] if not df_MBL.empty else df_MBL\n",
    "    df_MBL10 = df_MBL[df_MBL.Error_GT < 10] if not df_MBL.empty else df_MBL\n",
    "    df_MBL10_enc = df_MBL[df_MBL.Error_Enc < 10] if not df_MBL.empty else df_MBL\n",
    "    df_MBL20_enc = df_MBL[df_MBL.Error_Enc < 20] if not df_MBL.empty else df_MBL\n",
    "\n",
    "    MBL = len(df_MBL)\n",
    "    MBL_5 = len(df_MBL5)\n",
    "    MBL_5_enc = len(df_MBL5_enc)\n",
    "    MBL_10 = len(df_MBL10)\n",
    "    MBL_10_enc = len(df_MBL10_enc)\n",
    "    MBL_20_enc = len(df_MBL20_enc)\n",
    "\n",
    "    error_MBL = df_MBL.Error_GT if not df_MBL.empty else df_MBL # not used currently\n",
    "\n",
    "    prob_MBL = float(MBL)/expected_windows if expected_windows != 0 else 0\n",
    "    prob_MBL_5 =float(MBL_5)/MBL if MBL !=0 else 0\n",
    "    prob_MBL_5_enc =float(MBL_5_enc)/MBL if MBL !=0 else 0\n",
    "    prob_MBL_10 = float(MBL_10)/MBL if MBL !=0 else 0\n",
    "    prob_MBL_10_enc = float(MBL_10_enc)/MBL if MBL !=0 else 0\n",
    "    prob_MBL_20_enc = float(MBL_20_enc)/MBL if MBL !=0 else 0\n",
    "    \n",
    "\n",
    "    outfiletag = '_{}_{:%Y-%m-%d-%H%M}_{:%Y-%m-%d-%H%M}'.format(BeaconID,TimeStart,TimeEnd)\n",
    "    SBLfile = os.path.join(OUTPUTFOLDER, 'SBL' + str(MEOLUT) + outfiletag +'.csv')\n",
    "    MBLfile = os.path.join(OUTPUTFOLDER, 'MBL' + str(MEOLUT) + outfiletag +'.csv')\n",
    "    OUTfile = os.path.join(OUTPUTFOLDER, 'OUT' + str(MEOLUT) + outfiletag +'.csv')\n",
    "    LEOGEO_file = os.path.join(OUTPUTFOLDER, 'LEO' + outfiletag + '.csv')\n",
    "    RCC_Output_file = os.path.join(OUTPUTFOLDER, 'RCC' + outfiletag + '.csv')\n",
    "    #outfilenamelist = list()\n",
    "    outfilelist = OrderedDict()\n",
    "    outfilelist[OUTfile] = 'Output Summary'\n",
    "    outfilelist[SBLfile] = 'Single Burst Solutions'\n",
    "    outfilelist[MBLfile] = 'Multi Burst Solutions'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    if 'KMLgen' in result: \n",
    "        KMLfile = os.path.join(OUTPUTFOLDER, 'KML' + outfiletag +'.kml')\n",
    "        Mapfile = os.path.join('/MapTest?KML=' + KMLfile).replace(\"\\\\\",\"/\")\n",
    "        outfilelist[KMLfile] = 'KML File Output'\n",
    "        outfilelist[Mapfile] = 'MapIt'\n",
    "    df_SBL.to_csv(os.path.join(approot,SBLfile))\n",
    "    df_MBL.to_csv(os.path.join(approot,MBLfile))\n",
    "    #OrderedDict(reversed(list(outfilelist.items())))\n",
    "    #outfilelist.append(SBLfile)\n",
    "    #outfilelist.append(MBLfile)\n",
    "    #outfilelist.append(OUTfile)\n",
    "\n",
    "\n",
    "    with open(os.path.join(approot,OUTfile), 'wb') as csvfile:\n",
    "        csvoutwriter = csv.writer(csvfile, delimiter=',',\n",
    "                                quoting=csv.QUOTE_MINIMAL)\n",
    "        csvoutwriter.writerow(['MEOLUT', MEOStr])\n",
    "        csvoutwriter.writerow(['MEOLUT_ID', MEOLUT])\n",
    "        csvoutwriter.writerow(['BeaconID',BeaconID])\n",
    "        csvoutwriter.writerow(['Location',Location])\n",
    "        csvoutwriter.writerow(['TimeStart',TimeStart])\n",
    "        csvoutwriter.writerow(['TimeEnd',TimeEnd])\n",
    "        csvoutwriter.writerow([])\n",
    "        csvoutwriter.writerow(['Ground Truth Lat',Lat_GT])\n",
    "        csvoutwriter.writerow(['Ground Truth Long',Long_GT])\n",
    "        csvoutwriter.writerow(['Distance From MEOLUT',MEO_dist]) #'{:.2f}'.format(MEO_dist)])\n",
    "        csvoutwriter.writerow([])\n",
    "        csvoutwriter.writerow(['Time First Burst','{:%Y-%m-%d %H:%M:%S}'.format(timefirst)])    \n",
    "        csvoutwriter.writerow(['Time Last Burst', '{:%Y-%m-%d %H:%M:%S}'.format(timelast)])\n",
    "        csvoutwriter.writerow(['Time Span', timediff])\n",
    "        csvoutwriter.writerow([])\n",
    "        csvoutwriter.writerow(['SINGLE BURST LOCATIONS'])\n",
    "        csvoutwriter.writerow(['ExpSBL',expected_bursts])\n",
    "        csvoutwriter.writerow(['NumSBL',SBL])\n",
    "        csvoutwriter.writerow(['ProbSBL','{:.2%}'.format(prob_SBL)])\n",
    "        csvoutwriter.writerow([])\n",
    "        csvoutwriter.writerow(['NumSBL <5km', SBL_5])\n",
    "        csvoutwriter.writerow(['% SBL <5km', '{:.2%}'.format(prob_SBL_5)])\n",
    "        csvoutwriter.writerow([])\n",
    "        csvoutwriter.writerow(['NumSBL <10km', SBL_10])\n",
    "        csvoutwriter.writerow(['% SBL <10km', '{:.2%}'.format(prob_SBL_10)])\n",
    "        csvoutwriter.writerow([])\n",
    "        csvoutwriter.writerow(['NumSBL <5km (vs Enc)', SBL_5_enc])\n",
    "        csvoutwriter.writerow(['% SBL <5km (vs Enc)', '{:.2%}'.format(prob_SBL_5_enc)])\n",
    "        csvoutwriter.writerow([])\n",
    "        csvoutwriter.writerow(['NumSBL <10km (vs Enc)', SBL_10_enc])\n",
    "        csvoutwriter.writerow(['% SBL <10km (vs Enc)', '{:.2%}'.format(prob_SBL_10_enc)])\n",
    "        csvoutwriter.writerow([])\n",
    "        csvoutwriter.writerow(['NumSBL <20km (vs Enc)', SBL_20_enc])\n",
    "        csvoutwriter.writerow(['% SBL <20km (vs Enc)', '{:.2%}'.format(prob_SBL_20_enc)])\n",
    "        csvoutwriter.writerow([])\n",
    "        csvoutwriter.writerow(['MULTIPLE BURST LOCATIONS'])\n",
    "        csvoutwriter.writerow(['Window Period', window_span])\n",
    "        csvoutwriter.writerow(['ExpMBL',expected_windows])\n",
    "        csvoutwriter.writerow(['NumMBL',MBL])\n",
    "        csvoutwriter.writerow(['ProbMBL','{:.2%}'.format(prob_MBL)])\n",
    "        csvoutwriter.writerow([])\n",
    "        csvoutwriter.writerow(['NumMBL <5km', MBL_5])\n",
    "        csvoutwriter.writerow(['% MBL <5km', '{:.2%}'.format(prob_MBL_5)])\n",
    "        csvoutwriter.writerow([])\n",
    "        csvoutwriter.writerow(['NumMBL <10km', MBL_10])\n",
    "        csvoutwriter.writerow(['% MBL <10km','{:.2%}'.format(prob_MBL_10)])\n",
    "        csvoutwriter.writerow([])\n",
    "        csvoutwriter.writerow(['NumMBL <5km (vs Enc)', MBL_5_enc])\n",
    "        csvoutwriter.writerow(['% MBL <5km (vs Enc)', '{:.2%}'.format(prob_MBL_5_enc)])\n",
    "        csvoutwriter.writerow([])\n",
    "        csvoutwriter.writerow(['NumMBL <10km (vs Enc)', MBL_10_enc])\n",
    "        csvoutwriter.writerow(['% MBL <10km (vs Enc)','{:.2%}'.format(prob_MBL_10_enc)])\n",
    "        csvoutwriter.writerow([])\n",
    "        csvoutwriter.writerow(['NumMBL <20km (vs Enc)', MBL_20_enc])\n",
    "        csvoutwriter.writerow(['% MBL <20km (vs Enc)','{:.2%}'.format(prob_MBL_20_enc)])\n",
    "\n",
    "    if 'KMLgen' in result:\n",
    "        #print '\\nCreating KML file'\n",
    "        kml = simplekml.Kml()\n",
    "        if Lat_GT <> 0:\n",
    "            firstrad = 5000\n",
    "            secondrad = 10000\n",
    "            folEnc = kml.newfolder(name = 'Ground Truth - '+ str(MEOLUT))                \n",
    "            polycircle1 = polycircles.Polycircle(latitude=Lat_GT,\n",
    "                                    longitude=Long_GT,\n",
    "                                    radius=firstrad,\n",
    "                                    number_of_vertices=36)            \n",
    "            pol1 = kml.newpolygon(name=\"5km\",\n",
    "                                         outerboundaryis=polycircle1.to_kml())\n",
    "            pol1.style.polystyle.color = \\\n",
    "                simplekml.Color.changealphaint(100, simplekml.Color.green)\n",
    "            # Second region\n",
    "\n",
    "            polycircle2outer = polycircles.Polycircle(latitude=Lat_GT,\n",
    "                                    longitude=Long_GT,\n",
    "                                    radius=secondrad,\n",
    "                                    number_of_vertices=36)            \n",
    "\n",
    "            pol2 = kml.newpolygon(name=\"10km\",\n",
    "                                         outerboundaryis=polycircle2outer.to_kml(),\n",
    "                                         innerboundaryis = polycircle1.to_kml())\n",
    "            pol2.style.polystyle.color = \\\n",
    "                simplekml.Color.changealphaint(100, simplekml.Color.yellow)\n",
    "            pntEnc = folEnc.newpoint(\n",
    "                name = 'Ground Truth',\n",
    "                coords=[(Long_GT,Lat_GT)], \n",
    "                description = 'Lat,Long = (' + str(Lat_GT) + ', ' + str(Long_GT) + ')'  \n",
    "                )\n",
    "            pntEnc.style.iconstyle.icon.href = icon_list['little_L']\n",
    "            pntEnc.style.iconstyle.scale = 0.8\n",
    "            pntEnc.style.labelstyle.color = '00ff0000'  # Red\n",
    "        if 'SingleBurstGen' in result:\n",
    "            with open(os.path.join(approot,SBLfile), 'rb') as csvfile:\n",
    "                csvfile.next()\n",
    "                filereader = csv.reader(csvfile)\n",
    "                folSBL = kml.newfolder(name='Single Burst Locations - '+ str(MEOLUT))\n",
    "                folEnc = kml.newfolder(name = 'Encoded Locations - '+ str(MEOLUT))\n",
    "                for row in filereader:            \n",
    "                    pntSBL = folSBL.newpoint(\n",
    "                        name = row[0],\n",
    "                        coords=[(float(row[8]),float(row[7]),float(row[9]))], \n",
    "                        description = 'Single Burst Solution \\nBeacon = ' + row[2] + '\\nLat,Long,Alt = ' + row[7] + \n",
    "                        ', ' + row[8] + ', ' + row[9] + \n",
    "                        '\\nTimeSolutionAdded = ' + row[0] + '\\nTimeFirst = ' +row[5] + '\\nTimeLast = ' +row[6] + \n",
    "                        '\\nMEOLUT = ' + row[4] + '\\nGT_Error = ' + row[16] + '\\nEnc_Error = ' + row[17] +\n",
    "                        '\\nNum of Bursts = ' + row[10] + '\\nNum of Packets = ' +row[11] +'\\nDOP = ' + row[12] + \n",
    "                        '\\nEHE = ' + row[13]\n",
    "                        )\n",
    "                    # name=str(row[0][11:19])\n",
    "                    pntSBL.timespan.begin = row[0][:10] + 'T' + row[0][11:19]\n",
    "                    pntSBL.style.iconstyle.icon.href = icon_list['little_L']\n",
    "        if 'EncLocGen' in result:\n",
    "            with open(os.path.join(approot,MBLfile), 'rb') as csvfile:\n",
    "                csvfile.next()\n",
    "                filereader = csv.reader(csvfile)\n",
    "                folEnc = kml.newfolder(name = 'Encoded Locations - '+ str(MEOLUT))                \n",
    "                for row in filereader:\n",
    "                    if row[17] <> '':  \n",
    "                        pntEnc = folEnc.newpoint(\n",
    "                            name= row[0],\n",
    "                            coords=[(float(row[15]),float(row[14]))], \n",
    "                            description = 'Encoded Location - Beacon = ' + row[2] + '\\nTimeSolutionAdded = ' + \n",
    "                        row[0] + '\\nLat,Long = (' + row[14] + ', ' +row[15] + ')'  \n",
    "                            )\n",
    "                        pntEnc.timespan.begin = row[0][:10] + 'T' + row[0][11:19]\n",
    "                        pntEnc.style.iconstyle.icon.href = icon_list['little_E']\n",
    "                        pntEnc.style.iconstyle.scale = 0.8\n",
    "                        pntEnc.style.labelstyle.color = '00ff0000'  # Red\n",
    "                        pntEnc.style.labelstyle.scale = 0 \n",
    "        with open(os.path.join(approot,MBLfile), 'rb') as csvfile:\n",
    "            csvfile.next()\n",
    "            filereader = csv.reader(csvfile)\n",
    "            folMBL = kml.newfolder(name='Multi Burst Locations - '+ str(MEOLUT))\n",
    "            for row in filereader:            \n",
    "                pntMBL = folMBL.newpoint(\n",
    "                    name=row[0],\n",
    "                    coords=[(float(row[8]),float(row[7]),float(row[9]))], \n",
    "                    description = 'Multi Burst Location - Beacon = ' + row[2] + '\\nLat,Long,Alt = ' + row[7] + \n",
    "                    ', ' + row[8] + ', ' + row[9] + '\\nTimeSolutionAdded = ' + row[0] + '\\nTimeFirst = ' + \n",
    "                    row[5] + '\\nTimeLast = ' +row[6] + \n",
    "                    '\\nMEOLUT = ' + row[4] + '\\nGT_Error = ' + row[16] + '\\nEnc_Error = ' + row[17] + \n",
    "                    '\\nNum of Bursts = ' + row[10] + '\\nNum of Packets = ' +row[11] +'\\nDOP = ' + row[12] + \n",
    "                    '\\nEHE = ' + row[13]\n",
    "                    )\n",
    "                pntMBL.timespan.begin = row[0][:10] + 'T' + row[0][11:19]\n",
    "                pntMBL.style.iconstyle.icon.href = icon_list['little_M']\n",
    "                pntMBL.style.iconstyle.scale = 0.8 \n",
    "                pntMBL.style.labelstyle.color = 'ff0000ff'  # Red\n",
    "                pntMBL.style.labelstyle.scale = 0 \n",
    "        if 'LEOGen' in result:\n",
    "            outfilelist[LEOGEO_file] = 'LEO Solutions'\n",
    "            sql_query = ('SELECT b.AddTime, a.* from Lut406Solution a, inputmessage b '\n",
    "                'WHERE a.InMsgId = b.InMsgId '\n",
    "                'AND '\n",
    "                'Orbit <> ? '  #this gets LEO solutions\n",
    "                'AND '\n",
    "                'A_Tca between ? AND ? '\n",
    "                'AND '\n",
    "                'BcnId15 LIKE ? '\n",
    "                )\n",
    "            params=['Null',TimeStart, TimeEnd, BeaconQuery]\n",
    "            df = pd.read_sql_query(sql_query,conn, index_col = 'addtime', params=params)\n",
    "            #df = df[(df.BcnId15 == BeaconID)]\n",
    "            dfLEO_loc = df[df['a_lat'] != 'NULL']\n",
    "            if df.empty: \n",
    "                print('query did not find any data that matched')    \n",
    "            else:\n",
    "                #dfLEO = df[df.Orbit.notnull()]\n",
    "\n",
    "                dfLEO_loc.to_csv(os.path.join(approot,LEOGEO_file))\n",
    "                with open(os.path.join(approot,LEOGEO_file), 'rb') as csvfile:\n",
    "                    filereader = csv.reader(csvfile)\n",
    "                    csvfile.next()\n",
    "                    fol_LEO = kml.newfolder(name='LEO Locations')\n",
    "                    for row in filereader:            \n",
    "                        pnt_LEO = fol_LEO.newpoint(coords=[(float(row[22]),float(row[21]))], \n",
    "                            description = 'LEO Location \\nBeacon = ' + row[15] + '\\n' + '\\nLat,Long = ' + \n",
    "                            row[21] + ', ' + row[22] + \n",
    "                            '\\n\\nA_Tca = ' + row[23] + '\\nMCCTime = ' + row[0] + '\\n\\nLUT = ' + row[2] + '\\nSat = ' + row[3] +\n",
    "                            '\\nOrbit = ' + str(int(float(row[4]))) + '\\n\\nNominal = ' + row[73] +  \n",
    "                            '\\nNum of Points = ' +row[18] + '\\nA_Cta =' + row[24] + '\\nA_prob = ' +row[17] + '\\nSolId = ' + row[1]  \n",
    "                            )   \n",
    "                        pnt_LEO.timespan.begin = row[0][:10] + 'T' + row[0][11:19]\n",
    "                        pnt_LEO.style.iconstyle.icon.href = icon_list['little_L']\n",
    "                        #pnt_LEO.style.iconstyle.icon.href = 'file://C:/Users/Jesse/Documents/Programming/Python/MEO_Input_Processor/MEO_Input_Processor_v2_w_KML/icon35.png'\n",
    "                        pnt_LEO.style.iconstyle.scale = 0.7\n",
    "                        pnt_LEO.style.labelstyle.color = 'ffff0000'  # Red\n",
    "        if 'OutputSolution' in result:\n",
    "            outfilelist[RCC_Output_file] = 'RCC Output Solutions'\n",
    "            sql_query = (' '\n",
    "                #'declare @bcnid as varchar(15) '\n",
    "                #'declare @bcnid2 as varchar(17) '\n",
    "                #'set @bcnid= ? '\n",
    "                #'set @bcnid2= \"%\" + @bcnid + \"%\" '\n",
    "                'SELECT b.AddTime, b.AlertSiteSolId, b.TimeFirst, b.TimeLast,b.Tca, a.MsgName, '\n",
    "                'b.SolReal, b.EncReal, b.AlertMsgState, c.ComSiteName, c.DestMcc, '\n",
    "                'b.PrevSarNameList, b.CurSarNameList, b.SourceId,b.SourceId2, b.EncLat, '\n",
    "                'b.EncLon, b.Latitude, b.Longitude, b.A_Lat, b.A_Lon, b.B_Lat, b.B_Lon, '\n",
    "                'a.TableName, a.InMsgId, b.SourceNameRccMsg, b.BcnId15, b.RegBcnId15, '\n",
    "                'b.SatelliteIds, b.Sat, c.SitNum, b.ASiteDuration  '\n",
    "                'FROM OutputMessage a, OutSolution b, OutputProcess c '\n",
    "                'WHERE '\n",
    "                'b.TimeFirst > ? '\n",
    "                'AND ' \n",
    "                'b.TimeLast < ? '\n",
    "                'AND '\n",
    "                'b.BcnId15 like ? '\n",
    "                'AND (b.OutMsgId=a.OutMsgId AND c.OutMsgId=a.OutMsgId) '                \n",
    "                )\n",
    "            params=[TimeStart, TimeEnd, BeaconQuery]\n",
    "            df = pd.read_sql_query(sql_query,conn, params=params)\n",
    "            #df = df[(df.BcnId15 == BeaconID)]\n",
    "            if df.empty: \n",
    "                print('query did not find any RCC output data that matched')    \n",
    "            else:\n",
    "                #dfLEO = df[df.Orbit.notnull()]\n",
    "                dfRCC_loc = df[df.a_lat.notnull()]\n",
    "                dfRCC_loc.to_csv(os.path.join(approot,RCC_Output_file))\n",
    "                with open(os.path.join(approot,RCC_Output_file), 'rb') as csvfile:\n",
    "                    filereader = csv.reader(csvfile)\n",
    "                    csvfile.next()\n",
    "                    fol_RCC = kml.newfolder(name='RCC Output Locations')\n",
    "                    for row in filereader:  \n",
    "                        if row[18]:\n",
    "                            pnt_RCC = fol_RCC.newpoint(coords=[(float(row[19]),float(row[18]))], \n",
    "                                description = 'RCC Solution \\nBeacon = ' + row[27] + '\\n' \n",
    "                                '\\nLat,Long = {0:.2f}'.format(float(row[18])) + ',{0:.2f}'.format(float(row[19])) +\n",
    "                                '\\nAddTime = ' + row[1] + '\\nAlertSiteSolId = ' + row[2] +\n",
    "                                '\\nMsgName = ' + row[6] + '\\n\\nLUT = ' + row[14] + '\\nSat = ' \n",
    "                                )   \n",
    "                            pnt_RCC.timespan.begin = row[1][:10] + 'T' + row[1][11:19]\n",
    "                            pnt_RCC.style.iconstyle.icon.href = icon_list['green_arrow']\n",
    "                            #pnt_LEO.style.iconstyle.icon.href = 'file://C:/Users/Jesse/Documents/Programming/Python/MEO_Input_Processor/MEO_Input_Processor_v2_w_KML/icon35.png'\n",
    "                            pnt_RCC.style.iconstyle.scale = 0.7\n",
    "                            pnt_RCC.style.labelstyle.color = 'FFFFFF'  # Red\n",
    "            \n",
    "        kml.save(os.path.join(approot,KMLfile))\n",
    "    return OUTfile, outfilelist\n",
    "\n",
    "def MSSQL_burst(arg_dict, config_dict, **kwargs):\n",
    "    servername, databasename, OUTPUTFOLDER, approot = config_dict[\"servername\"], config_dict[\"oppsdatabase\"], config_dict[\"OUTPUTFOLDER\"], config_dict[\"approot\"]\n",
    "    \n",
    "    beaconIDstring = arg_dict.get('beaconID', \"%\")\n",
    "    TimeSpan = arg_dict.get('EndTime') - arg_dict.get('StartTime')\n",
    "    num_bursts = TimeSpan.total_seconds() / 50\n",
    "    filetimetag = datetime.strftime(datetime.utcnow(),\"%Y%m%d_%H%M%S\")\n",
    "    ref_flag = False\n",
    "    filelist = list()\n",
    "    MEOnamelist = list()\n",
    "    for MEOLUT in arg_dict['MEOLUTList']:\n",
    "        for ant_i in ant_list:\n",
    "            if arg_dict.get('UseBeaconID') == \"UseRefBeacon\": \n",
    "                ref_flag = True\n",
    "                if arg_dict.get('refbeacon') == 'FL-HI-Ref': \n",
    "                    beaconIDstring = ReferenceBeacons[MEOLUTref[MEOLUT]]['beaconId']\n",
    "                else: \n",
    "                    beaconIDstring = ReferenceBeacons[arg_dict.get(\"refbeacon\")]['beaconId']\n",
    "            else:\n",
    "                beaconIDstring = arg_dict.get('beaconID', \"%\")\n",
    "            outpackets = find_packets(servername, databasename,beaconIDstring, arg_dict['StartTime'],arg_dict['EndTime'], MEOLUT, ant_i, **kwargs) # sat \n",
    "            num_packets_found = len(outpackets)\n",
    "            percent_packets = (num_packets_found/num_bursts)*100\n",
    "            plot_packets(outpackets, MEOLUT, ant_i,arg_dict['StartTime'],arg_dict['EndTime'], num_packets_found, percent_packets)\n",
    "        filename = os.path.normpath(os.path.join(OUTPUTFOLDER, str(MEOLUT) + '_' + filetimetag + '_output.png'))\n",
    "        filelist.append(filename)\n",
    "        MEOnamelist.append(MEOLUTName[MEOLUT])\n",
    "        plt.savefig(os.path.join(approot, filename)) #, bbox_inches='tight')\n",
    "        plt.clf()\n",
    "        plt.cla()\n",
    "    return filelist\n",
    "\n",
    "def MEOLUT_alarms(StartTime, EndTime, servername = 'localhost', databasename = 'mccoperational', **kwargs):\n",
    "    if 'sql_login' in kwargs:\n",
    "        conn = odbc.connect(r'Driver={FreeTDS};Server='+servername+';Database='+databasename+'; UID='+UID+'; PWD=' + PWD, readonly=True, autocommit = True)\n",
    "    else:\n",
    "        conn = odbc.connect(r'Driver={SQL Server};Server='+servername+';Database='+databasename+';Trusted_Connection=yes;',readonly=True, autocommit = True)\n",
    "    odbc.lowercase = True\n",
    "    query_params = [StartTime, EndTime]\n",
    "    sql_query = ('SELECT * from MeolutAlarms '\n",
    "        'WHERE '\n",
    "        'AddTime BETWEEN ? AND ? '\n",
    "    )\n",
    "    df = pd.read_sql_query(sql_query,conn, index_col = 'msgtime', params=query_params)\n",
    "    df.sort_index().ix[StartTime:EndTime]\n",
    "\n",
    "    dfClosedlist = df.alarmid[df.alarmtimeon.isnull()].tolist()\n",
    "    dfClosed = df[df.alarmid.isin(dfClosedlist)]\n",
    "     #list of closed alarmes between start and end time\n",
    "    closedalarms = dfClosed.alarmid.unique().tolist()    \n",
    "    #list of open alarms as of end time\n",
    "    dfOpen = df[~df.alarmid.isin(dfClosedlist)]\n",
    "\n",
    "    openalarms = dfOpen.alarmid.unique().tolist()\n",
    "    numalarms = len(openalarms)\n",
    "    alarmlist = []\n",
    "    for alarm in openalarms:    \n",
    "        alarms = {\n",
    "            'alarmid': int(dfOpen[(dfOpen.alarmid == alarm)].iloc[0].alarmid),\n",
    "            'meolutname': dfOpen[(dfOpen.alarmid == alarm)].iloc[0].meolutname,\n",
    "            'alarmtext': dfOpen[(dfOpen.alarmid == alarm)].iloc[0].alarmtext,\n",
    "            'openat': dfOpen[(dfOpen.alarmid == alarm)].iloc[0].alarmtimeon,\n",
    "            'stillopen': dfOpen[(dfOpen.alarmid == alarm)].iloc[-1].alarmtimeon\n",
    "        }\n",
    "        alarmlist.append(alarms)\n",
    "    closedalarmlist = []\n",
    "    for alarm in closedalarms:    \n",
    "        alarms = {\n",
    "            'alarmid': int(dfClosed[(dfClosed.alarmid == alarm)].iloc[0].alarmid),\n",
    "            'meolutname': dfClosed[(dfClosed.alarmid == alarm)].iloc[0].meolutname,\n",
    "            'alarmtext': dfClosed[(dfClosed.alarmid == alarm)].iloc[0].alarmtext,\n",
    "            'openat': dfClosed[(dfClosed.alarmid == alarm)].iloc[0].alarmtimeon,\n",
    "            'closedate': dfClosed[(dfClosed.alarmid == alarm) & (dfClosed.alarmtimeon.isnull())].iloc[0].alarmtimeoff\n",
    "            \n",
    "        }\n",
    "        closedalarmlist.append(alarms)\n",
    "    return alarmlist, closedalarmlist, numalarms\n",
    "\n",
    "def MEOLUT_status(StartTime, EndTime, servername = 'localhost', databasename = 'mccoperational', **kwargs):\n",
    "    if 'sql_login' in kwargs:\n",
    "        conn = odbc.connect(r'Driver={FreeTDS};Server='+servername+';Database='+databasename+'; UID='+UID+'; PWD=' + PWD, readonly=True, autocommit = True)\n",
    "    else:\n",
    "        conn = odbc.connect(r'Driver={SQL Server};Server='+servername+';Database='+databasename+';Trusted_Connection=yes;',readonly=True, autocommit=True)\n",
    "    #StartTime = StartTime - timedelta(days=5) ### REMOVE this when you have data that is more current\n",
    "    query_params = [StartTime, EndTime]\n",
    "    sql_query = ('SELECT * from MeolutStatus '\n",
    "        'WHERE '\n",
    "        'AddTime BETWEEN ? AND ? '\n",
    "    )\n",
    "    df = pd.read_sql_query(sql_query,conn, index_col = 'msgtime', params=query_params)\n",
    "    df.sort_index().ix[StartTime:EndTime]\n",
    "    if df.empty: \n",
    "        HI = {'component': 'N/A',\n",
    "            'msgtime': 'N/A',\n",
    "            'status': 'N/A',\n",
    "            }\n",
    "        FL = {'component': 'N/A',\n",
    "            'msgtime': 'N/A',\n",
    "            'status': 'N/A',\n",
    "            }\n",
    "        return HI, FL\n",
    "        #raise Exception('no status messages in window between start and endtime')\n",
    "    else:\n",
    "        dfHIcurrentmsgnum = int(df[(df.meolutid == 3385)].iloc[-1].msgnum)\n",
    "        dfFLcurrentmsgnum = int(df[(df.meolutid == 3669)].iloc[-1].msgnum)\n",
    "        dfHI = df[(df.meolutid == 3385) & (df.msgnum == dfHIcurrentmsgnum)]\n",
    "        dfFL = df[(df.meolutid == 3669) & (df.msgnum == dfFLcurrentmsgnum)]\n",
    "        statusHIlist = []\n",
    "        statusFLlist = []\n",
    "        statusHI = OrderedDict\n",
    "        statusFL = OrderedDict\n",
    "        for item, row in dfHI.iterrows():\n",
    "            statusHI = {\n",
    "                'component': row['component'],\n",
    "                'msgtime': item,\n",
    "                'status': int(row['status']),\n",
    "                }\n",
    "            statusHIlist.append(statusHI)\n",
    "        for item, row in dfFL.iterrows():\n",
    "            statusFL = {\n",
    "                'component': row['component'],\n",
    "                'msgtime': item,\n",
    "                'status': int(row['status']),\n",
    "                }\n",
    "            statusFLlist.append(statusFL)\n",
    "    return statusHIlist, statusFLlist\n",
    "\n",
    "def MEOLUT_percent(StartTime, EndTime, servername = 'localhost', databasename = 'MccTestLGM', **kwargs):\n",
    "    if 'sql_login' in kwargs:\n",
    "        conn = odbc.connect(r'Driver={FreeTDS};Server='+servername+';Database='+databasename+'; UID='+UID+'; PWD=' + PWD, readonly=True, autocommit = True)\n",
    "    else:\n",
    "        conn = odbc.connect(r'Driver={SQL Server};Server='+servername+';Database='+databasename+';Trusted_Connection=yes;',readonly=True, autocommit=True)\n",
    "    c = conn.cursor()\n",
    "    def get_packets(BeaconID, MEOLUT, Antenna, StartTime, EndTime):\n",
    "        query_params = [BeaconID, MEOLUT,  Antenna, StartTime, EndTime]\n",
    "        sql_query = ('SELECT COUNT(*) from MeolutPackets '\n",
    "            'WHERE '\n",
    "            'BcnId15 like ? '\n",
    "            'AND '\n",
    "            'MeolutId like ? '\n",
    "            'AND ' \n",
    "            'AntennaId like ? '\n",
    "            'AND '\n",
    "            'UplinkTOADate between ? AND ? '\n",
    "             )\n",
    "        c.execute(sql_query, query_params)\n",
    "        numpackets = c.fetchone()[0]\n",
    "        return numpackets\n",
    "\n",
    "    TimeSpan = EndTime - StartTime\n",
    "    expected_bursts = TimeSpan.total_seconds() / 50\n",
    "    antlist = range(1,7)\n",
    "    percentdict = defaultdict(dict)\n",
    "\n",
    "    beaconIDstring = \"ADDC002%\"\n",
    "    for ant in ant_list:\n",
    "        numpackets = get_packets(beaconIDstring, 3669, ant, StartTime,EndTime)\n",
    "        percentdict['FL'][ant] = round((numpackets / expected_bursts) * 100,2)\n",
    "    beaconIDstring = \"AA5FC00%\"\n",
    "    for ant in ant_list:\n",
    "        numpackets = get_packets(beaconIDstring, 3385, ant, StartTime,EndTime)\n",
    "        percentdict['HI'][ant] = round((numpackets / expected_bursts) * 100,2)\n",
    "    return percentdict\n",
    "\n",
    "def Open_Sites(servername = 'localhost', databasename = 'MccTestLGM', **kwargs):\n",
    "    if 'sql_login' in kwargs:\n",
    "        conn = odbc.connect(r'Driver={FreeTDS};Server='+servername+';Database='+databasename+'; UID='+UID+'; PWD=' + PWD, readonly=True, autocommit = True)\n",
    "    else:\n",
    "        conn = odbc.connect(r'Driver={SQL Server};Server='+servername+';Database='+databasename+';Trusted_Connection=yes;',readonly=True, autocommit=True)\n",
    "    c = conn.cursor()\n",
    "    params = ['N']\n",
    "    sql_query = ('SELECT alertsitenum, bcnid15, midname, '\n",
    "        'complat, complon, opentime, lastupdtime, numpasses, '\n",
    "        'numsol, numleogeosol, nummeosol, numdopsol, numdoasol '\n",
    "        ' from AlertSiteSum '\n",
    "        'WHERE '\n",
    "        'Closed = ? '\n",
    "        )\n",
    "    c.execute(sql_query, params)\n",
    "    return c.fetchall()\n",
    "\n",
    "def alertsitesum_query(sitenum, OUTPUTFOLDER, approot,servername = 'localhost', databasename = 'MccTestLGM', **kwargs):\n",
    "    if 'sql_login' in kwargs:\n",
    "        conn = odbc.connect(r'Driver={FreeTDS};Server='+servername+';Database='+databasename+'; UID='+UID+'; PWD=' + PWD, readonly=True, autocommit = True)\n",
    "    else:\n",
    "        conn = odbc.connect(r'Driver={SQL Server};Server='+servername+';Database='+databasename+';Trusted_Connection=yes;',readonly=True, autocommit=True)\n",
    "    c = conn.cursor()\n",
    "    params = [sitenum]\n",
    "    sql_query = ('SELECT alertsitenum, bcnid15, midname, '\n",
    "        'complat, complon, opentime, lastupdtime, numpasses, '\n",
    "        'numsol, numleogeosol, nummeosol, numdopsol, numdoasol '\n",
    "        ' from AlertSiteSum '\n",
    "        'WHERE '\n",
    "        'alertsitenum = ? '\n",
    "        )\n",
    "    c.execute(sql_query, params)\n",
    "    return c.fetchall()\n",
    "\n",
    "def alertsitesol_query(sitenum, OUTPUTFOLDER, approot,servername = 'localhost', databasename = 'MccTestLGM', **kwargs):\n",
    "    if 'sql_login' in kwargs:\n",
    "        conn = odbc.connect(r'Driver={FreeTDS};Server='+servername+';Database='+databasename+'; UID='+UID+'; PWD=' + PWD, readonly=True, autocommit = True)\n",
    "    else:\n",
    "        conn = odbc.connect(r'Driver={SQL Server};Server='+servername+';Database='+databasename+';Trusted_Connection=yes;',readonly=True, autocommit=True)\n",
    "    c = conn.cursor()\n",
    "    params = [sitenum]\n",
    "    sql_query = ('select alertsitesolid, inputdatatype, bcnid15, framesync, '\n",
    "        'complat, complon, sitfunc, gentime, addtime, sourceid, sourcename, '\n",
    "        'sourcemccname, numbursts, numpackets, numsatellites, dop, latitude, '\n",
    "        'longitude, a_lat, a_lon, MatchDistance, AlertMsgState, ExpectedHorzError, Sat, Tca '\n",
    "        'from AlertSiteSol where '\n",
    "        'AlertSiteNum = ? '\n",
    "        'order by gentime '\n",
    "        )\n",
    "    c.execute(sql_query, params)\n",
    "    insols = c.fetchall()\n",
    "    KMLfile = False\n",
    "    if \"makeKML\" in kwargs:\n",
    "        if kwargs.get(\"makeKML\"):\n",
    "            KMLfile = os.path.join(OUTPUTFOLDER, 'KML_Input_site_' + sitenum +'.kml')\n",
    "            kml = simplekml.Kml()\n",
    "            fol_RCC = kml.newfolder(name='Input Locations')\n",
    "            for row in insols:  \n",
    "                        if (row[16] <> 'NULL') or row[18]:\n",
    "                            if row[16] <> 'NULL':\n",
    "                                pnt_RCC = fol_RCC.newpoint(\n",
    "                                    coords=[(float(row[17]),float(row[16]))], \n",
    "                                    description = 'MEO Solution \\nBeacon = ' + str(row[2]) + '\\n' \n",
    "                                    '\\nLat,Long = {0:.4f}'.format(float(row[16])) + ',{0:.4f}'.format(float(row[17])) +\n",
    "                                    '\\nAddTime = ' + str(row[8]) + '\\nAlertSiteSolId = ' + str(int(row[0])) +\n",
    "                                    '\\nAlertMsgName = ' + str(row[21]) + '\\n\\nSource = ' + str(row[10]) + \n",
    "                                    '\\nNumBursts = ' + str(int(row[12])) + '\\nNumPackets = ' + str(int(row[13])) +\n",
    "                                    '\\nNumSats = ' + str(int(row[14])) + '\\nDOP = ' + str(row[15]) + \n",
    "                                    '\\nEHE = ' + str(row[22])\n",
    "                                    )\n",
    "                                pnt_RCC.style.iconstyle.icon.href = icon_list['circle_M']\n",
    "                                pnt_RCC.style.iconstyle.scale = 0.5\n",
    "                            elif row[18] :\n",
    "                                pnt_RCC = fol_RCC.newpoint(\n",
    "                                    coords=[(float(row[19]),float(row[18]))], \n",
    "                                    description = 'LEO Solution \\nBeacon = ' + str(row[2]) + '\\n' \n",
    "                                    '\\nLat,Long = {0:.4f}'.format(float(row[18])) + ',{0:.4f}'.format(float(row[19])) +\n",
    "                                    '\\nAddTime = ' + str(row[8]) + '\\nAlertSiteSolId = ' + str(int(row[0])) +\n",
    "                                    '\\nAlertMsgName = ' + str(row[21]) + '\\n\\nSource = ' + str(row[10]) + \n",
    "                                    '\\nSat = ' + str(row[23]) + '\\nTCA = ' + str(row[24])\n",
    "                                    )\n",
    "                                pnt_RCC.style.iconstyle.icon.href = icon_list['circle_L']\n",
    "                                pnt_RCC.style.iconstyle.scale = 0.8\n",
    "                            pnt_RCC.timespan.begin = str(row[8])[:10] + 'T' + str(row[8])[11:19]\n",
    "                            pnt_RCC.style.labelstyle.color = 'FFFFFF'              \n",
    "            kml.save(os.path.join(approot,KMLfile))\n",
    "    return insols, KMLfile\n",
    "\n",
    "def outsol_query(sitenum, OUTPUTFOLDER, approot, servername = 'localhost', databasename = 'MccTestLGM', **kwargs):\n",
    "    if 'sql_login' in kwargs:\n",
    "        conn = odbc.connect(r'Driver={FreeTDS};Server='+servername+';Database='+databasename+'; UID='+UID+'; PWD=' + PWD, autocommit=True)\n",
    "    else:\n",
    "        conn = odbc.connect(r'Driver={SQL Server};Server='+servername+';Database='+databasename+';Trusted_Connection=yes;',readonly=True, autocommit=True)\n",
    "    c = conn.cursor()\n",
    "    params = [sitenum]\n",
    "    sql_query = (' '\n",
    "        #'declare @bcnid as varchar(15) '\n",
    "        #'declare @bcnid2 as varchar(17) '\n",
    "        #'set @bcnid= ? '\n",
    "        #'set @bcnid2= \"%\" + @bcnid + \"%\" '\n",
    "        'SELECT b.AddTime, b.AlertSiteSolId, b.TimeFirst, b.TimeLast, b.Tca, a.MsgName, '\n",
    "        'b.SolReal, b.EncReal, b.AlertMsgState, c.ComSiteName, c.DestMcc, '\n",
    "        'b.PrevSarNameList, b.CurSarNameList, b.SourceId,b.SourceId2, b.EncLat, '\n",
    "        'b.EncLon, b.Latitude, b.Longitude, b.A_Lat, b.A_Lon, b.B_Lat, b.B_Lon, '\n",
    "        'a.TableName, a.InMsgId, b.SourceNameRccMsg, b.BcnId15, b.RegBcnId15, '\n",
    "        'b.SatelliteIds, b.Sat, c.SitNum, b.ASiteDuration  '\n",
    "        'FROM OutputMessage a, OutSolution b, OutputProcess c '\n",
    "        'WHERE '\n",
    "        'b.alertsitenum = ? '\n",
    "        'AND (b.OutMsgId=a.OutMsgId AND c.OutMsgId=a.OutMsgId) '\n",
    "        'order by addtime '                 \n",
    "        )\n",
    "    c.execute(sql_query, params)\n",
    "    outsols = c.fetchall()\n",
    "    KMLfile = False\n",
    "    if \"makeKML\" in kwargs:\n",
    "        if kwargs.get(\"makeKML\"):\n",
    "            KMLfile = os.path.join(OUTPUTFOLDER, 'KML_RCC_site_' + sitenum +'.kml')\n",
    "            kml = simplekml.Kml()\n",
    "            fol_RCC = kml.newfolder(name='RCC Output Locations')\n",
    "            for row in outsols:\n",
    "                if ((row[17] is not None) and (row[17] <> 'NULL')) or ((row[19] is not None) and (row[19] <> 'NULL')):\n",
    "                    if (row[17] is not None) and (row[17] <> 'NULL'):\n",
    "                        pnt_RCC = fol_RCC.newpoint(coords=[(float(row[18]),float(row[17]))], \n",
    "                            description = 'RCC Solution \\nBeacon = ' + str(row[26]) + '\\n' \n",
    "                            '\\nLat,Long = {0:.4f}'.format(float(row[17])) + ',{0:.4f}'.format(float(row[18])) +\n",
    "                            '\\nAddTime = ' + str(row[0]) + '\\nAlertSiteSolId = ' + str(int(row[1])) +\n",
    "                            '\\nMsgName = ' + str(row[5]) + '\\n\\nLUT = ' + str(int(row[13])) + '\\nSats = ' + str(row[28])\n",
    "                            )\n",
    "                    if (row[19] is not None) and (row[19] <> 'NULL'):\n",
    "                        pnt_RCC = fol_RCC.newpoint(coords=[(float(row[20]),float(row[19]))], \n",
    "                            description = 'RCC Solution \\nBeacon = ' + str(row[26]) + '\\n' \n",
    "                            '\\nLat,Long = {0:.4f}'.format(float(row[19])) + ',{0:.4f}'.format(float(row[20])) +\n",
    "                            '\\nAddTime = ' + str(row[0]) + '\\nAlertSiteSolId = ' + str(int(row[1])) +\n",
    "                            '\\nMsgName = ' + str(row[5]) + '\\n\\nLUT = ' + str(int(row[13])) + '\\nSat = ' + str(row[29]) \n",
    "                            )\n",
    "                    pnt_RCC.timespan.begin = str(row[0])[:10] + 'T' + str(row[0])[11:19]\n",
    "                    pnt_RCC.style.iconstyle.scale = 0.9\n",
    "                    pnt_RCC.style.labelstyle.color = 'FFFFFF'  \n",
    "                    if row[5] == 'MEOFirstAlertDOA':\n",
    "                        pnt_RCC.style.iconstyle.icon.href = icon_list['One']\n",
    "                    elif row[5] == '406BlownCompDoppler':\n",
    "                        pnt_RCC.style.iconstyle.icon.href = icon_list['red_cross']\n",
    "                    elif row[5] == 'MEOBlownCompDOA':\n",
    "                        pnt_RCC.style.iconstyle.icon.href = icon_list['red_cross']\n",
    "                    elif row[5] == 'MEONocrDOA':\n",
    "                        pnt_RCC.style.iconstyle.icon.href = icon_list['green_arrow']\n",
    "                    elif row[5] == 'MEOUpdatedNoCompDOA':\n",
    "                        pnt_RCC.style.iconstyle.icon.href = icon_list['yellow_pin']\n",
    "                    elif row[5] == 'MEOUpdatedCompDOA':\n",
    "                        pnt_RCC.style.iconstyle.icon.href = icon_list['M']\n",
    "                    elif row[5] == '406UpdatedCompDoppler':\n",
    "                        pnt_RCC.style.iconstyle.icon.href = icon_list['L']\n",
    "                    else:\n",
    "                        pnt_RCC.style.iconstyle.icon.href = icon_list['red_pin']\n",
    "\n",
    "               \n",
    "            kml.save(os.path.join(approot,KMLfile))\n",
    "    return outsols, KMLfile\n",
    "\n",
    "def both_kml(sitenum, OUTPUTFOLDER, approot, servername = 'localhost', databasename = 'MccTestLGM', **kwargs):\n",
    "    if 'sql_login' in kwargs:\n",
    "        conn = odbc.connect(r'Driver={FreeTDS};Server='+servername+';Database='+databasename+'; UID='+UID+'; PWD=' + PWD, autocommit=True)\n",
    "    else:\n",
    "        conn = odbc.connect(r'Driver={SQL Server};Server='+servername+';Database='+databasename+';Trusted_Connection=yes;',readonly=True, autocommit=True)\n",
    "    c = conn.cursor()\n",
    "    params = [sitenum]\n",
    "    sql_query = (' '\n",
    "        #'declare @bcnid as varchar(15) '\n",
    "        #'declare @bcnid2 as varchar(17) '\n",
    "        #'set @bcnid= ? '\n",
    "        #'set @bcnid2= \"%\" + @bcnid + \"%\" '\n",
    "        'SELECT b.AddTime, b.AlertSiteSolId, b.TimeFirst, b.TimeLast, b.Tca, a.MsgName, '\n",
    "        'b.SolReal, b.EncReal, b.AlertMsgState, c.ComSiteName, c.DestMcc, '\n",
    "        'b.PrevSarNameList, b.CurSarNameList, b.SourceId,b.SourceId2, b.EncLat, '\n",
    "        'b.EncLon, b.Latitude, b.Longitude, b.A_Lat, b.A_Lon, b.B_Lat, b.B_Lon, '\n",
    "        'a.TableName, a.InMsgId, b.SourceNameRccMsg, b.BcnId15, b.RegBcnId15, '\n",
    "        'b.SatelliteIds, b.Sat, c.SitNum, b.ASiteDuration  '\n",
    "        'FROM OutputMessage a, OutSolution b, OutputProcess c '\n",
    "        'WHERE '\n",
    "        'b.alertsitenum = ? '\n",
    "        'AND (b.OutMsgId=a.OutMsgId AND c.OutMsgId=a.OutMsgId) '\n",
    "        'order by addtime '                 \n",
    "        )\n",
    "    c.execute(sql_query, params)\n",
    "    outsols = c.fetchall()\n",
    "    KMLfile = False\n",
    "    KMLfile = os.path.join(OUTPUTFOLDER, 'KML_site_' + sitenum +'.kml')\n",
    "    Mapfile = os.path.join('/MapTest?KML=' + KMLfile).replace(\"\\\\\",\"/\")\n",
    "    kml = simplekml.Kml()\n",
    "    fol_RCC = kml.newfolder(name='RCC Output Locations')\n",
    "    for row in outsols:\n",
    "\n",
    "        if ((row[17] is not None) and (row[17] <> 'NULL')) or ((row[19] is not None) and (row[19] <> 'NULL')):\n",
    "            if (row[17] is not None) and (row[17] <> 'NULL'):\n",
    "                pnt_RCC = fol_RCC.newpoint(coords=[(float(row[18]),float(row[17]))], \n",
    "                    description = 'RCC Solution \\nBeacon = ' + str(row[26]) + '\\n' \n",
    "                    '\\nLat,Long = {0:.4f}'.format(float(row[17])) + ',{0:.4f}'.format(float(row[18])) +\n",
    "                    '\\nAddTime = ' + str(row[0]) + '\\nAlertSiteSolId = ' + str(int(row[1])) +\n",
    "                    '\\nMsgName = ' + str(row[5]) + '\\n\\nLUT = ' + str(int(row[13])) + '\\nSats = ' + str(row[28])\n",
    "                    )\n",
    "            if (row[19] is not None) and (row[19] <> 'NULL'):\n",
    "                pnt_RCC = fol_RCC.newpoint(coords=[(float(row[20]),float(row[19]))], \n",
    "                    description = 'RCC Solution \\nBeacon = ' + str(row[26]) + '\\n' \n",
    "                    '\\nLat,Long = {0:.4f}'.format(float(row[19])) + ',{0:.4f}'.format(float(row[20])) +\n",
    "                    '\\nAddTime = ' + str(row[0]) + '\\nAlertSiteSolId = ' + str(int(row[1])) +\n",
    "                    '\\nMsgName = ' + str(row[5]) + '\\n\\nLUT = ' + str(int(row[13])) + '\\nSat = ' + str(row[29]) \n",
    "                    )\n",
    "            pnt_RCC.timespan.begin = str(row[0])[:10] + 'T' + str(row[0])[11:19]\n",
    "            pnt_RCC.style.iconstyle.scale = 0.9\n",
    "            pnt_RCC.style.labelstyle.color = 'FFFFFF'  \n",
    "            if row[5] == 'MEOFirstAlertDOA':\n",
    "                pnt_RCC.style.iconstyle.icon.href = icon_list['One']\n",
    "            elif row[5] == '406BlownCompDoppler':\n",
    "                pnt_RCC.style.iconstyle.icon.href = icon_list['red_cross']\n",
    "            elif row[5] == 'MEOBlownCompDOA':\n",
    "                pnt_RCC.style.iconstyle.icon.href = icon_list['red_cross']\n",
    "            elif row[5] == 'MEONocrDOA':\n",
    "                pnt_RCC.style.iconstyle.icon.href = icon_list['green_arrow']\n",
    "            elif row[5] == 'MEOUpdatedNoCompDOA':\n",
    "                pnt_RCC.style.iconstyle.icon.href = icon_list['yellow_pin']\n",
    "            elif row[5] == 'MEOUpdatedCompDOA':\n",
    "                pnt_RCC.style.iconstyle.icon.href = icon_list['M']\n",
    "            elif row[5] == '406UpdatedCompDoppler':\n",
    "                pnt_RCC.style.iconstyle.icon.href = icon_list['L']\n",
    "            else:\n",
    "                pnt_RCC.style.iconstyle.icon.href = icon_list['red_pin']\n",
    "\n",
    "    ## Now get MEOLUT input \n",
    "    if 'sql_login' in kwargs:\n",
    "        conn = odbc.connect(r'Driver={FreeTDS};Server='+servername+';Database='+databasename+'; UID='+UID+'; PWD=' + PWD, autocommit=True)\n",
    "    else:\n",
    "        conn = odbc.connect(r'Driver={SQL Server};Server='+servername+';Database='+databasename+';Trusted_Connection=yes;',readonly=True, autocommit=True)\n",
    "    c = conn.cursor()\n",
    "    params = [sitenum]\n",
    "    sql_query = ('select alertsitesolid, inputdatatype, bcnid15, framesync, '\n",
    "        'complat, complon, sitfunc, gentime, addtime, sourceid, sourcename, '\n",
    "        'sourcemccname, numbursts, numpackets, numsatellites, dop, latitude, '\n",
    "        'longitude, a_lat, a_lon, MatchDistance, AlertMsgState, ExpectedHorzError, Sat, Tca '\n",
    "        'from AlertSiteSol where '\n",
    "        'AlertSiteNum = ? '\n",
    "        'order by gentime '\n",
    "        )\n",
    "    c.execute(sql_query, params)\n",
    "    insols = c.fetchall()\n",
    "    fol_MEO = kml.newfolder(name='Input Locations')\n",
    "    for row in insols:  \n",
    "                if ((row[16] is not None) and (row[16] <> 'NULL')) or ((row[18] is not None) and (row[18] <> 'NULL')):\n",
    "                    if ((row[16] is not None) and (row[16] <> 'NULL')):\n",
    "                        pnt_MEO = fol_MEO.newpoint(coords=[(float(row[17]),float(row[16]))], \n",
    "                            description = 'MEO Solution \\nBeacon = ' + str(row[2]) + '\\n' \n",
    "                            '\\nLat,Long = {0:.4f}'.format(float(row[16])) + ',{0:.4f}'.format(float(row[17])) +\n",
    "                            '\\nAddTime = ' + str(row[8]) + '\\nAlertSiteSolId = ' + str(int(row[0])) +\n",
    "                            '\\nAlertMsgName = ' + str(row[21]) + '\\n\\nSource = ' + str(row[10]) + \n",
    "                            '\\nNumBursts = ' + str(int(row[12])) + '\\nNumPackets = ' + str(int(row[13])) +\n",
    "                            '\\nNumSats = ' + str(int(row[14])) + '\\nDOP = ' + str(row[15]) + \n",
    "                            '\\nEHE = ' + str(row[22])\n",
    "                            )\n",
    "                        pnt_MEO.style.iconstyle.icon.href = icon_list['little_M']\n",
    "                        pnt_MEO.style.iconstyle.scale = 0.5\n",
    "                    elif ((row[18] is not None) and (row[18] <> 'NULL')):\n",
    "                        pnt_MEO = fol_MEO.newpoint(coords=[(float(row[19]),float(row[18]))], \n",
    "                            description = 'LEO Solution \\nBeacon = ' + str(row[2]) + '\\n' \n",
    "                            '\\nLat,Long = {0:.4f}'.format(float(row[18])) + ',{0:.4f}'.format(float(row[19])) +\n",
    "                            '\\nAddTime = ' + str(row[8]) + '\\nAlertSiteSolId = ' + str(int(row[0])) +\n",
    "                            '\\nAlertMsgName = ' + str(row[21]) + '\\n\\nSource = ' + str(row[10]) + \n",
    "                            '\\nSat = ' + str(row[23]) + '\\nTCA = ' + str(row[24])\n",
    "                            )\n",
    "                        pnt_MEO.style.iconstyle.icon.href = icon_list['little_L']\n",
    "                        pnt_MEO.style.iconstyle.scale = 0.8\n",
    "                    pnt_MEO.timespan.begin = str(row[8])[:10] + 'T' + str(row[8])[11:19]\n",
    "                    pnt_MEO.style.labelstyle.color = 'FFFFFF'                          \n",
    "    kml.save(os.path.join(approot,KMLfile))\n",
    "    return KMLfile, Mapfile\n",
    "def MSSQL_beacon_analysis(result, MEOLUTList, TimeStart, TimeEnd, config_dict, gt_file = False, Lat_GT=0, Long_GT=0, Location='', **kwargs):\n",
    "    servername, databasename, OUTPUTFOLDER, approot = config_dict[\"servername\"], config_dict[\"oppsdatabase\"], config_dict[\"OUTPUTFOLDER\"], config_dict[\"approot\"]\n",
    "    filetimetag = datetime.strftime(datetime.utcnow(),\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    filelist = OrderedDict()\n",
    "    imglist = []\n",
    "    if MEOLUTList==None: MEOLUTList = MEOList\n",
    "    if 'sql_login' in kwargs:\n",
    "        conn = odbc.connect(r'Driver={FreeTDS};Server='+servername+';Database='+databasename+'; UID='+UID+'; PWD=' + PWD, autocommit=True)\n",
    "    else:\n",
    "        conn = odbc.connect(r'Driver={SQL Server};Server='+servername+';Database='+databasename+';Trusted_Connection=yes;',readonly=True, autocommit=True)\n",
    "\n",
    "    BeaconQuery, BeaconID, Lat_GT, Long_GT, Location, MEO_dist = parse_results(result,MEOLUTList)\n",
    "    MEOList_str = '_'.join([str(MEO) for MEO in MEOLUTList])\n",
    "    outfiletag = '_{}_{}_{:%Y-%m-%d-%H%M}_{:%Y-%m-%d-%H%M}'.format(BeaconID,MEOList_str, TimeStart,TimeEnd)   \n",
    "    #Generate stats on a df (<5km, 10, 20 , median, quintiles)  \n",
    "    def stats(df,dist_list, q_list):\n",
    "        ''' Returns a tuple of total num solutions in df, # within dist_list[0], % within dist_list[0], etc, \n",
    "        median, number of burst within quintile[0], etc.  \n",
    "        then mean and 95%\n",
    "        '''\n",
    "        distout = []\n",
    "        perout = []\n",
    "        outlist = []\n",
    "        totnum = df.shape[0]\n",
    "        outlist.append(totnum)\n",
    "        ave = round(df[errorname].mean(),3)\n",
    "        median = round(df[errorname].quantile(.5),3)\n",
    "        win_5km = round(safe_div(df[df[errorname]<5].shape[0],totnum),3)\n",
    "        win_10km = round(safe_div(df[df[errorname]<10].shape[0],totnum),3)\n",
    "        q95 = round(df[errorname].quantile(.95),3)\n",
    "        outlist.append(ave)\n",
    "        for dist in dist_list:\n",
    "            distout.append(df[df[errorname]<dist].shape[0])\n",
    "            perout.append(round(safe_div(df[df[errorname]<dist].shape[0],totnum),2))\n",
    "        distlistout = [val for pair in zip(distout, perout) for val in pair] #interleaves two lists of same length\n",
    "        outlist.extend(distlistout)\n",
    "        qout = df[errorname].quantile(q_list)\n",
    "        qout = [round(q,2) for q in qout]\n",
    "\n",
    "        outlist.extend(qout)\n",
    "        return outlist, ave, median,  q95, win_5km, win_10km\n",
    "\n",
    "    #Return dataframe where a certain satellite is used\n",
    "    def sat_find(df, sat):\n",
    "        dfsat = df[df[satidsname].str.contains(sat)]\n",
    "        return dfsat\n",
    "\n",
    "    def get_cmap(n, name='brg'):\n",
    "        '''Returns a function that maps each index in 0, 1, ..., n-1 to a distinct \n",
    "        RGB color; the keyword argument name must be a standard mpl colormap name.'''\n",
    "        return plt.cm.get_cmap(name, n)\n",
    "\n",
    "    def hist_cum_plot(df,list1,maxrange,title, textstr,legendhandles,textstr2, **args):\n",
    "        # add filter out of where df[errorname] == None \n",
    "        df = df[df[errorname].notnull()]\n",
    "        bin_range = np.arange(0, maxrange+2)\n",
    "        dfall = np.clip(df[errorname],bin_range[0],bin_range[-1])\n",
    "        count, division = np.histogram(dfall, bins = bin_range)\n",
    "        ax1 = dfall.hist(bins=division, stacked = True, color = 'grey')\n",
    "        ax1.set_ylabel('Number of Locations Produced')\n",
    "        ax1.set_xlabel('Location Error (km)')\n",
    "        cumulative = np.cumsum(count).astype(np.float64)\n",
    "        x = np.linspace(0,bin_range[-1],cumulative.size)\n",
    "        cumulative/=cumulative.max()\n",
    "        cumulative*=100.\n",
    "        ax2 = ax1.twinx()\n",
    "        ax2.set_ylabel('Cumulative Error (%)')\n",
    "        props = dict(boxstyle='round', facecolor='wheat', alpha=0.3)\n",
    "        props2 = dict(boxstyle='round', facecolor='white', alpha=0.3)\n",
    "        ax2.text(bin_range.mean(), 30, textstr, fontsize=10,\n",
    "            verticalalignment='bottom', bbox = props)\n",
    "        if textstr2:\n",
    "            ax2.text(bin_range.mean(), 70, textstr2, fontsize=10,\n",
    "                verticalalignment='center', bbox = props2)\n",
    "        plt.plot(x,cumulative,'o-', color = 'black')\n",
    "        cmap = get_cmap(len(list1)+1)\n",
    "        plotdf = []\n",
    "        #print 'len list1 ' + str(len(list1))\n",
    "\n",
    "        # Loop below builds the cumulative error plots and arrays for stacked histogram\n",
    "        if list1: \n",
    "            for i, df1 in enumerate(list1):\n",
    "                df2 = np.clip(df1[errorname],bin_range[0],bin_range[-1])\n",
    "                plotdf.append(df2)\n",
    "                count, division = np.histogram(df2, bins = bin_range, range=(bin_range.min(),bin_range.max()))\n",
    "                cumulative = np.cumsum(count).astype(np.float64)\n",
    "                x = np.linspace(0,bin_range[-1],cumulative.size)\n",
    "                cumulative/=cumulative.max()\n",
    "                cumulative*=100.\n",
    "                plt.plot(x,cumulative, color=cmap(i), linestyle='dashed', linewidth=2)\n",
    "                ax2.legend(legendhandles, fontsize = 10, loc = 'right')\n",
    "        else:\n",
    "            df2 = np.clip(df[errorname],bin_range[0],bin_range[-1])\n",
    "            plotdf.append(df2)\n",
    "            count, division = np.histogram(df2, bins = bin_range, range=(bin_range.min(),bin_range.max()))\n",
    "            cumulative = np.cumsum(count).astype(np.float64)\n",
    "            x = np.linspace(0,bin_range[-1],cumulative.size)\n",
    "            cumulative/=cumulative.max()\n",
    "            cumulative*=100.\n",
    "            plt.plot(x,cumulative, linestyle='dashed', linewidth=2)\n",
    "            ax2.legend(legendhandles, fontsize = 10, loc = 'right')\n",
    "            \n",
    "        # This builds the df for stacked histogram and color list\n",
    "        plotlist = []\n",
    "        colors = []\n",
    "        for i, df4 in enumerate(plotdf):\n",
    "            plotlist.append(df4)\n",
    "            colors.append(cmap(i))\n",
    "        ax1.hist(plotlist, division, histtype='bar', stacked = True, \n",
    "                 color=colors, rwidth=0.85, alpha = 0.65) #, range = (0, 51)) \n",
    "                 #,range = (plotlist[1].min(),plotlist[1].max()))\n",
    "        plt.title(title, fontsize = 14)\n",
    "        ax1.set_xlim([bin_range[0],bin_range[-1]])\n",
    "        ax2.set_ylim([0,100])\n",
    "        #if plotmean: plt.axvline(df[errorname].mean(), color='gray', linestyle='dashed', linewidth=1)\n",
    "        #if plotmedian: plt.axvline(df[errorname].median(), color='gray', linestyle='dashed', linewidth=1)\n",
    "        return plt\n",
    "\n",
    "    UseMCC = True\n",
    "    if result.get('UseBeaconID') == 'SiteInput':\n",
    "        bcn_or_site = 'Site'\n",
    "        Sitenum = result.get('siteID')\n",
    "    else:\n",
    "        bcn_or_site = 'Beacon'\n",
    "    dist = [5, 10, 20]\n",
    "    q = [0.5, .75, .9, .95]\n",
    "    errorname = 'Error_GT'\n",
    "\n",
    "    ''' Define the column names for data below'''\n",
    "    fieldname = OrderedDict()\n",
    "    if UseMCC:\n",
    "        fieldname['datatypename'] = 'datatype'\n",
    "        fieldname['bcn15name'] = 'bcnid15'\n",
    "        fieldname['bcn30name'] = 'bcnid30'\n",
    "        fieldname['sourceidname'] = 'sourceid'\n",
    "        fieldname['timefirstname'] = 'timefirst'\n",
    "        fieldname['timelastname'] = 'timelast'\n",
    "        fieldname['latname'] = 'latitude'\n",
    "        fieldname['lonname'] = 'longitude'\n",
    "        fieldname['altname'] = 'altitude'\n",
    "        fieldname['numburstsname'] = 'numbursts'\n",
    "        fieldname['numpacketsname'] = 'numpackets'\n",
    "        fieldname['numsatsname'] = 'numsatellites'\n",
    "        fieldname['dopname'] = 'dop'\n",
    "        fieldname['cn0name'] = 'averagecn0'\n",
    "        fieldname['ehename'] = 'expectedhorzerror'\n",
    "        fieldname['satidsname'] = 'satelliteids'\n",
    "       \n",
    "\n",
    "    else:\n",
    "        datatypename = 'dataUsed'\n",
    "        errorname = 'locError_km'\n",
    "        errorname = 'Error'\n",
    "        numsatsname = 'nbSat'\n",
    "        numburstsname = 'nbBursts'\n",
    "        satidsname = 'listSatID'\n",
    "\n",
    "    fieldlist = []\n",
    "    for key, value in fieldname.iteritems():\n",
    "        fieldlist.append(value)\n",
    "    sql_query_field_list = \", \".join(fieldlist)\n",
    "    \n",
    "    if bcn_or_site == 'Site':\n",
    "        sql_query = ('declare @bcnid varchar(16) = ( '\n",
    "\t                 'select top 1 BcnId15 From AlertSiteSum where '\n",
    "\t                 'AlertSiteNum = ? '\n",
    "                     'ORDER BY TimeLast desc) '\n",
    "\t                 'SELECT ' + sql_query_field_list + ' FROM '\n",
    "                     'InputMEOSolution '\n",
    "                     'WHERE '\n",
    "                     'BcnId15 = @bcnid AND '\n",
    "                     'TimeFirst between ? AND ? '\n",
    "                     )\n",
    "        params=[Sitenum, TimeStart, TimeEnd]\n",
    "    else:\n",
    "        sql_query = ('SELECT ' + sql_query_field_list + ' FROM '\n",
    "                     'InputMEOSolution ' \n",
    "                     'WHERE ' \n",
    "                     'TimeSolutionGenerated between ? AND ? '\n",
    "                     'AND '\n",
    "                     'BcnId15 LIKE ? '\n",
    "                     )\n",
    "        params=[TimeStart, TimeEnd, BeaconQuery]\n",
    "    df = pd.read_sql_query(sql_query,conn, params= params) #, index_col = 'timesolutionadded', params=params)\n",
    "    df_data = []\n",
    "    for MEO in MEOLUTList:\n",
    "        df_data.append(filter1(df,'sourceid',MEO))\n",
    "    dfMEO = pd.concat(df_data)\n",
    "    #Use only multiburst data type\n",
    "    df_filter = filter1(dfMEO,fieldname['datatypename'],0)\n",
    "\n",
    "    filterlist = []\n",
    "    if result.get('filter1check',False):\n",
    "        if result.get('filter1sel') == 'filter1ran':\n",
    "            df_filter =  filter_range(df_filter, fieldname[result.get('filter1')], result.get('filter1rangelow',0), result.get('filter1rangehigh',100))\n",
    "            filterlist.append(fieldname[result.get('filter1')] + ' between ' + result.get('filter1rangelow',0) + ' and ' + result.get('filter1rangehigh',100))\n",
    "        else:\n",
    "            df_filter = filter1(df_filter, fieldname[result.get('filter1')], result.get('filter1value',0))\n",
    "            filterlist.append(fieldname[result.get('filter1')] + ' = ' + result.get('filter1value',0))\n",
    "    if result.get('filter2check',False):\n",
    "        if result.get('filter2sel') == 'filter2ran':\n",
    "            df_filter =  filter_range(df_filter, fieldname[result.get('filter2')], result.get('filter2rangelow',0), result.get('filter2rangehigh',100))\n",
    "            filterlist.append(fieldname[result.get('filter2')] + ' between ' + result.get('filter2rangelow',0) + ' and ' + result.get('filter2rangehigh',100))\n",
    "        else:\n",
    "            df_filter = filter1(df_filter, fieldname[result.get('filter2')], result.get('filter2value',0))\n",
    "            filterlist.append(fieldname[result.get('filter2')] + ' = ' + result.get('filter2value',0))\n",
    "    if result.get('filter3check',False):\n",
    "        if result.get('filter3sel') == 'filter3ran':\n",
    "            df_filter =  filter_range(df_filter, fieldname[result.get('filter3')], result.get('filter3rangelow',0), result.get('filter3rangehigh',100))\n",
    "            filterlist.append(fieldname[result.get('filter3')] + ' between ' + result.get('filter3rangelow',0) + ' and ' + result.get('filter3rangehigh',100))\n",
    "        else:\n",
    "            df_filter = filter1(df_filter, fieldname[result.get('filter3')], result.get('filter3value',0))\n",
    "            filterlist.append(fieldname[result.get('filter3')] + ' = ' + result.get('filter3value',0))\n",
    "    if df_filter.empty: \n",
    "        print 'no data ' \n",
    "        return BeaconID, None, None, None\n",
    "    \n",
    "    #dfout = sat_find(dfout1,'330') \n",
    "    #### Need to implement sat find\n",
    "    \n",
    "    # Fill in encoded locations\n",
    "    lat_fun = lambda hexin: bcn.beacon(hexin).lat\n",
    "    lon_fun = lambda hexin: bcn.beacon(hexin).lon\n",
    "    df_filter['Enc_Lat'] = df_filter['bcnid30'].apply(lat_fun)\n",
    "    df_filter['Enc_Lon'] = df_filter['bcnid30'].apply(lon_fun)\n",
    "\n",
    "    # if GT value is passed (stationary) write Lat_GT, Long_GT and Error_GT to DF\n",
    "    if (Lat_GT is not None) and (Long_GT is not None):\n",
    "        df_filter['Lat_GT'],df_filter['Lon_GT'] = Lat_GT, Long_GT\n",
    "        df_filter['Error_GT'] = df_filter[['latitude','longitude', 'Lat_GT','Lon_GT']].apply(haversine, axis = 1)\n",
    "    elif gt_file:\n",
    "        # If GT file is passed, read it, interpolate, write KML if passed, write Error_GT\n",
    "        if gt_file[-3:] == 'csv': \n",
    "            df_gt = pd.read_csv(gt_file, index_col = 'time', parse_dates = ['time']) \n",
    "        else:\n",
    "            df_gt = pd.read_excel(gt_file, index_col = 'time') \n",
    "        # add ability to read excel files \n",
    "\n",
    "        #gt_starttime = df_gt.index.min()\n",
    "        #gt_endtime = df_gt.index.max()\n",
    "        sol_starttime = df_filter[fieldname['timefirstname']].min()\n",
    "        sol_endtime = df_filter[fieldname['timelastname']].max()\n",
    "        df_gt = df_gt.iloc[::10]\n",
    "        df_gt = df_gt.loc[df_gt.index > TimeStart ]#sol_starttime - timedelta(minutes=10)]\n",
    "        df_gt = df_gt.loc[df_gt.index < TimeEnd] #sol_endtime + timedelta(minutes=10)]\n",
    "        if result.get('KMLgen'):\n",
    "            kml = simplekml.Kml()\n",
    "            GT_fol = kml.newfolder(name='GT-Track')\n",
    "            for row in df_gt.itertuples():\n",
    "                GT_point = GT_fol.newpoint(\n",
    "                name= 'GT-' + str(row[0]),\n",
    "                coords=[(float(row[2]),float(row[1]))],\n",
    "                description= str(row[0]) \n",
    "                )\n",
    "                GT_point.timespan.begin = str(row[0])[:10] + 'T' + str(row[0])[11:19]\n",
    "                #GT_point.style.iconstyle.icon.href = 'static/icons/blue_pog.png'\n",
    "                GT_point.style.iconstyle.icon.href = icon_list['blue_dot']\n",
    "                GT_point.style.labelstyle.scale = 0 \n",
    "                GT_point.style.iconstyle.scale = 0.3\n",
    "        def get_lat_lon_time(df,dateandtime):\n",
    "            if dateandtime not in df.index:\n",
    "                newrow = pd.DataFrame(data = [np.nan], index = [dateandtime])\n",
    "                df = df.append(newrow)\n",
    "            LON = pd.Series(index=df.index, data= df.lon.values).sort_index().interpolate(method='time')[dateandtime]\n",
    "            LAT = pd.Series(index=df.index, data= df.lat.values).sort_index().interpolate(method='time')[dateandtime]\n",
    "            return LAT, LON, dateandtime\n",
    "\n",
    "        for index, row in df_filter.iterrows():\n",
    "            lat, lon, timeat = get_lat_lon_time(df_gt,row['timelast'])\n",
    "            df_filter.set_value(index,'Lat_GT', lat)\n",
    "            df_filter.set_value(index,'Lon_GT', lon)\n",
    "            #df_filter.set_value(index,'Time_GT', timeat)\n",
    "\n",
    "\n",
    "\n",
    "        df_filter['Error_GT'] = df_filter[['Lat_GT','Lon_GT','latitude','longitude']].apply(haversine, axis = 1)\n",
    "        if 'Enc_Lat' in df_filter.columns: \n",
    "            df_filter['Error_Enc_Loc_GT'] = df_filter[['Lat_GT','Lon_GT','Enc_Lat','Enc_Lon']].apply(haversine, axis = 1)\n",
    "   \n",
    "    #else write Error_GT is 'NA'\n",
    "    else:\n",
    "        df_filter['Error_GT'] = 0\n",
    "\n",
    "    df_filter['Error_Enc'] = df_filter[['latitude','longitude','Enc_Lat','Enc_Lon']].apply(haversine, axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    ### still need to add column for location error here\n",
    "\n",
    "    # Need to write sols to file if checked or if you need to generate KML file\n",
    "    if result.get('SolutionsOut',False) or result.get('KMLgen',False):\n",
    "        Solutionfilename = os.path.normpath(os.path.join(OUTPUTFOLDER, filetimetag + '_Solutions.csv'))\n",
    "        df_filter.to_csv(os.path.join(approot,Solutionfilename))\n",
    "        filelist[Solutionfilename] = 'Histo/KML Solutions file'\n",
    "\n",
    "    statsout, mean, median, q95, win_5km, win_10km = stats(df_filter,dist,q)\n",
    "\n",
    "    ### This is for generating plots\n",
    "    if result.get('histcum',False):\n",
    "        textstr1 = 'Total Stats \\n\\nNum Locations = %.d\\nmean = %.1f km\\nmedian = %.1f km\\n95%% = %.1f km\\n\\n%% within 5 km = %.1f%%\\n%% within 10 km = %.1f%%'%(statsout[0], mean, median,  q95, 100*win_5km, 100*win_10km)# ' % (statsout[0])#\\nmean=%.2f$\\nmedian=%.2f$\\n95=%.2f'%(statsout[0], mean, median, q95)\n",
    "        legendhandles = ['all']\n",
    "\n",
    "        dflist = []\n",
    "        titleheader = []\n",
    "        titlelist = []\n",
    "        filtertext = None\n",
    "        #Generate text box for filters\n",
    "        if len(filterlist) > 0: \n",
    "            filtertextlist = ['Filters \\n']\n",
    "            for item in filterlist:\n",
    "                filtertextlist.append(item)\n",
    "            filtertext = '\\n'.join(filtertextlist)\n",
    "        \n",
    "        #Building Plot Title \n",
    "        if result.get('Location'):\n",
    "            titleheader.append(result.get('Location')+ ': ')\n",
    "            titleheader.append(BeaconID + '\\n')\n",
    "        if (result.get('beaconLat') and result.get('beaconLon')): \n",
    "            titleheader.append('(' + result.get('beaconLat') + ', ' +result.get('beaconLon')+')')\n",
    "        if result.get('UseBeaconID') == 'UseRefBeacon':\n",
    "            titleheader.append('Ref Beacon: '+ result.get('refbeacon')+' - '+ BeaconID + '\\n')\n",
    "            titleheader.append('Location: (' + str(ReferenceBeacons[result.get('refbeacon')]['beaconLat']) + ', ' +str(ReferenceBeacons[result.get('refbeacon')]['beaconLat'])+')')\n",
    "        titlelist.append(' '.join(titleheader))\n",
    "        MEOListstring = ['MEOLUT(s): ']\n",
    "        for MEO in MEOLUTList:\n",
    "            MEOListstring.append(str(MEO))\n",
    "\n",
    "        titlelist.append(' '.join(MEOListstring))\n",
    "\n",
    "        #Need to get the field to vary and set it below\n",
    "        if result.get('plotvary'):\n",
    "            varyfield = fieldname[result.get('plotvaryby')]\n",
    "            titlelist.append('Varying ' + varyfield)\n",
    "            if varyfield == 'numsatellites':\n",
    "                satrangediff = 1\n",
    "                satrange = range(3,11,satrangediff) # could be variable          \n",
    "                for i in satrange:\n",
    "                    if i == satrange[-1]:\n",
    "                        dflist.append(filter_range(df_filter,varyfield,i,20))\n",
    "                        legendhandles.append(varyfield + ': ' + str(i) + '+ ')\n",
    "                    else:\n",
    "                        dflist.append(filter1(df_filter,varyfield,i))\n",
    "                        legendhandles.append(varyfield + ': ' + str(i))\n",
    "            if varyfield == 'dop':\n",
    "                doprangediff = 1\n",
    "                doprange = range(0,7,doprangediff) # could be variable \n",
    "                for i in doprange:\n",
    "                    if i == doprange[-1]:\n",
    "                        dflist.append(filter_range(df_filter,varyfield,i,100))\n",
    "                        legendhandles.append(varyfield + ': ' + str(i) + '+ ')\n",
    "                    else:\n",
    "                        dflist.append(filter_range(df_filter,varyfield,i,i+doprangediff))\n",
    "                        legendhandles.append(varyfield + ': ' + str(i) + ' - ' + str(i+doprangediff))\n",
    "            if varyfield == 'expectedhorzerror':\n",
    "                eherangediff = 2\n",
    "                eherange = range(0,10,eherangediff) # could be variable \n",
    "                for i in eherange:\n",
    "                    if i == eherange[-1]:\n",
    "                        dflist.append(filter_range(df_filter,varyfield,i,100))\n",
    "                        legendhandles.append(varyfield + ': ' + str(i) + '+ ')\n",
    "                    else:\n",
    "                        dflist.append(filter_range(df_filter,varyfield,i,i+eherangediff))\n",
    "                        legendhandles.append(varyfield + ': ' + str(i) + ' - ' + str(i+eherangediff))\n",
    "            if varyfield == 'numbursts':\n",
    "                numburstrangediff = 3\n",
    "                numburstrange = [1, 2]\n",
    "                numburstrange.extend(range(3,30,numburstrangediff)) # could be variable \n",
    "                for i in numburstrange:\n",
    "                    if i == 1 or i == 2:\n",
    "                        dflist.append(filter1(df_filter,varyfield,i))\n",
    "                        legendhandles.append(varyfield + ': ' + str(i) )                    \n",
    "                    elif i == numburstrange[-1]:\n",
    "                        dflist.append(filter_range(df_filter,varyfield,i,100))\n",
    "                        legendhandles.append(varyfield + ': ' + str(i) + '+ ')\n",
    "                    else:\n",
    "                        dflist.append(filter_range(df_filter,varyfield,i,i+numburstrangediff))\n",
    "                        legendhandles.append(varyfield + ': ' + str(i) + ' - ' + str(i+numburstrangediff))\n",
    "            if varyfield == 'numpackets':\n",
    "                numpacketsrangediff = 10\n",
    "                numpacketsrange = range(0,100,numpacketsrangediff) # could be variable \n",
    "                for i in numpacketsrange:\n",
    "                    if i == numpacketsrange[-1]:\n",
    "                        dflist.append(filter_range(df_filter,varyfield,i,200))\n",
    "                        legendhandles.append(varyfield + ': ' + str(i) + '+ ')\n",
    "                    else:\n",
    "                        dflist.append(filter_range(df_filter,varyfield,i,i+numpacketsrangediff))\n",
    "                        legendhandles.append(varyfield + ': ' + str(i) + ' - ' + str(i+numpacketsrangediff))\n",
    "            if varyfield == 'averagecn0':\n",
    "                cn0rangediff = 2\n",
    "                cn0range = range(30,50,cn0rangediff) # could be variable \n",
    "                for i in cn0range:\n",
    "                    if i == cn0range[-1]:\n",
    "                        dflist.append(filter_range(df_filter,varyfield,i,100))\n",
    "                        legendhandles.append(varyfield + ': ' + str(i) + '+ ')\n",
    "                    else:\n",
    "                        dflist.append(filter_range(df_filter,varyfield,i,i+cn0rangediff))\n",
    "                        legendhandles.append(varyfield + ': ' + str(i) + ' - ' + str(i+cn0rangediff))\n",
    "\n",
    "\n",
    "        title = \"\\n\".join(titlelist)\n",
    "        # range needs to be chosen correct for what field is varying - currently good for numsats \n",
    "\n",
    "        plt1 = plt.figure(figsize=(16, 9), dpi=400, facecolor='w', edgecolor='k')\n",
    "        plt1 = hist_cum_plot(df_filter,dflist,50,title, textstr1,legendhandles, filtertext) \n",
    "\n",
    "        filename = os.path.normpath(os.path.join(OUTPUTFOLDER, 'histogram' + outfiletag +'_' + filetimetag + '.png'))\n",
    "        imglist.append(filename)\n",
    "        plt1.savefig(os.path.join(approot, filename)) #, bbox_inches='tight')\n",
    "        plt.clf()\n",
    "        plt.cla()\n",
    "        plt.close('all')\n",
    "    statsfile = os.path.normpath(os.path.join(OUTPUTFOLDER, 'out_stats_sum' + filetimetag + '_out_stats_sum.csv'))\n",
    "    rw = []\n",
    "    rw.extend(statsout)\n",
    "    \n",
    "    headerlist = []\n",
    "    statslist = []\n",
    "    headerlist.append(bcn_or_site)\n",
    "    if bcn_or_site == 'Site':\n",
    "        statslist.append(Sitenum)\n",
    "    else:\n",
    "        statslist.append(BeaconID)\n",
    "    if result.get('Location'): \n",
    "        headerlist.append('Location')\n",
    "        statslist.append(result.get('Location'))\n",
    "    if (result.get('beaconLat') and result.get('beaconLon')): \n",
    "        headerlist.append('BeaconLat')\n",
    "        headerlist.append('BeaconLon')\n",
    "        statslist.append(result.get('beaconLat'))\n",
    "        statslist.append(result.get('beaconLon'))\n",
    "\n",
    "    MEOListstring = []\n",
    "    for i, MEO in enumerate(MEOLUTList):\n",
    "        headerlist.append('MEO-' + str(i+1))\n",
    "        statslist.append(str(MEO))\n",
    "        headerlist.append('MEO-' + str(i+1) + ' dist (km)')\n",
    "        if MEO_dist[i] <> None: \n",
    "            statslist.append(str(round(MEO_dist[i],1)))\n",
    "        else:\n",
    "            statslist.append('NA')\n",
    "    \n",
    "    for i, filter in enumerate(filterlist):\n",
    "        headerlist.append('Filter-' + str(i+1))\n",
    "        statslist.append(filter)\n",
    "\n",
    "\n",
    "    #headrow = [','.join(headerlist)]\n",
    "    headrow = []\n",
    "    \n",
    "    headrow2 = ['# locations','ave','# <5 km','% < 5 km','# < 10 km','% < 10 km','# < 20 km','% < 20 km','median (km)','75% (km)','90% (km)','95% (km)']\n",
    "    headrow.extend(headerlist)\n",
    "    headrow.extend(headrow2)\n",
    "\n",
    "    statsrow = []\n",
    "    statsrow.extend(statslist)\n",
    "    statsrow.extend(rw)\n",
    "\n",
    "    with open(os.path.join(approot, statsfile), 'a') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile, delimiter=',')\n",
    "        csvwriter.writerow(headrow)\n",
    "        csvwriter.writerow(statsrow)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    if result.get('KMLgen'): \n",
    "        KMLfile = os.path.join(OUTPUTFOLDER, 'KML' + filetimetag +'.kml')\n",
    "        Mapfile = os.path.join('/MapTest?KML=' + KMLfile).replace(\"\\\\\",\"/\")\n",
    "        filelist[KMLfile] = 'KML File Output'\n",
    "        filelist[Mapfile] = 'MapIt'\n",
    "        if not gt_file: \n",
    "            print 'making kml'\n",
    "            kml = simplekml.Kml()\n",
    "        if (result.get('GTSource') == 'GTLatLon') and (result.get('beaconLat')) <> '':\n",
    "            firstrad = 5000\n",
    "            secondrad = 10000\n",
    "            folEnc = kml.newfolder(name = 'Ground Truth ')                \n",
    "            polycircle1 = polycircles.Polycircle(latitude=Lat_GT,\n",
    "                                    longitude=Long_GT,\n",
    "                                    radius=firstrad,\n",
    "                                    number_of_vertices=36)            \n",
    "            pol1 = kml.newpolygon(name=\"5km\",\n",
    "                                         outerboundaryis=polycircle1.to_kml())\n",
    "            pol1.style.polystyle.color = \\\n",
    "                simplekml.Color.changealphaint(100, simplekml.Color.green)\n",
    "            # Second region\n",
    "\n",
    "            polycircle2outer = polycircles.Polycircle(latitude=Lat_GT,\n",
    "                                    longitude=Long_GT,\n",
    "                                    radius=secondrad,\n",
    "                                    number_of_vertices=36)            \n",
    "\n",
    "            pol2 = kml.newpolygon(name=\"10km\",\n",
    "                                         outerboundaryis=polycircle2outer.to_kml(),\n",
    "                                         innerboundaryis = polycircle1.to_kml())\n",
    "            pol2.style.polystyle.color = \\\n",
    "                simplekml.Color.changealphaint(100, simplekml.Color.yellow)\n",
    "            pntEnc = folEnc.newpoint(\n",
    "                name = 'Ground Truth',\n",
    "                coords=[(Long_GT,Lat_GT)], \n",
    "                description = 'Lat,Long = (' + str(Lat_GT) + ', ' + str(Long_GT) + ')'  \n",
    "                )\n",
    "            pntEnc.style.iconstyle.icon.href = icon_list['white_arrow']\n",
    "            pntEnc.style.iconstyle.scale = 0.8\n",
    "            pntEnc.style.labelstyle.color = '00ff0000'  # Red\n",
    "\n",
    "        with open(os.path.join(approot,Solutionfilename), 'rb') as csvfile:\n",
    "            csvfile.next()\n",
    "            filereader = csv.reader(csvfile)\n",
    "            try: \n",
    "                kml\n",
    "            except:\n",
    "                kml = simplekml.Kml()\n",
    "            folEnc = kml.newfolder(name = 'Encoded Locations')                \n",
    "            for row in filereader:\n",
    "                if (row[17] <> 'NULL') and (row[17] is not None) and (row[17] <> ''):  \n",
    "                    pntEnc = folEnc.newpoint(\n",
    "                        name= row[6],\n",
    "                        coords=[(float(row[18]),float(row[17]))], \n",
    "                        description = 'Encoded Location - Beacon = ' + row[2] + '\\nTimeLast = ' + \n",
    "                    row[6] + '\\nLat,Long = (' + row[17] + ', ' +row[18] + ')'  \n",
    "                        )\n",
    "                    pntEnc.timespan.begin = row[6][:10] + 'T' + row[6][11:19]\n",
    "                    pntEnc.style.iconstyle.icon.href = icon_list['circle_E']\n",
    "                    pntEnc.style.iconstyle.scale = 0.8\n",
    "                    pntEnc.style.labelstyle.color = '00ff0000'  # Red\n",
    "                    pntEnc.style.labelstyle.scale = 0 \n",
    "        with open(os.path.join(approot,Solutionfilename), 'rb') as csvfile:\n",
    "            csvfile.next()\n",
    "            filereader = csv.reader(csvfile)\n",
    "            folMBL = kml.newfolder(name='MEOLUT Locations')\n",
    "            for row in filereader:            \n",
    "                try: \n",
    "                    GT_error = '{0:.2f}'.format(float(row[21]))\n",
    "                except: \n",
    "                    GT_error = 'NA' \n",
    "                try: \n",
    "                    Enc_error = '{0:.2f}'.format(float(row[22]))\n",
    "                except: \n",
    "                    Enc_error = 'NA' \n",
    "                \n",
    "                pntMBL = folMBL.newpoint(\n",
    "                    name=row[6],\n",
    "                    coords=[(float(row[8]),float(row[7]),float(row[9]))], \n",
    "                    description = 'Multi Burst Location - Beacon = ' + row[2] + '\\nLat,Long,Alt = ' + row[7] + \n",
    "                    ', ' + row[8] + ', ' + row[9] + '\\nTimeLast = ' + row[6] + '\\nTimeFirst = ' + \n",
    "                    row[5] + '\\nMEOLUT = ' + row[4] + '\\nGT_Error = ' + GT_error + \n",
    "                    '\\nEnc_Error = '+ Enc_error +  \n",
    "                    '\\nNum of Bursts = ' + row[10] + '\\nNum of Packets = ' +row[11] +'\\nNum Sats = ' + row[12] + \n",
    "                    '\\nDOP = ' +row[13] + '\\nAveCN0 = ' +row[14] + '\\nEHE = ' + row[15] + '\\nSats-' + row[16]\n",
    "\n",
    "                    )\n",
    "                pntMBL.timespan.begin = row[6][:10] + 'T' + row[6][11:19]\n",
    "                pntMBL.style.iconstyle.icon.href = icon_list['little_M']\n",
    "                pntMBL.style.iconstyle.scale = 0.4\n",
    "                pntMBL.style.labelstyle.color = 'ff0000ff'  # Red\n",
    "                pntMBL.style.labelstyle.scale = 0  \n",
    "\n",
    "                if (result.get('ErrorLines') and (GT_error != 'NA')):\n",
    "                    if 'Error Lines' not in [x.name for x in kml.containers]:\n",
    "                        GT_loc_fol = kml.newfolder(name='Error Lines')\n",
    "                    GT_errorline = GT_loc_fol.newlinestring(name='Error - ' + row[6])\n",
    "                    GT_errorline.coords = [(float(row[8]),float(row[7]),float(row[9])),(float(row[20]), float(row[19]), 0)]\n",
    "                    GT_errorline.timespan.begin = str(row[6])[:10] + 'T' + str(row[6])[11:19]\n",
    "                    GT_errorline.style.iconstyle.icon.href = icon_list['blue_dot']\n",
    "                    GT_errorline.style.labelstyle.scale = 0 \n",
    "\n",
    "        kml.save(os.path.join(approot,KMLfile))\n",
    "    return BeaconID, statsfile, imglist, filelist\n",
    "    #for sat in us_sarsats:\n",
    "    #    dfsat = sat_find(dfout1,str(sat))\n",
    "    #    dfout = dfsat\n",
    "    #    statsout, mean, median, q95, win_5km, win_10km = stats(dfout,dist,q)\n",
    "    #    rw = [sat]\n",
    "    #    rw.extend(statsout)\n",
    "    #    with open('out_sat_stats_sum.csv', 'a') as csvfile:\n",
    "    #        csvwriter = csv.writer(csvfile, delimiter=',')\n",
    "    #        csvwriter.writerow(rw)\n",
    "def MeoDataCollection(result, MEOLUTList, StartTime, EndTime, config_dict, zip_file = False , **kwargs):\n",
    "    servername, databasename, OUTPUTFOLDER, approot = config_dict[\"servername\"], config_dict[\"oppsdatabase\"], config_dict[\"OUTPUTFOLDER\"], config_dict[\"approot\"]\n",
    "    if 'sql_login' in kwargs:\n",
    "        conn = odbc.connect(r'Driver={FreeTDS};Server='+servername+';Database='+databasename+'; UID='+UID+'; PWD=' + PWD, autocommit = True)\n",
    "    else:\n",
    "        conn = odbc.connect(r'Driver={SQL Server};Server='+servername+';Database='+databasename+';Trusted_Connection=yes;',readonly=True, autocommit = True)\n",
    "    UseMCC = True\n",
    "    meoListString = \"_\".join([str(i) for i in MEOLUTList])\n",
    "    placeholders = \",\".join(\"?\" * len(MEOLUTList))\n",
    "    BeaconQuery, BeaconID, Lat_GT, Long_GT, Location, MEO_dist = parse_results(result,MEOLUTList)\n",
    "    outfiletag = '_{}_{:%Y-%m-%d-%H%M}_{:%Y-%m-%d-%H%M}'.format(BeaconID,StartTime,EndTime)\n",
    "    outfile_dict = OrderedDict()\n",
    "    \n",
    "    if result.get('AllSiteSols',False):\n",
    "        # Get and make all alertsitesols file\n",
    "        sql_query = \"\"\"\\\n",
    "            SELECT * FROM [MccMeoLutMonitor].[dbo].[AlertSiteSol] \n",
    "            WHERE TimeFirst > ? \n",
    "            AND AddTime < ?\n",
    "            AND BcnId15 like ?\n",
    "\n",
    "            \"\"\"\n",
    "        params = [StartTime, EndTime, BeaconQuery]\n",
    "        c = conn.cursor()\n",
    "        c.execute(sql_query, params)\n",
    "        columns = [column[0] for column in c.description]\n",
    "        out = c.fetchall()\n",
    "        if out:\n",
    "            allsols_file = os.path.join(OUTPUTFOLDER, 'all_alert_site_sols' + outfiletag +'.csv')\n",
    "            outfile_dict[allsols_file] = 'All Alert Site Solutions'\n",
    "            with open(os.path.join(approot,allsols_file), 'wb') as csvfile:\n",
    "                csvoutwriter = csv.writer(csvfile, delimiter=',',\n",
    "                                        quoting=csv.QUOTE_MINIMAL)\n",
    "                csvoutwriter.writerow(columns)\n",
    "                for row in out:\n",
    "                    csvoutwriter.writerow(row)\n",
    "\n",
    "    if result.get('J1data',False):\n",
    "        J1_header = ['BurstId', 'BcnId30','BcnId15','Received','FOA','FOAOff','TOA', 'TOAOff','CN0','BitRate', 'Ant','Sat','MEOLUT','BCH_Errors']\n",
    "        # Get the J1 data or return blank file name \n",
    "\n",
    "        \n",
    "        sql_query = \"\"\"\\\n",
    "            SELECT \n",
    "            DbId as 'BurstId', BcnId30, BcnId15, AddTime as 'Received', \n",
    "            UplinkFOA as 'FOA', DownLinkFOAOffset as 'FOAOff', \n",
    "            dateadd(ns, UplinkTOANanoSecs, convert(datetime2, UplinkTOAdate)) as 'TOA',\n",
    "            DownlinkTOAOffset as 'TOAOff', CarrierToNoise as 'CN0', BitRate, AntennaId as 'Ant', \n",
    "            SatId as 'Sat', MeolutId as 'MEOLUT', NumBCHErrs\n",
    "            FROM [MccMeoLutMonitor].[dbo].[MeolutPackets] \n",
    "            WHERE \n",
    "            BcnId15 like ? AND\n",
    "            UplinkTOADate between ? AND ? \n",
    "            AND\n",
    "            MeolutId in (%s) \n",
    "            \"\"\" % placeholders\n",
    "        params = [BeaconQuery, StartTime, EndTime]\n",
    "        params.extend(MEOLUTList)\n",
    "        c = conn.cursor()\n",
    "        c.execute(sql_query, params)\n",
    "        columns = [column[0] for column in c.description]\n",
    "        out = c.fetchall()\n",
    "        if out:\n",
    "            J1_file = os.path.join(OUTPUTFOLDER, 'J1_' + meoListString + outfiletag +'.csv')\n",
    "            outfile_dict[J1_file] = 'J1 - Raw Bursts'\n",
    "            with open(os.path.join(approot,J1_file), 'wb') as csvfile:\n",
    "                csvoutwriter = csv.writer(csvfile, delimiter=',',\n",
    "                                        quoting=csv.QUOTE_MINIMAL)\n",
    "                csvoutwriter.writerow(columns)\n",
    "                for row in out:\n",
    "                    csvoutwriter.writerow(row)\n",
    "            \n",
    "        # write a second J1 file from zip if needed \n",
    "        if zip_file:\n",
    "            J1_file_zip = os.path.join(OUTPUTFOLDER, 'J1_from_zip_' + meoListString + outfiletag +'.csv')\n",
    "            outfile_dict[J1_file_zip] = 'J1 - Raw Bursts from zip file'\n",
    "            filetypesearch = \"TOA_FOA_DATA\"\n",
    "            country = \"USA\"\n",
    "            for MEO in MEOLUTList:\n",
    "                my_regex = file_search_regex(filetypesearch, country)\n",
    "                zipmatches = find_file_inzip(zip_file, my_regex)\n",
    "                burstlist = list()\n",
    "                search_zip_output(MEO, zip_file, zipmatches, filetypesearch, J1_file_zip, approot, J1_header, country, beaconId)\n",
    "        print 'done making J1 file at ' + str(datetime.utcnow())    \n",
    "\n",
    "    if result.get('J2data',False):\n",
    "        #J2 - Format - \n",
    "        sql_query = \"\"\"\\\n",
    "            SELECT\tSolId as 'Solution ID', \n",
    "                SourceId as 'LUT ID', \n",
    "                TimeFirst as 'Time of First Burst', \n",
    "                TimeLast as 'Time of Last Burst', \n",
    "                FileTime as 'Time Solution Sent', \n",
    "                BcnId15 as 'Beacon 15 Hex ID', \n",
    "                FreqBias/1000000 as 'Detection Frequency', \n",
    "                BcnId36 as 'Beacon 36 Hex ID', \n",
    "                NumBursts, NULL as 'Data Used', \n",
    "                SourceAntennaIds as 'Antenna IDs',\n",
    "                NumPackets as 'Number of Packets used', \n",
    "                NumSatellites as 'Number of Satellites used', \n",
    "                SatelliteIds as 'Sat IDs', \n",
    "                DOP, \n",
    "                ExpectedHorzError as 'EHE',\n",
    "                QualityFactor, \n",
    "                NULL as 'Location Methodology', \n",
    "                Latitude, \n",
    "                Longitude, \n",
    "                Altitude \n",
    "            FROM [MccMeoLutMonitor].[dbo].[InputMEOSolution]\n",
    "            WHERE TimeLast > ? \n",
    "            AND TimeFirst < ?\n",
    "            AND BCNID15 like ? \n",
    "            AND datatype = 0 \n",
    "            AND SourceId in (%s)\n",
    "            \"\"\" % placeholders\n",
    "        params = [StartTime, EndTime, BeaconQuery]\n",
    "        params.extend(MEOLUTList)\n",
    "        c = conn.cursor()\n",
    "        c.execute(sql_query, params)\n",
    "        columns = [column[0] for column in c.description]\n",
    "        out = c.fetchall()\n",
    "        if out:\n",
    "            J2_file = os.path.join(OUTPUTFOLDER, 'J2_' + meoListString + outfiletag +'.csv')\n",
    "            outfile_dict[J2_file] = 'J2 - MEOLUT Solutions'\n",
    "            with open(os.path.join(approot,J2_file), 'wb') as csvfile:\n",
    "                csvoutwriter = csv.writer(csvfile, delimiter=',',\n",
    "                                        quoting=csv.QUOTE_MINIMAL)\n",
    "                csvoutwriter.writerow(columns)\n",
    "                for row in out:\n",
    "                    csvoutwriter.writerow(row)\n",
    "\n",
    "    if result.get('J3data',False):\n",
    "        # Get and make J3 (schedule)\n",
    "        sql_query = \"\"\"\\\n",
    "            --J3 Format--MEO\n",
    "            declare @starttime datetime, @endtime datetime\n",
    "            select @starttime = ?\n",
    "            select @endtime = ?\n",
    "            select distinct\tt.LutId as 'MEOLUT ID', \n",
    "                    t.AntennaId as 'Antenna ID', \n",
    "                    t.SatId as 'Sat ID', \n",
    "                    t.AOSStr as 'AOS_Time', \n",
    "                    t.LOSStr as 'LOS_Time', \n",
    "                    DATEDIFF(second,t.AOSStr,t.LOSStr)/60 as 'Duration', \n",
    "                    NULL as 'Azimuth at AOS',\n",
    "                    NULL as 'Elevation at AOS', \n",
    "                    NULL as 'Azimuth at LOS', \n",
    "                    NULL as 'Elevation at LOS' \n",
    "            FROM [MccMeoLutMonitor].[dbo].[PassesTaken] t\n",
    "            WHERE\n",
    "                t.AntennaId <> 7 AND (t.AntennaId <> 8)\n",
    "                AND ((@starttime between t.AOSStr and t.LOSStr) \n",
    "                    or (@endtime between t.AOSStr and t.LOSStr)\n",
    "                    or (t.LOSStr between @starttime and @endtime) \n",
    "                    OR (t.AOSStr between @starttime and @endtime)\n",
    "                    )\n",
    "                    AND t.LutId in (%s)\n",
    "                    order by aos_time\n",
    "            \"\"\" % placeholders\n",
    "\n",
    "        params = [StartTime, EndTime]\n",
    "        params.extend(MEOLUTList)\n",
    "        c = conn.cursor()\n",
    "        c.execute(sql_query, params)\n",
    "        columns = [column[0] for column in c.description]\n",
    "        out = c.fetchall()\n",
    "        if out:   \n",
    "            J3_file = os.path.join(OUTPUTFOLDER, 'J3_' + meoListString + '_{:%Y-%m-%d-%H%M}_{:%Y-%m-%d-%H%M}'.format(StartTime, EndTime) + '.csv')\n",
    "            outfile_dict[J3_file] = 'J3 - MEOLUT Tracked Passes'\n",
    "            with open(os.path.join(approot,J3_file), 'wb') as csvfile:\n",
    "                csvoutwriter = csv.writer(csvfile, delimiter=',',\n",
    "                                        quoting=csv.QUOTE_MINIMAL)\n",
    "                csvoutwriter.writerow(columns)\n",
    "                for row in out:\n",
    "                    csvoutwriter.writerow(row)\n",
    "    return outfile_dict, BeaconID\n",
    "\n",
    "def api_meo_accuracy_all( config_dict, arg_dict, output_format = 'data_list'):\n",
    "    servername, databasename, OUTPUTFOLDER, approot = config_dict[\"servername\"], config_dict[\"oppsdatabase\"], config_dict[\"OUTPUTFOLDER\"], config_dict[\"approot\"]\n",
    "    conn = odbc.connect(r'Driver={SQL Server};Server='+servername+';Database='+databasename+';Trusted_Connection=yes;',readonly=True, autocommit = True)\n",
    "    meoListString = \"_\".join([str(i) for i in arg_dict['MEOLUTList']])\n",
    "    sql_query = \"\"\"\\\n",
    "        select * FROM [MccMeoLutMonitor].[dbo].[MeolutRealTimeLocationMonitor]\n",
    "        where AddTime between ? and ? \n",
    "        \"\"\"\n",
    "    params = [datetime.strftime(arg_dict.get('StartTime'), datetime_format), datetime.strftime(arg_dict.get('EndTime'), datetime_format)]\n",
    "    params = [arg_dict.get('StartTime'),arg_dict.get('EndTime')]\n",
    "    if arg_dict.get('MEOLUTList',False):\n",
    "        placeholders = \",\".join(\"?\" * len(arg_dict.get('MEOLUTList')))\n",
    "        sql_query += 'and LUT in ({})'.format(placeholders)\n",
    "        params.extend(arg_dict.get('MEOLUTList'))        \n",
    "    c = conn.cursor()\n",
    "    c.execute(sql_query, tuple(params))\n",
    "    columns = [column[0] for column in c.description]\n",
    "    out = c.fetchall()\n",
    "    if out:\n",
    "        meoListString = \"_\".join([str(i) for i in arg_dict.get('MEOLUTList')])\n",
    "        out_file_string = meoListString + '_{:%Y-%m-%d-%H%M}_{:%Y-%m-%d-%H%M}.csv'.format(arg_dict.get('StartTime'), arg_dict.get('EndTime'))    \n",
    "        output = sql_outputer(out, output_format, c,\n",
    "                            approot = approot,  \n",
    "                            OUTPUTFOLDER=OUTPUTFOLDER,\n",
    "                            out_file_string= out_file_string,\n",
    "                            ) \n",
    "        return output\n",
    "    return None\n",
    "\n",
    "def api_meo_ref_beacon_locations( arg_dict, config_dict, output_format = 'json'):\n",
    "    servername, databasename, OUTPUTFOLDER, approot = config_dict[\"servername\"], config_dict[\"oppsdatabase\"], config_dict[\"OUTPUTFOLDER\"], config_dict[\"approot\"]\n",
    "    conn = odbc.connect(r'Driver={SQL Server};Server='+servername+';Database='+databasename+';Trusted_Connection=yes;',readonly=True, autocommit = True)\n",
    "    if arg_dict.get('MEOLUTList',False): \n",
    "        meoListString = \"_\".join([str(i) for i in arg_dict['MEOLUTList']])\n",
    "        out_file_string = meoListString + '_{:%Y-%m-%d-%H%M}_{:%Y-%m-%d-%H%M}.csv'.format(arg_dict.get('StartTime'), arg_dict.get('EndTime'))    \n",
    "    sql_query = \"\"\"\\\n",
    "        select * FROM [MccMeoLutMonitor].[dbo].[MeolutRefBeaconLocations]\n",
    "        where AddTime between ? and ? \n",
    "        \"\"\"\n",
    "    params = [datetime.strftime(arg_dict.get('StartTime'), datetime_format), datetime.strftime(arg_dict.get('EndTime'), datetime_format)]\n",
    "    params = [arg_dict.get('StartTime'),arg_dict.get('EndTime')]\n",
    "    if arg_dict.get('MEOLUTList',False):\n",
    "        placeholders = \",\".join(\"?\" * len(arg_dict.get('MEOLUTList')))\n",
    "        sql_query += 'and MeolutId in ({})'.format(placeholders)\n",
    "        params.extend(arg_dict.get('MEOLUTList'))        \n",
    "    c = conn.cursor()\n",
    "    cur = c.execute(sql_query, tuple(params))\n",
    "    columns = [column[0] for column in c.description]\n",
    "    out = list()\n",
    "    for j in cur:\n",
    "        out.append(j) \n",
    "    if out:\n",
    "        out_file_string = '{:%Y-%m-%d-%H%M}_{:%Y-%m-%d-%H%M}.csv'.format(arg_dict.get('StartTime'), arg_dict.get('EndTime'))        \n",
    "        output = sql_outputer(out, output_format, c,\n",
    "                            approot = approot,  \n",
    "                            OUTPUTFOLDER=OUTPUTFOLDER,\n",
    "                            out_file_string= out_file_string,\n",
    "                            ) \n",
    "        return output\n",
    "    return None\n",
    "\n",
    "def api_leo_lmdb( config_dict, arg_dict, output_format = 'data_list'):\n",
    "    servername, databasename, OUTPUTFOLDER, approot = config_dict[\"servername\"], config_dict[\"oppsdatabase\"], config_dict[\"OUTPUTFOLDER\"], config_dict[\"approot\"]\n",
    "    conn = odbc.connect(r'Driver={SQL Server};Server='+servername+';Database='+databasename+';Trusted_Connection=yes;',readonly=True, autocommit = True)\n",
    "    leoListString = \"_\".join([str(i) for i in arg_dict['LEOLUTList']])\n",
    "    columns = ['LUT','SAT','ORBIT','AOS','LOS','AzAOS','AzTCA','AzLOS','SCHEDULED','CONFLICT',\n",
    "    'PassMissed','PassMissedReason','MissExcused','MissExcuseReason','MaxElavation','PassRcvdMCC',\n",
    "    'INSPEC','Num406','NumINT','MccRcvd','PassSummaryReceived','TimeStamp']\n",
    "    sql_query = \"\"\"\\\n",
    "        select {} FROM [MccMeoLutMonitor].[dbo].[LMDB]\n",
    "        where AOS between ? and ? \n",
    "        \"\"\".format(\",\".join(columns))\n",
    "    params = [datetime.strftime(arg_dict.get('StartTime'), datetime_format), datetime.strftime(arg_dict.get('EndTime'), datetime_format)]\n",
    "    params = [arg_dict.get('StartTime'),arg_dict.get('EndTime')]\n",
    "    if arg_dict.get('LEOLUTList',False):\n",
    "        placeholders = \",\".join(\"?\" * len(arg_dict.get('LEOLUTList')))\n",
    "        sql_query += 'and LUT in ({})'.format(placeholders)\n",
    "        params.extend(arg_dict.get('LEOLUTList'))        \n",
    "    c = conn.cursor()\n",
    "    c.execute(sql_query, tuple(params))\n",
    "    columns = [column[0] for column in c.description]\n",
    "    out = c.fetchall()\n",
    "    if out:\n",
    "        leoListString = \"_\".join([str(i) for i in arg_dict.get('LEOLUTList')])\n",
    "        out_file_string = leoListString + '_{:%Y-%m-%d-%H%M}_{:%Y-%m-%d-%H%M}.csv'.format(arg_dict.get('StartTime'), arg_dict.get('EndTime'))    \n",
    "        output = sql_outputer(out, output_format, c,\n",
    "                            approot = approot,  \n",
    "                            OUTPUTFOLDER=OUTPUTFOLDER,\n",
    "                            out_file_string= out_file_string,\n",
    "                            ) \n",
    "        return output\n",
    "    return None\n",
    "    \n",
    "\n",
    "def api_meo_schedule(MEOLUTList, StartTime, EndTime, output_format, config_dict):\n",
    "    servername, databasename, OUTPUTFOLDER, approot = config_dict[\"servername\"], config_dict[\"oppsdatabase\"], config_dict[\"OUTPUTFOLDER\"], config_dict[\"approot\"]\n",
    "    conn = odbc.connect(r'Driver={SQL Server};Server='+servername+';Database='+databasename+';Trusted_Connection=yes;',readonly=True, autocommit = True)\n",
    "    meoListString = \"_\".join([str(i) for i in MEOLUTList])\n",
    "    placeholders = \",\".join(\"?\" * len(MEOLUTList))\n",
    "    sql_query = \"\"\"\\\n",
    "        --J3 Format--MEO\n",
    "        declare @starttime datetime, @endtime datetime\n",
    "        select @starttime = ?\n",
    "        select @endtime = ?\n",
    "        select distinct\tt.LutId as 'MEOLUT ID', \n",
    "                t.AntennaId as 'Antenna ID', \n",
    "                t.SatId as 'Sat ID', \n",
    "                t.AOSStr as 'AOS_Time', \n",
    "                t.LOSStr as 'LOS_Time', \n",
    "                DATEDIFF(second,t.AOSStr,t.LOSStr)/60 as 'Duration', \n",
    "                NULL as 'Azimuth at AOS',\n",
    "                NULL as 'Elevation at AOS', \n",
    "                NULL as 'Azimuth at LOS', \n",
    "                NULL as 'Elevation at LOS' \n",
    "        FROM [MccMeoLutMonitor].[dbo].[PassesTaken] t\n",
    "        WHERE\n",
    "            t.AntennaId <> 7 AND (t.AntennaId <> 8)\n",
    "            AND ((@starttime between t.AOSStr and t.LOSStr) \n",
    "                or (@endtime between t.AOSStr and t.LOSStr)\n",
    "                or (t.LOSStr between @starttime and @endtime) \n",
    "                OR (t.AOSStr between @starttime and @endtime)\n",
    "                )\n",
    "                AND t.LutId in (%s)\n",
    "                order by aos_time\n",
    "        \"\"\" % placeholders\n",
    "\n",
    "    params = [StartTime, EndTime]\n",
    "    params.extend(MEOLUTList)\n",
    "    c = conn.cursor()\n",
    "    c.execute(sql_query, params)\n",
    "    columns = [column[0] for column in c.description]\n",
    "    out = c.fetchall()\n",
    "    if out:\n",
    "        meoListString = \"_\".join([str(i) for i in MEOLUTList])\n",
    "        out_file_string='J3_' + meoListString + '_{:%Y-%m-%d-%H%M}_{:%Y-%m-%d-%H%M}.csv'.format(StartTime, EndTime)    \n",
    "        return sql_outputer(out, output_format, c,\n",
    "                            approot = approot,  \n",
    "                            OUTPUTFOLDER=OUTPUTFOLDER,\n",
    "                            out_file_string= out_file_string,\n",
    "                            )\n",
    "        # if output_format == 'csv':   \n",
    "        #     meoListString = \"_\".join([str(i) for i in MEOLUTList])\n",
    "        #     J3_file = os.path.join(OUTPUTFOLDER, 'J3_' + meoListString + '_{:%Y-%m-%d-%H%M}_{:%Y-%m-%d-%H%M}.csv'.format(StartTime, EndTime) )\n",
    "        #     with open(os.path.join(approot,J3_file), 'wb') as csvfile:\n",
    "        #         csvoutwriter = csv.writer(csvfile, delimiter=',',\n",
    "        #                                 quoting=csv.QUOTE_MINIMAL)\n",
    "        #         csvoutwriter.writerow(columns)\n",
    "        #         for row in out:\n",
    "        #             csvoutwriter.writerow(row)\n",
    "        #     return J3_file\n",
    "        # if output_format == 'json':\n",
    "        #     r = [dict((c.description[i][0], value) \\\n",
    "        #     for i, value in enumerate(row)) for row in out]\n",
    "        #     return (r[0] if r else None) if one else r\n",
    "        # else:\n",
    "        #     outdata = [columns]\n",
    "        #     for row in out:\n",
    "        #         outdata.append(row)\n",
    "        #     return outdata\n",
    "\n",
    "def sql_outputer(outdata, output_format, c, one=False, **kwargs ):\n",
    "    columns = [column[0] for column in c.description]\n",
    "    if output_format == 'csv':   \n",
    "        csv_out_file = os.path.join(kwargs.get('OUTPUTFOLDER') + kwargs.get('out_file_string'))\n",
    "        with open(os.path.join(kwargs.get('approot'),csv_out_file), 'wb') as csvfile:\n",
    "            csvoutwriter = csv.writer(csvfile, delimiter=',',\n",
    "                                    quoting=csv.QUOTE_MINIMAL)\n",
    "            csvoutwriter.writerow(columns)\n",
    "            for row in outdata:\n",
    "                csvoutwriter.writerow(row)\n",
    "        return csv_out_file\n",
    "    if output_format == 'json':\n",
    "        r = [dict((c.description[i][0], value) \\\n",
    "            for i, value in enumerate(row)) for row in outdata]\n",
    "        return (r[0] if r else None) if one else r\n",
    "    else:\n",
    "        output_data = [columns]\n",
    "        for row in outdata:\n",
    "            output_data.append(row)\n",
    "        return output_data\n",
    "\n",
    "def api_meo_ref_beacon_accuracy(MEOLUT, StartTime, EndTime, arg_dict, config_dict, **kwargs):\n",
    "    servername, databasename  = config_dict[\"servername\"], config_dict[\"oppsdatabase\"]\n",
    "    timedelta_secs = (EndTime - StartTime).total_seconds()\n",
    "    expected_locations = timedelta_secs/50.0\n",
    "    if not kwargs.get('distlist',False):\n",
    "        distlist = [2, 5, 10, 20]\n",
    "        outdistdict = {}\n",
    "    keylist = ['percent_less_than_'+str(dist)+'km' for dist in distlist]\n",
    "    numlist = ['number_less_than_'+str(dist)+'km' for dist in distlist]\n",
    "    RefBeacon = arg_dict.get('RefBeacon', MEOLUTref[MEOLUT])\n",
    "    beacon = ReferenceBeacons[RefBeacon]\n",
    "    conn = odbc.connect(r'Driver={SQL Server};Server='+servername+';Database='+databasename+';Trusted_Connection=yes;',readonly=True, autocommit = True)\n",
    "    sql_query = \"\"\" Select Latitude, Longitude FROM [MccMeoLutMonitor].[dbo].[InputMeoSolution] \n",
    "        WHERE Datatype = 0 AND SourceId = ? \n",
    "        AND bcnId15 = ? \n",
    "        AND TimeLast between ? AND ? \"\"\"\n",
    "    params = [MEOLUT, beacon['beaconId'], StartTime, EndTime]\n",
    "    c = conn.cursor()\n",
    "    c.execute(sql_query, params)\n",
    "    out = c.fetchall()\n",
    "    output = {'SourceId': MEOLUT, 'RefBeacon': RefBeacon, 'StartTime': StartTime, \n",
    "                'EndTime': EndTime, 'beaconId': beacon['beaconId'], 'expected_locations': expected_locations,\n",
    "                'beaconLat': beacon['beaconLat'], 'beaconLon': beacon['beaconLon']}\n",
    "    if not out: \n",
    "        output.update({\"mean\": None, \n",
    "        \"median\": None, \n",
    "        \"num_of_locations\": 0, \n",
    "        \"p75\": None, \n",
    "        \"p90\": None, \n",
    "        \"p95\": None, \n",
    "        \"percent_locations\": 0})\n",
    "        for key in keylist: \n",
    "            output.update({key: None})\n",
    "        for num in numlist: \n",
    "            output.update({num: None})\n",
    "        return output \n",
    "    else: \n",
    "        out_dict = [dict((c.description[i][0], value) \\\n",
    "            for i, value in enumerate(row)) for row in out]\n",
    "        out_distlist = []\n",
    "        num_of_locations = len(out)\n",
    "        output.update({'num_of_locations': num_of_locations})\n",
    "        for row in out_dict:\n",
    "            out_distlist.append(haversine((row['latitude'],row['longitude'],beacon['beaconLat'],beacon['beaconLon'])))\n",
    "        output.update({'p75': np.percentile(out_distlist, 75),\n",
    "                        'p90': np.percentile(out_distlist, 90),\n",
    "                        'p95': np.percentile(out_distlist, 95)})\n",
    "        for i, dist in enumerate(distlist):\n",
    "            under_dist = [x for x in out_distlist if x < dist]\n",
    "            output.update({keylist[i]: (100.0*len([x for x in out_distlist if x < dist]))/num_of_locations,\n",
    "                            numlist[i]: len([x for x in out_distlist if x < dist])})\n",
    "        output.update({'percent_locations': 100.0*len(out_distlist)/expected_locations})\n",
    "        return output\n",
    "        \n",
    "\n",
    "    \n",
    "# check if out and then update output dict (locations, percentages) before returning \n",
    "\n",
    "def api_meo_location_accuracy(MEOLUT, StartTime, EndTime, config_dict, **kwargs):\n",
    "    output = {}\n",
    "    output[MEOLUT]={}\n",
    "    servername, databasename  = config_dict[\"servername\"], config_dict[\"oppsdatabase\"]\n",
    "    timedelta_secs = (EndTime - StartTime).total_seconds()\n",
    "    if not kwargs.get('distList',False):\n",
    "        distList = [2, 5, 10, 20]\n",
    "        outdistdict = {}\n",
    "    keylist = ['percent_less_than_'+str(dist)+'km' for dist in distList]\n",
    "    numlist = ['number_less_than_'+str(dist)+'km' for dist in distList]\n",
    "    \n",
    "    if 'sql_login' in kwargs:\n",
    "        conn = odbc.connect(r'Driver={FreeTDS};Server='+servername+';Database='+databasename+'; UID='+UID+'; PWD=' + PWD, autocommit = True)\n",
    "    else:\n",
    "        conn = odbc.connect(r'Driver={SQL Server};Server='+servername+';Database='+databasename+';Trusted_Connection=yes;',readonly=True, autocommit = True)\n",
    "    sql_query = \"\"\"\\\n",
    "        select TOP(1)\n",
    "\t        \n",
    "\t        num_of_locations = count(distance) OVER (PARTITION BY SourceId),\n",
    "\t        mean = avg(distance) OVER (PARTITION BY SourceId), \n",
    "\t        median = PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY distance) OVER (PARTITION BY [SourceId]), \n",
    "\t        P75 = PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY distance) OVER (PARTITION BY [SourceId]), \n",
    "            P90 = PERCENTILE_CONT(0.9) WITHIN GROUP (ORDER BY distance) OVER (PARTITION BY [SourceId]), \n",
    "\t        P95 = PERCENTILE_CONT(0.95) WITHIN GROUP (ORDER BY distance) OVER (PARTITION BY [SourceId]) \n",
    "        FROM [MccMeoLutMonitor].[dbo].[InputMeoSolution] \n",
    "        WHERE Distance is not null \n",
    "        AND SourceId = ?\n",
    "        AND TimeLast between ? AND ? \n",
    "        \"\"\"\n",
    "    params = [MEOLUT, StartTime, EndTime]\n",
    "    if kwargs.get('beaconId',False):\n",
    "        beacon_string = kwargs.get('beaconId')\n",
    "        sql_query += 'AND bcnId15 like ?'\n",
    "        params.append(beacon_string)\n",
    "    c = conn.cursor()\n",
    "    c.execute(sql_query, params)\n",
    "    columns = [column[0] for column in c.description]\n",
    "    out = c.fetchone()\n",
    "\n",
    "    if out: \n",
    "        #output['count'] = int(out[1])\n",
    "        for ind, col in enumerate(columns):\n",
    "            output[MEOLUT][col] = out[ind]\n",
    "    else: \n",
    "        for ind, col in enumerate(columns):\n",
    "            output[MEOLUT][col] = 0\n",
    "            #output['count'] = 0\n",
    "        for dist in distList:\n",
    "            output[MEOLUT]['percent_less_than_'+str(dist)+'km'] = 0\n",
    "            output[MEOLUT]['number_less_than_'+str(dist)+'km'] = 0\n",
    "        output[MEOLUT]['percent_locations'] = 0\n",
    "        return output\n",
    "    \n",
    "    # Only get down here if you have any solutions - ie out has data \n",
    "    output[MEOLUT]['percent_locations'] = 100.0* output[MEOLUT]['num_of_locations']/(float(timedelta_secs/50))\n",
    "    sql_query = \"\"\"\\\n",
    "        SELECT DISTANCE\n",
    "        FROM [MccMeoLutMonitor].[dbo].[InputMeoSolution] \n",
    "        WHERE Distance is not null \n",
    "        AND SourceId = ?\n",
    "        AND TimeLast between ? AND ? \n",
    "        \n",
    "        \"\"\"\n",
    "    params = [MEOLUT, StartTime, EndTime]\n",
    "    if kwargs.get('beaconId',False):\n",
    "        beacon_string = kwargs.get('beaconId')\n",
    "        sql_query += 'AND bcnId15 like ?'\n",
    "        params.append(beacon_string)\n",
    "\n",
    "    c = conn.cursor()\n",
    "    c.execute(sql_query, params)\n",
    "    out = c.fetchall()\n",
    "    for dist in distList:\n",
    "        outdistdict[dist] = sum(i[0] < dist for i in out)\n",
    "        output[MEOLUT]['number_less_than_' + str(dist)+'km'] = sum(i[0] < dist for i in out)\n",
    "        output[MEOLUT]['percent_less_than_' + str(dist)+'km'] = (100.0*sum(i[0] < dist for i in out))/float(output[MEOLUT]['num_of_locations'])\n",
    "    return output\n",
    "\n",
    "def real_time_packet_stats(MEOLUT, Time, config_dict):\n",
    "    servername, databasename  = config_dict[\"servername\"], config_dict[\"oppsdatabase\"]\n",
    "    conn = odbc.connect(r'Driver={SQL Server};Server='+servername+';Database='+databasename+';Trusted_Connection=yes;', readonly=True, autocommit = True)\n",
    "    sql_query = \"\"\"\\\n",
    "        SELECT TOP (1) *\n",
    "        FROM [MccMeoLutMonitor].[dbo].[MeolutRealTimeMonitor]\n",
    "        where MeolutId = ? and \n",
    "        AddTime < ?\n",
    "        order by AddTime desc \n",
    "        \"\"\"\n",
    "    params = [MEOLUT, Time]\n",
    "    c = conn.cursor()\n",
    "    c.execute(sql_query, params)\n",
    "    out = c.fetchall()\n",
    "    columns = [column[0] for column in c.description]\n",
    "    r = [dict((c.description[i][0], str(value)) \\\n",
    "    for i, value in enumerate(row)) for row in out]\n",
    "    return (r[0] if r else None)\n",
    "\n",
    "def api_meo_packet_throughput(MEOLUT, StartTime, EndTime, config_dict, rep_rate, minutes, **kwargs):\n",
    "    servername, databasename  = config_dict[\"servername\"], config_dict[\"oppsdatabase\"]\n",
    "    if 'sql_login' in kwargs:\n",
    "        conn = odbc.connect(r'Driver={FreeTDS};Server='+servername+';Database='+databasename+'; UID='+UID+'; PWD=' + PWD, readonly=True, autocommit = True)\n",
    "    else:\n",
    "        conn = odbc.connect(r'Driver={SQL Server};Server='+servername+';Database='+databasename+';Trusted_Connection=yes;', readonly=True, autocommit = True)\n",
    "    sql_query = \"\"\"\\\n",
    "        select DISTINCT\n",
    "            [antennaId],\n",
    "\t\t\tnum = count(DbId) OVER (PARTITION BY antennaId) \n",
    "        FROM [MccMeoLutMonitor].[dbo].[MeolutPackets] \n",
    "        WHERE MeolutId = ?\n",
    "        AND UplinkTOADate between ? AND ? \n",
    "    \"\"\"\n",
    "    timedelta_secs = (EndTime - StartTime).total_seconds()\n",
    "    params = [MEOLUT, StartTime, EndTime]\n",
    "    if kwargs['beaconId']:\n",
    "        beacon_string = kwargs.get('beaconId')\n",
    "        sql_query += 'AND bcnId15 like ?'\n",
    "        params.append(beacon_string)\n",
    "    c = conn.cursor()\n",
    "    c.execute(sql_query, params)\n",
    "    columns = [column[0] for column in c.description]\n",
    "    out = c.fetchall()\n",
    "    output = {'MEOLUT': MEOLUT, 'antenna': OrderedDict()}\n",
    "    if (MEOLUT == 3669):\n",
    "        ant_len = 9\n",
    "    elif (MEOLUT == 3385):\n",
    "        ant_len = 8 \n",
    "    else:\n",
    "        ant_len = 2\n",
    "    for i in range(1,ant_len+1):\n",
    "        output['antenna'][i] = {'count': 0, 'percent' : 0}\n",
    "    for j in out: \n",
    "        output['antenna'][j[0]]['count'] = j[1]\n",
    "        if rep_rate:\n",
    "            output['antenna'][j[0]]['percent'] = 100.0*float(j[1])/float(timedelta_secs / float(rep_rate))\n",
    "\n",
    "    return output\n",
    "def api_site_sum_query(arg_dict, config_dict, **kwargs):\n",
    "    servername, databasename, OUTPUTFOLDER, approot = config_dict[\"servername\"], config_dict[\"oppsdatabase\"], config_dict[\"OUTPUTFOLDER\"], config_dict[\"approot\"]\n",
    "    conn = odbc.connect(r'Driver={SQL Server};Server='+servername+';Database='+databasename+';Trusted_Connection=yes;',readonly=True, autocommit = True)\n",
    "     \n",
    "    fieldlist = ['AlertSiteNum, BcnId15', 'BcnId30', 'BcnType', 'MidName', 'CompLat', 'CompLon', 'Closed', \n",
    "                 'OpenTime', 'CloseTime', 'TimeFirst', 'TimeLast', 'LastUpdTime', 'NumMsgSent', \n",
    "                 'MsgTimeLast', 'NumPasses', 'NumSol', 'NumLeoGeoSol', 'NumDopSol', 'NumMeoSol']   \n",
    "    sql_query_field_list = ', '.join(fieldlist)\n",
    "    params = []\n",
    "    NOMAS = False # as in \"No mas\" - set to True to stop adding to query string\n",
    "    print 'in init'\n",
    "    print arg_dict\n",
    "    if arg_dict.get('sitenum'):\n",
    "        sql_query = \"\"\" select top 1 {} FROM \n",
    "            AlertSiteSum WHERE \n",
    "            AlertSiteNum = ? \n",
    "            ORDER BY TimeLast \"\"\".format(sql_query_field_list)\n",
    "        params.append(arg_dict['sitenum'])\n",
    "        NOMAS = True\n",
    "    else:    \n",
    "        sql_query = \"\"\" SELECT {} from AlertSiteSum \"\"\".format(sql_query_field_list)\n",
    "        if arg_dict.get('open_closed') == 'closed':\n",
    "            sql_query+=' WHERE Closed = ? '\n",
    "            params.append('Y')\n",
    "        elif arg_dict.get('open_closed') == 'open': \n",
    "            sql_query+=' WHERE Closed = ? ' \n",
    "            params.append('N')\n",
    "\n",
    "    if arg_dict.get('StartTime') and not NOMAS:\n",
    "        if sql_query.find(\"WHERE\") == -1: sql_query+= ' WHERE LastUpdTime > ?'\n",
    "        else: sql_query+=(' AND LastUpdTime > ?')\n",
    "        params.append(arg_dict['StartTime'])\n",
    "    if arg_dict.get('EndTime') and not NOMAS:\n",
    "        if sql_query.find(\"WHERE\") ==-1: sql_query+= ' WHERE TimeFirst < ?'\n",
    "        else: sql_query+=(' AND TimeFirst < ? ')\n",
    "        params.append(arg_dict['EndTime'])\n",
    "\n",
    "    if arg_dict.get('open_closed')=='all_open':\n",
    "        sql_query = \"\"\"\n",
    "            SELECT {} from AlertSiteSum \n",
    "            WHERE CLOSED = ? \"\"\".format(sql_query_field_list)\n",
    "        params = ['N']\n",
    "    c = conn.cursor()\n",
    "    c.execute(sql_query, tuple(params))\n",
    "    out = c.fetchall()\n",
    "    columns = [column[0] for column in c.description]\n",
    "    if out:\n",
    "        out_file_string = '_SiteSum_{:%Y-%m-%d-%H%M}_{:%Y-%m-%d-%H%M}.csv'.format(arg_dict.get('StartTime'), arg_dict.get('EndTime'))    \n",
    "        output = sql_outputer(out, arg_dict['output_format'], c,\n",
    "                            approot = approot,  \n",
    "                            OUTPUTFOLDER=OUTPUTFOLDER,\n",
    "                            out_file_string= out_file_string,\n",
    "                            ) \n",
    "        return output\n",
    "    else: return None\n",
    "def api_site(config_dict, sitenum = None, table = None, type = 'all', one= False, **kwargs):\n",
    "    servername, databasename  = config_dict[\"servername\"], config_dict[\"oppsdatabase\"]    \n",
    "    if 'sql_login' in kwargs:\n",
    "        conn = odbc.connect(r'Driver={FreeTDS};Server='+servername+';Database='+databasename+'; UID='+UID+'; PWD=' + PWD,readonly=True, autocommit = True)\n",
    "    else:\n",
    "        conn = odbc.connect(r'Driver={SQL Server};Server='+servername+';Database='+databasename+';Trusted_Connection=yes;',readonly=True, autocommit = True)\n",
    "    if 'data' in kwargs:\n",
    "        if not table: table = data.get('table','alertsitesol')\n",
    "        if not sitenum: sitenum = data.get('sitenum',None)\n",
    "    sql_query = \"\"\" SELECT * FROM [MccMeoLutMonitor].[dbo].[%s] \n",
    "        WHERE AlertSiteNum = ?\n",
    "        \"\"\" % table\n",
    "    if type == 'leo':\n",
    "        sql_query+= 'AND a_lat is not NULL'\n",
    "    if type == 'meo':\n",
    "        sql_query+= \"AND InputDataType = 'M'\"\n",
    "    if type == 'enc':\n",
    "        sql_query+= \"AND EncLat is not NULL\"\n",
    "    if type == 'comp':\n",
    "        sql_query+= \"AND CompLat is not NULL \"\n",
    "\n",
    "    params = [sitenum]\n",
    "    c = conn.cursor()\n",
    "    c.execute(sql_query, params)\n",
    "    r = [dict((c.description[i][0], value) \\\n",
    "        for i, value in enumerate(row)) for row in c.fetchall()]\n",
    "    columns = [column[0] for column in c.description]\n",
    "    return (r[0] if r else None) if one else r\n",
    "\n",
    "def api_JSON_leo_geo_sols(data, config_dict, **kwargs):\n",
    "    servername, databasename  = config_dict[\"servername\"], config_dict[\"oppsdatabase\"]\n",
    "    if 'sql_login' in kwargs:\n",
    "        conn = odbc.connect(r'Driver={FreeTDS};Server='+servername+';Database='+databasename+'; UID='+UID+'; PWD=' + PWD,readonly=True, autocommit = True)\n",
    "    else:\n",
    "        conn = odbc.connect(r'Driver={SQL Server};Server='+servername+';Database='+databasename+';Trusted_Connection=yes;',readonly=True, autocommit = True)\n",
    "    sql_query = \"\"\"\\\n",
    "        SELECT CAST( (SELECT * FROM [MccMeoLutMonitor].[dbo].[Lut406Solution] \n",
    "        \"\"\" \n",
    "    where = []\n",
    "    params = []\n",
    "    if data.get('bcnId15', None):\n",
    "        where.append(\" bcnId15 like ? \")\n",
    "        params.append(data['bcnId15'])\n",
    "    if data.get('startTime', None):\n",
    "        where.append(\" A_Tca > ? \")\n",
    "        params.append(data['startTime'])\n",
    "    if data.get('endTime', None):\n",
    "        where.append(\" A_Tca < ? \")\n",
    "        params.append(data['endTime'])\n",
    "    if data.get('lut', None):\n",
    "        where.append(\" lut like ? \")\n",
    "        params.append(data['lut'])\n",
    "    if data.get('sat', None):\n",
    "        where.append(\" sat = ? \")\n",
    "        params.append(data['sat'])\n",
    "    if where: \n",
    "        sql_query = '{} WHERE {}'.format(sql_query, ' AND '.join(where))\n",
    "    sql_query_end = \"\"\"\\\n",
    "        FOR JSON PATH) \n",
    "        AS VARCHAR(MAX))\n",
    "        \"\"\"\n",
    "    sql_query += sql_query_end  \n",
    "    c = conn.cursor()\n",
    "    c.execute(sql_query, params)\n",
    "    columns = [column[0] for column in c.description]\n",
    "    out = c.fetchone()\n",
    "    return out \n",
    "\n",
    "def api_output_sols(data, config_dict, sitenum = None, **kwargs):\n",
    "    servername, databasename  = config_dict[\"servername\"], config_dict[\"oppsdatabase\"]\n",
    "    if 'sql_login' in kwargs:\n",
    "        conn = odbc.connect(r'Driver={FreeTDS};Server='+servername+';Database='+databasename+'; UID='+UID+'; PWD=' + PWD,readonly=True, autocommit = True)\n",
    "    else:\n",
    "        conn = odbc.connect(r'Driver={SQL Server};Server='+servername+';Database='+databasename+';Trusted_Connection=yes;',readonly=True, autocommit = True)\n",
    "    sql_query = \"\"\"\\\n",
    "        SELECT * FROM [MccMeoLutMonitor].[dbo].[OutSolution] \n",
    "        WHERE AlertSiteNum = ?\n",
    "        \"\"\" \n",
    "    params = [sitenum]\n",
    "    c = conn.cursor()\n",
    "    c.execute(sql_query, params)\n",
    "    columns = [column[0] for column in c.description]\n",
    "    outdata = c.fetchall()\n",
    "\n",
    "\n",
    "    return columns, outdata\n",
    "\n",
    "def api_JSON_output_sols(data, config_dict, sitenum = None, **kwargs):\n",
    "    servername, databasename  = config_dict[\"servername\"], config_dict[\"oppsdatabase\"]\n",
    "    if 'sql_login' in kwargs:\n",
    "        conn = odbc.connect(r'Driver={FreeTDS};Server='+servername+';Database='+databasename+'; UID='+UID+'; PWD=' + PWD, readonly=True, autocommit = True)\n",
    "    else:\n",
    "        conn = odbc.connect(r'Driver={SQL Server};Server='+servername+';Database='+databasename+';Trusted_Connection=yes;',readonly=True, autocommit = True)\n",
    "    sql_query = \"\"\"\\\n",
    "        SELECT CAST( (SELECT * FROM [MccMeoLutMonitor].[dbo].[OutSolution] \n",
    "        WHERE AlertSiteNum = ?\n",
    "        FOR JSON PATH) \n",
    "        AS VARCHAR(MAX)) \n",
    "        \"\"\" \n",
    "    params = [sitenum]\n",
    "    c = conn.cursor()\n",
    "    c.execute(sql_query, params)\n",
    "    columns = [column[0] for column in c.description]\n",
    "    out = c.fetchone()\n",
    "    return out\n",
    "\n",
    "def czml_all_sites_sum_query(servername = 'localhost', databasename='mccoperational', **kwargs):\n",
    "    if 'sql_login' in kwargs:\n",
    "        conn = odbc.connect(r'Driver={FreeTDS};Server='+servername+';Database='+databasename+'; UID='+UID+'; PWD=' + PWD, readonly=True, autocommit = True)\n",
    "    else:\n",
    "        conn = odbc.connect(r'Driver={SQL Server};Server='+servername+';Database='+databasename+';Trusted_Connection=yes;',readonly=True, autocommit = True)\n",
    "    fieldname = OrderedDict()      \n",
    "    fieldlist = ['AlertSiteNum', 'BcnId15', 'MidName', 'BcnType', 'OpenTime', 'LastUpdTime', \n",
    "                 'CompLat', 'CompLon','NumSol', 'NumMeoSol', 'NumDopSol', 'NumEncSol', \n",
    "                 'NumCompCalc', 'NumMsgSent', 'MsgTimeLast', 'CurSarNameList', 'BcnIsRegistered']\n",
    "    sql_query_field_list = ', '.join(fieldlist)\n",
    "    sql_query = ('select ' + sql_query_field_list + ' FROM '\n",
    "                'AlertSiteSum WHERE '\n",
    "                'Closed = ? '\n",
    "                'ORDER BY OpenTime DESC '\n",
    "                )\n",
    "    params=['N']\n",
    "    c = conn.cursor()\n",
    "    c.execute(sql_query, params)\n",
    "    out = c.fetchall()\n",
    "    r = OrderedDict()\n",
    "    idlist = [{\"id\":\"document\", \"version\":\"1.0\"}]\n",
    "    for i in out:\n",
    "        r[i[0]]= {fieldlist[j]: value for j, value in enumerate(i)}\n",
    "        if i[7] <> \"NULL\" and i[6] <> \"NULL\" and i[6] is not None:\n",
    "            idlist.append({\"id\": str(int(i[0])),\n",
    "                           \"parent\": 'realtimesites',\n",
    "                           \"label\": {\n",
    "                               \"text\": str(int(i[0])),\n",
    "                               \"show\": True,\n",
    "                               \"horizontalOrigin\": \"CENTER\",\n",
    "                               \"pixelOffset\": {\n",
    "                                   \"cartesian2\" : [0, 20]\n",
    "                                },\n",
    "                               \"font\": \"14pt Verdana\"\n",
    "                            },  \n",
    "                            \"position\": {\n",
    "                                \"cartographicDegrees\": [float(i[7]),float(i[6]),0]\n",
    "                            }, \n",
    "                            \"point\": {\n",
    "                                \"color\": { \"rgba\": [0,0,255,255] },\n",
    "                                \"pixelSize\": math.ceil(i[8]/100),\n",
    "                                \"outlineColor\": {\n",
    "                                    \"rgba\": [255, 0, 0, 255]\n",
    "                                },\n",
    "                                \"outlineWidth\" : 1\n",
    "                            },\n",
    "                            \"description\": \"<br>\".join([str(fieldlist[j]) + \" : \" + str(value) for j, value in enumerate(i)])})\n",
    "    try:\n",
    "        return idlist\n",
    "    except: \n",
    "        return None\n",
    "\n",
    "def czml_meolut_ant_per(attime, bcnid, sourceid, servername = 'localhost', databasename='mccoperational', **kwargs):\n",
    "    if 'sql_login' in kwargs:\n",
    "        conn = odbc.connect(r'Driver={FreeTDS};Server='+servername+';Database='+databasename+'; UID='+UID+'; PWD=' + PWD, readonly=True, autocommit = True)\n",
    "    else:\n",
    "        conn = odbc.connect(r'Driver={SQL Server};Server='+servername+';Database='+databasename+';Trusted_Connection=yes;',readonly=True, autocommit = True)\n",
    "    UseMCC = True\n",
    "    fieldname = OrderedDict()      \n",
    "    fieldlist = ['RecordTime', 'RunStartTime', 'RunEndTime', 'Ant01Per', \n",
    "                'Ant02Per', 'Ant03Per', 'Ant04Per', 'Ant05Per', 'Ant06Per']\n",
    "    sql_query_field_list = ', '.join(fieldlist)\n",
    "    sql_query = ('select top 1 ' + sql_query_field_list + ' FROM '\n",
    "                '[MccTestLGM].[dbo].[MeolutMonitor] WHERE '\n",
    "                'SourceId = ? AND '\n",
    "                'BcnId15 = ? AND '\n",
    "                'RecordTime < ? '\n",
    "                'ORDER BY RecordTime DESC '\n",
    "                )\n",
    "    params=[sourceid, bcnid, attime]\n",
    "    c = conn.cursor()\n",
    "    c.execute(sql_query, params)\n",
    "    out = c.fetchall()\n",
    "    doc = czml.CZML()\n",
    "    packet1 = czml.CZMLPacket(id='document', version= '1.0')\n",
    "    doc.packets.append(packet1)\n",
    "    packet2 = czml.CZMLPacket(id = 'FL_MEO_Percent')\n",
    "    ant1 = czml.Point(position = 1, show = True)\n",
    "    ant1.color = {'rgba': [0, 255, 127, 55]}\n",
    "    packet2.billboard = ant1\n",
    "    doc.packets.append(packet2)\n",
    "    \n",
    "    doc.write('example.czml')\n",
    "    try:\n",
    "        return doc.dumps()\n",
    "    except: \n",
    "        return None\n",
    "\n",
    "\n",
    "def czml_site_meo_input(Sitenum, servername = 'localhost', databasename='mccoperational', **kwargs):\n",
    "    if 'sql_login' in kwargs:\n",
    "        conn = odbc.connect(r'Driver={FreeTDS};Server='+servername+';Database='+databasename+'; UID='+UID+'; PWD=' + PWD, readonly=True, autocommit = True)\n",
    "    else:\n",
    "        conn = odbc.connect(r'Driver={SQL Server};Server='+servername+';Database='+databasename+';Trusted_Connection=yes;',readonly=True, autocommit = True)\n",
    "    UseMCC = True\n",
    "    fieldname = OrderedDict()\n",
    "    if UseMCC:\n",
    "        fieldname['datatypename'] = 'datatype'\n",
    "        fieldname['bcn15name'] = 'bcnid15'\n",
    "        fieldname['bcn30name'] = 'bcnid30'\n",
    "        fieldname['sourceidname'] = 'sourceid'\n",
    "        fieldname['timefirstname'] = 'timefirst'\n",
    "        fieldname['timelastname'] = 'timelast'\n",
    "        fieldname['latname'] = 'latitude'\n",
    "        fieldname['lonname'] = 'longitude'\n",
    "        fieldname['altname'] = 'altitude'\n",
    "        fieldname['numburstsname'] = 'numbursts'\n",
    "        fieldname['numpacketsname'] = 'numpackets'\n",
    "        fieldname['numsatsname'] = 'numsatellites'\n",
    "        fieldname['dopname'] = 'dop'\n",
    "        fieldname['cn0name'] = 'averagecn0'\n",
    "        fieldname['ehename'] = 'expectedhorzerror'\n",
    "        fieldname['satidsname'] = 'satelliteids'    \n",
    "    fieldlist = [fieldname[key] for i, key in enumerate(fieldname)]\n",
    "  \n",
    "    sql_query_field_list = ', '.join(fieldlist)\n",
    "    sql_query = ('select ' + sql_query_field_list + ' FROM '\n",
    "                'InputMeoSolution where '\n",
    "                ' bcnid15 = '\n",
    "                '(select top 1 BcnId15 from '\n",
    "                'AlertSiteSum where AlertSiteNum = ? ORDER BY TimeLast ) '\n",
    "                )\n",
    "    params=[Sitenum]\n",
    "    c = conn.cursor()\n",
    "    c.execute(sql_query, params)\n",
    "    out = c.fetchall()\n",
    "    sql_query2 = ('select top 1 LastUpdTime from AlertSiteSum where AlertSiteNum = ? ')\n",
    "    c2 = conn.cursor()\n",
    "    c2.execute(sql_query2, [Sitenum])\n",
    "    LastUpdTime = c2.fetchone()\n",
    "    r = OrderedDict()\n",
    "    idlist = [{\"id\":\"document\", \"version\":\"1.0\"}]\n",
    "    for i in out:\n",
    "\n",
    "        r[i[0]]= {fieldlist[j]: value for j, value in enumerate(i)}\n",
    "        if (i[7] is not None) or (i[6] is not None):\n",
    "            idlist.append({\"id\": str((i[5])),\n",
    "                           \"name\": i[5].isoformat(),\n",
    "                           #\"availability\":\"2017-08-04T16:00:00Z/2017-09-04T17:00:00Z\",\n",
    "                           \"parent\": Sitenum,\n",
    "                           \"availability\":i[5].isoformat() + 'Z/' + LastUpdTime[0].isoformat() + 'Z',\n",
    "                           \"label\": {\n",
    "                               \"text\": str(int(i[0])),\n",
    "                               \"show\": False,\n",
    "                               \"horizontalOrigin\": \"CENTER\",\n",
    "                               \"pixelOffset\": {\n",
    "                                   \"cartesian2\" : [0, 20]\n",
    "                                },\n",
    "                               \"font\": \"14pt Verdana\"\n",
    "                            },  \n",
    "                            \"position\": {\n",
    "                                \"cartographicDegrees\": [float(i[7]),float(i[6]),0]\n",
    "                            }, \n",
    "                            \"point\": {\n",
    "                                \"color\": { \n",
    "                                    \"rgba\": [255,255,255,255] \n",
    "                                    },\n",
    "                                \"pixelSize\": 5,\n",
    "                                \"outlineColor\": {\n",
    "                                    \"rgba\": [233, 127, 21, 255]\n",
    "                                },\n",
    "                                \"outlineWidth\" : 2\n",
    "                            },\n",
    "                            \"description\": \"<br>\".join(['Site : ' + str(int(Sitenum))] + [str(fieldlist[j]) + \" : \" + str(value) for j, value in enumerate(i)])})\n",
    "    try:\n",
    "        return idlist\n",
    "    except: \n",
    "        return None\n",
    "\n",
    "\n",
    "def czml_alert_site(type, sitenum, jsonIn):\n",
    "    r = OrderedDict()\n",
    "    idlist = [{\"id\":\"document\", \"version\":\"1.0\"}]\n",
    "    delta = timedelta(minutes=(30))\n",
    "    if type == \"comp\":\n",
    "        pointcolor = [200,25,25,200]\n",
    "        nameheader = \"composite location: \"\n",
    "        pointsize = 10\n",
    "        lonfield, latfield ='complon', 'complat'\n",
    "    if type == \"leo\":\n",
    "        pointcolor = [100,100,100,100]\n",
    "        nameheader = \"leo location: \"\n",
    "        pointsize = 10\n",
    "        lonfield, latfield = 'a_lat', 'a_lon'\n",
    "    for solid, solution in jsonIn.iteritems():\n",
    "        #for field, value in solution.iteritems():\n",
    "        #idlist.append({field: value})\n",
    "        idlist.append({\"id\": str(solid),\n",
    "                        \"name\": nameheader + str(solid),\n",
    "                        #\"availability\":\"2017-08-04T16:00:00Z/9999-12-31T24:00:00Z\",\n",
    "                        \"parent\": str(sitenum),\n",
    "                        \"availability\":time_to_datetime(solution['addtime']).isoformat() +'Z/' + (time_to_datetime(solution['rcvtime'])+delta).isoformat() +'Z',\n",
    "                        \"label\": {\n",
    "                            \"text\": str(solid),\n",
    "                            \"show\": False,\n",
    "                            \"horizontalOrigin\": \"CENTER\",\n",
    "                            \"pixelOffset\": {\n",
    "                                \"cartesian2\" : [0, 20]\n",
    "                            },\n",
    "                            \"font\": \"8pt Verdana\"\n",
    "                        },  \n",
    "                        \"position\": {\n",
    "                            \"cartographicDegrees\": [solution[lonfield], solution[latfield],0]\n",
    "                        }, \n",
    "                        \"point\": {\n",
    "                            \"color\": { \n",
    "                                \"rgba\": pointcolor \n",
    "                                },\n",
    "                            \"pixelSize\": pointsize,\n",
    "                            \"outlineColor\": {\n",
    "                                \"rgba\": [255, 255, 255, 255]\n",
    "                            },\n",
    "                            \"outlineWidth\" : 1\n",
    "                        },\n",
    "                        \"description\": \"<br>\".join(['Site : ' + str(sitenum)] + [str(field) + \" : \" + str(value) for field, value in solution.iteritems()])})\n",
    "    try:\n",
    "        return idlist\n",
    "    except: \n",
    "        return None\n",
    "\n",
    "\n",
    "def czml_meo_orbit_all(starttime, endtime, config_dict, satnum = False, **kwargs):\n",
    "    servername, databasename  = config_dict[\"servername\"], config_dict[\"oppsdatabase\"]\n",
    "    if 'sql_login' in kwargs:\n",
    "        conn = odbc.connect(r'Driver={FreeTDS};Server='+servername+';Database='+databasename+'; UID='+UID+'; PWD=' + PWD, readonly=True, autocommit = True)\n",
    "    else:\n",
    "        conn = odbc.connect(r'Driver={SQL Server};Server='+servername+';Database='+databasename+';Trusted_Connection=yes;',readonly=True, autocommit = True)\n",
    "\n",
    "    satdict = OrderedDict()\n",
    "    sql_query = (\"select distinct sat from OrbitVector WHERE (Epoch between ? AND ?) AND LEFT(sat, 1) in ('3','4') order by sat \" )\n",
    "    c = conn.cursor()\n",
    "    params = [starttime, endtime]\n",
    "    c.execute(sql_query, params)\n",
    "    out = c.fetchall()\n",
    "    if satnum: \n",
    "        out = [(satnum,)]\n",
    "    for sat in out: \n",
    "        if sat[0] is not None:\n",
    "            params = [sat[0], starttime, endtime]\n",
    "            sql_query2 = ('select Epoch, SatXPos, SatYPos, SatZPos, SatXVel, SatYVel, SatZVel from OrbitVector WHERE sat = ? '\n",
    "                            'AND Epoch between ? AND ? '\n",
    "                            )\n",
    "            c2 = conn.cursor()\n",
    "            c2.execute(sql_query2, params)\n",
    "            outsatlist = c2.fetchall()\n",
    "            satdict[sat[0]]= outsatlist \n",
    "    satlist = [{\"id\":\"document\", \"version\":\"1.0\"}]\n",
    "    for i, value in enumerate(satdict):\n",
    "        poslist = []\n",
    "        if satdict[value]:\n",
    "            if str(value)[0] == \"3\":\n",
    "                pointprop = {\"color\": {\n",
    "                                \"rgba\": [0,0,255,255] \n",
    "                            },\n",
    "                            \"pixelSize\": 5,\n",
    "                            \"outlineColor\": {\n",
    "                                \"rgba\": [0, 127, 255, 200]\n",
    "                            },\n",
    "                            \"outlineWidth\" : 1\n",
    "                            }\n",
    "            else:\n",
    "                pointprop = {\"color\": {\n",
    "                                \"rgba\": [255,0,0,255] \n",
    "                            },\n",
    "                            \"pixelSize\": 5,\n",
    "                            \"outlineColor\": {\n",
    "                                \"rgba\": [0, 127, 255, 200]\n",
    "                            },\n",
    "                            \"outlineWidth\" : 1\n",
    "                            }\n",
    "            for j in range(len(satdict[value])):\n",
    "                poslist.extend([satdict[value][j][0].isoformat()+'Z'])\n",
    "                poslist.extend([satdict[value][j][i]*1000 for i in range(1,7)])\n",
    "            satlist.append({\"id\": int(value),\n",
    "                            \"name\": int(value),\n",
    "                            \"description\": \"<p>Satellite - \" + str(int(value)) + \"</p>\",\n",
    "                            \"parent\": \"meoSats\",\n",
    "                            \"label\": {\n",
    "                                \"text\": str(int(value)),\n",
    "                                \"font\": \"10pt Verdana\",\n",
    "                                \"horizontalOrigin\": \"CENTER\",\n",
    "                                \"pixelOffset\": {\n",
    "                                    \"cartesian2\" : [0, 20]\n",
    "                                }\n",
    "                            },\n",
    "                            \"availability\":starttime.isoformat() + 'Z/' + endtime.isoformat() + 'Z',\n",
    "                            \"position\": {\n",
    "                                \"interpolationAlgorithm\": \"LAGRANGE\",\n",
    "                                \"interpolationDegree\": 5,\n",
    "                                \"referenceFrame\": \"FIXED\",\n",
    "                                \"cartesianVelocity\": \n",
    "                                    poslist\n",
    "                            },\n",
    "                            \"point\": pointprop\n",
    "                            })\n",
    "    try:\n",
    "        return satlist\n",
    "    except: \n",
    "        return None\n",
    "\n",
    "def czml_meo_ant_per(data, StartTime, EndTime):\n",
    "    czml_list = [{\"id\":\"document\", \n",
    "                  \"version\":\"1.0\",\n",
    "                  \"name\" : \"MEOLUT Antenna Percentages\"}]\n",
    "    id_list = []\n",
    "    for key, val in data.iteritems():\n",
    "        if key == 'MEOLUT':\n",
    "            MEOLUT = val\n",
    "        if key == 'antenna':\n",
    "            for ant, stat in val.iteritems():\n",
    "                id_list.append((ant,stat['percent']))\n",
    "                if stat['percent'] > 0.8: \n",
    "                    rgba = [0 , 255, 0, 100]\n",
    "                    rgb = (0,255,0)\n",
    "                if stat['percent'] < 0.5: \n",
    "                    rgba = [255 , 0, 0, 100]\n",
    "                    rgb = (255, 0, 0) \n",
    "                if 0.5 < stat['percent'] < 0.8: \n",
    "                    rgba = [(stat['percent']-1.7)*(-212.5) , (stat['percent']-0.5)*850, 0, 100]\n",
    "                    rgb = ((stat['percent']-1.7)*(-212.5) , (stat['percent']-0.5)*850, 0)\n",
    "                czml_list.append({\n",
    "                    \"id\": str(MEOLUT) + \"-\" + str(int(ant)),\n",
    "                    \"name\": str(MEOLUT) + \"-\" + str(int(ant))+ \" percent\",\n",
    "                    \"parent\": \"meoPer-\" + str(MEOLUT),\n",
    "                    \"position\" : {\n",
    "                        \"cartographicDegrees\" : [MEOLUT_antenna_locations[MEOLUT][ant][1], \n",
    "                                                 MEOLUT_antenna_locations[MEOLUT][ant][0], \n",
    "                                                 MEOLUT_antenna_locations[MEOLUT][ant][2]]},\n",
    "                    \"cylinder\" : {\n",
    "                        \"length\" : 3+30.0*stat['percent'],\n",
    "                        #\"length\" : 30.0,\n",
    "                        \"topRadius\" : 8.0,\n",
    "                        \"bottomRadius\" : 8.0,\n",
    "                        \"material\" : {\n",
    "                            \"solidColor\" : {\n",
    "                                \"color\" : {\n",
    "                                    \"rgba\" : rgba\n",
    "                                }\n",
    "                            }\n",
    "                        },\n",
    "                        \"outline\" : \"true\",\n",
    "                        \"outlineColor\" : {\n",
    "                            \"rgba\" : [0, 0, 0, 255]\n",
    "                        },\n",
    "                    },\n",
    "                    \"description\" : \"<p style='color:rgb\" + str(rgb) + \"'>\" + \"percent = \" + '{:.1%}'.format(stat['percent']) + \"</p>\"\n",
    "                        \n",
    "                    \n",
    "                })\n",
    "    return czml_list\n",
    "                #czml_list.append({\n",
    "                #\"id\": key+\"-\"})\n",
    "\n",
    "    #\"id\" : \"shape1\",\n",
    "    #\"name\" : \"Green cylinder with black outline\",\n",
    "    #\"position\" : {\n",
    "    #    \"cartographicDegrees\" : [-100.0, 40.0, 200000.0]\n",
    "    #},\n",
    "    #\"cylinder\" : {\n",
    "    #    \"length\" : 400000.0,\n",
    "    #    \"topRadius\" : 200000.0,\n",
    "    #    \"bottomRadius\" : 200000.0,\n",
    "    #    \"material\" : {\n",
    "    #        \"solidColor\" : {\n",
    "    #            \"color\" : {\n",
    "    #                \"rgba\" : [0, 255, 0, 128]\n",
    "    #            }\n",
    "    #        }\n",
    "    #    },\n",
    "    #    \"outline\" : true,\n",
    "    #    \"outlineColor\" : {\n",
    "    #        \"rgba\" : [0, 0, 0, 255]\n",
    "    #    }\n",
    "def czml_leo_orbit_all(starttime, endtime, servername = 'localhost', databasename='mccoperational',  satnum = False, **kwargs):\n",
    "    if 'sql_login' in kwargs:\n",
    "        conn = odbc.connect(r'Driver={FreeTDS};Server='+servername+';Database='+databasename+'; UID='+UID+'; PWD=' + PWD, readonly=True, autocommit = True)\n",
    "    else:\n",
    "        conn = odbc.connect(r'Driver={SQL Server};Server='+servername+';Database='+databasename+';Trusted_Connection=yes;',readonly=True, autocommit = True)\n",
    "\n",
    "    satdict = OrderedDict()\n",
    "    sql_query = ('select distinct Sat from LutOrbitVectorOut order by Sat ' )\n",
    "    c = conn.cursor()\n",
    "    c.execute(sql_query)\n",
    "    out = c.fetchall()\n",
    "    if satnum: \n",
    "        out = [(satnum,)]\n",
    "\n",
    "    for sat in out: \n",
    "        if sat[0] is not None:\n",
    "            params = [sat[0], starttime, endtime]\n",
    "            sql_query2 = ('select Epoch, SatXPos, SatYPos, SatZPos, SatXVel, SatYVel, SatZVel, Orbit from LutOrbitVectorOut WHERE sat = ? '\n",
    "                            'AND Epoch > ? '\n",
    "                            'AND Epoch < ? '\n",
    "                            )\n",
    "            c2 = conn.cursor()\n",
    "            c2.execute(sql_query2, params)\n",
    "            outsatlist = c2.fetchall()\n",
    "            satdict[sat[0]]= outsatlist \n",
    "    satlist = [{\"id\":\"document\", \"version\":\"1.0\"}]\n",
    "    for i, value in enumerate(satdict):\n",
    "        poslist = []\n",
    "        for j in range(len(satdict[value])):\n",
    "            poslist.extend([satdict[value][j][0].isoformat()+'Z'])\n",
    "            poslist.extend([satdict[value][j][i]*1000 for i in range(1,7)])\n",
    "        satlist.append({\"id\": value,\n",
    "                        \"name\": value,\n",
    "                        \"label\": {\n",
    "                            \"text\": str(value),\n",
    "                            \"font\": \"10pt Verdana\",\n",
    "                            \"horizontalOrigin\": \"CENTER\",\n",
    "                            \"pixelOffset\": {\n",
    "                                \"cartesian2\" : [0, 20]\n",
    "                            }\n",
    "                        },\n",
    "                        \"availability\":starttime.isoformat() + 'Z/' + endtime.isoformat() + 'Z',\n",
    "                        \"position\": {\n",
    "                            \"interpolationAlgorithm\": \"LAGRANGE\",\n",
    "                            \"interpolationDegree\": 2,\n",
    "                            \"referenceFrame\": \"FIXED\",\n",
    "                            \"cartesianVelocity\": \n",
    "                                poslist\n",
    "                        },\n",
    "\n",
    "                        #\"availability\":\"2017-08-04T16:00:00Z/2017-09-04T17:00:00Z\",\n",
    "                        #\"availability\":i[5].isoformat() + 'Z/' + LastUpdTime[0].isoformat() + 'Z',\n",
    "\n",
    "                        #    \"pixelOffset\": {\n",
    "                        #        \"cartesian2\" : [0, 20]\n",
    "                        #    },\n",
    "                        #    \"font\": \"14pt Verdana\"\n",
    "                        #}\n",
    "                        #\"position\": {\n",
    "                        #    \"cartographicDegrees\": [float(i[7]),float(i[6]),0]\n",
    "                        #}, \n",
    "                        \"point\": {\n",
    "                            \"color\": { \n",
    "                                #\"rgba\": [63,191,191,120] \n",
    "                                \"rgba\": [255,255,255,255] \n",
    "                                },\n",
    "                            \"pixelSize\": 5,\n",
    "                            \"outlineColor\": {\n",
    "                                \"rgba\": [0, 127, 255, 200]\n",
    "                            },\n",
    "                            \"outlineWidth\" : 2\n",
    "                        }\n",
    "                        })\n",
    "\n",
    "\n",
    "                        #\"description\": \"<br>\".join(['Site : ' + str(int(Sitenum))] + [str(fieldlist[j]) + \" : \" + str(value) for j, value in enumerate(i)])})\n",
    "    try:\n",
    "        return satlist\n",
    "    except: \n",
    "        return None\n",
    "\n",
    "\n",
    "def czml_meo_sched_all(starttime, endtime, servername = 'localhost', databasename='mccoperational',  antnum = False, **kwargs):\n",
    "    if 'sql_login' in kwargs:\n",
    "        conn = odbc.connect(r'Driver={FreeTDS};Server='+servername+';Database='+databasename+'; UID='+UID+'; PWD=' + PWD, readonly=True, autocommit = True)\n",
    "    else:\n",
    "        conn = odbc.connect(r'Driver={SQL Server};Server='+servername+';Database='+databasename+';Trusted_Connection=yes;',readonly=True, autocommit = True)\n",
    "\n",
    "    for LUT in [3669, 3385]:\n",
    "        satdict = OrderedDict()\n",
    "        params = [starttime, endtime, LUT]\n",
    "        sql_query = ('select LutId, AntennaId, SatId, AOSStr, LOSStr, TimeRecordAdded from PassesPlanned '\n",
    "                    'where TimeRecordAdded = (select top 1 TimeRecordAdded from PassesPlanned where '\n",
    "                    'AOSStr > ? and LOSStr < ? AND LutId = ? '\n",
    "                    'order by TimeRecordAdded desc) '\n",
    "                    )\n",
    "        c = conn.cursor()\n",
    "        c.execute(sql_query, params)\n",
    "        out = c.fetchall()\n",
    "        for sat in out: \n",
    "            if sat[0] is not None:\n",
    "                params = [str(sat[0]), starttime, endtime]\n",
    "                sql_query2 = ('select Epoch, SatXPos, SatYPos, SatZPos, SatXVel, SatYVel, SatZVel, Orbit from LutOrbitVectorOut WHERE sat = ? '\n",
    "                                'AND Epoch > ? '\n",
    "                                'AND Epoch < ? '\n",
    "                                )\n",
    "                c2 = conn.cursor()\n",
    "                c2.execute(sql_query2, params)\n",
    "                outsatlist = c2.fetchall()\n",
    "                satdict[sat[0]]= outsatlist \n",
    "        satlist = [{\"id\":\"document\", \"version\":\"1.0\"}]\n",
    "        for i, value in enumerate(satdict):\n",
    "            passlist = []\n",
    "            for j in range(len(satdict[value])):\n",
    "                passlist.extend([satdict[value][j][0].isoformat()+'Z'])\n",
    "                passlist.extend([satdict[value][j][i]*1000 for i in range(1,7)])\n",
    "            satlist.append({\"id\": value,\n",
    "                            \"name\": value,\n",
    "                            \"label\": {\n",
    "                                \"text\": str(value),\n",
    "                                \"font\": \"10pt Verdana\",\n",
    "                                \"horizontalOrigin\": \"CENTER\",\n",
    "                                \"pixelOffset\": {\n",
    "                                    \"cartesian2\" : [0, 20]\n",
    "                                }\n",
    "                            },\n",
    "                            \"availability\":starttime.isoformat() + 'Z/' + endtime.isoformat() + 'Z',\n",
    "                            \"position\": {\n",
    "                                \"interpolationAlgorithm\": \"LAGRANGE\",\n",
    "                                \"interpolationDegree\": 2,\n",
    "                                \"referenceFrame\": \"FIXED\",\n",
    "                                \"cartesianVelocity\": \n",
    "                                    poslist\n",
    "                            },\n",
    "\n",
    "                            #\"availability\":\"2017-08-04T16:00:00Z/2017-09-04T17:00:00Z\",\n",
    "                            #\"availability\":i[5].isoformat() + 'Z/' + LastUpdTime[0].isoformat() + 'Z',\n",
    "\n",
    "                            #    \"pixelOffset\": {\n",
    "                            #        \"cartesian2\" : [0, 20]\n",
    "                            #    },\n",
    "                            #    \"font\": \"14pt Verdana\"\n",
    "                            #}\n",
    "                            #\"position\": {\n",
    "                            #    \"cartographicDegrees\": [float(i[7]),float(i[6]),0]\n",
    "                            #}, \n",
    "                            \"point\": {\n",
    "                                \"color\": { \n",
    "                                    #\"rgba\": [63,191,191,120] \n",
    "                                    \"rgba\": [255,255,255,255] \n",
    "                                    },\n",
    "                                \"pixelSize\": 5,\n",
    "                                \"outlineColor\": {\n",
    "                                    \"rgba\": [0, 127, 255, 200]\n",
    "                                },\n",
    "                                \"outlineWidth\" : 2\n",
    "                            }\n",
    "                            })\n",
    "\n",
    "\n",
    "                        #\"description\": \"<br>\".join(['Site : ' + str(int(Sitenum))] + [str(fieldlist[j]) + \" : \" + str(value) for j, value in enumerate(i)])})\n",
    "    try:\n",
    "        return satlist\n",
    "    except: \n",
    "        return None\n",
    "     \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MCC_Web_App",
   "language": "python",
   "name": "mcc_web_app"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
